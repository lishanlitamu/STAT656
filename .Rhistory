cbind(.,XtslaDummy) %>%
dplyr::select(-R1,-S1,-R2,-S2,-R3,-S3)
hclustPlotF(tslaXyeoJ)
macdPrice = TTR::MACD(tslaAddK$PX_LAST, nFast = daysMACDfast, nSlow = daysMACDslow, nSig = daysMACDsignal)
macdPrice = TTR::MACD(tslaAddK$PX_LAST, nFast = daysMACDfast, nSlow = daysMACDslow, nSig = daysMACDsignal)[,1]
tslaAddMACD = tslaAddK %>% mutate(macdPrice)
macdVolume = (TTR::MACD(tslaAddK$PX_VOLUME, nFast = daysMACDfast, nSlow = daysMACDslow, nSig = daysMACDsignal))[,1]
tslaAddMACD = tslaAddK %>% mutate(macdPrice) %>% mutate(macdVolume)
daysR = 14 #default
#tslaHLC  = tslaSelected %>% dplyr::select(PX_HIGH, PX_LOW, PX_LAST)
tslaAddR = tslaAddMACD %>%
mutate(larryWilliamsR = TTR::WPR(tslaHLC, n = daysR))
tslaAddAD = tslaAddR %>%
mutate(williamsAD = TTR::williamsAD(tslaHLC))
daysCCI = 20
tslaAddCCI = tslaAddAD %>%
mutate(cci = TTR::CCI(tslaHLC, n = daysCCI))
#--End--#
#Summarize how many indicators we've added.
beforeAfterVar = tslaAddCCI[,(ncol(tslaSelected)+1):ncol(tslaAddCCI)]
names(beforeAfterVar)
tslaY  = tslaAddCCI %>%
na.omit() %>%
dplyr::select(diffHighLow, stockReturn) %>%
dplyr::as_tibble() %>%
dplyr::slice(-1)
tslaX    = tslaAddCCI %>%
na.omit() %>%
.[1:(nrow(.)-1),] %>%
dplyr::as_tibble(.)
names(tslaY)[1] = "diffHighLowTomorrow" #Y1
names(tslaY)[2] = "stockReturnTomorrow" #Y2
tslaFull = dplyr::as_tibble(cbind(tslaY,tslaX))
#Correlation between stock data of today and difference between highest and lowest stock prices on tomorrow is much higher than correlation between stock data of today and daily stock return on tomorrow. Thus, it's suggested to use "diffHighLowTomorrow " as the supervisor in model fitting.
#summary(tslaY$diffHighLowTomorrow)
hclustPlotF(tslaX)
anyNA(tslaX)
hclustPlotF(tslaX)
cor(tslaX)
## Load raw data into the global environment
tsla <- base::data.frame(data.table::fread("1 - Data/Tesla/tsla.csv", na.strings = c("#N/A N/A", "#N/A Invalid Field", "#N/A Requesting Data...")), stringsAsFactors = F)
goog <- base::data.frame(data.table::fread("1 - Data/Google/goog.csv", na.strings = c("#N/A N/A", "#N/A Invalid Field", "#N/A Requesting Data...")), stringsAsFactors = F)
## Clean raw data
tsla <- tsla %>% dplyr::select_if(~sum(!is.na(.)) > 0) %>% # Drop columns that contain only NAs
dplyr::filter(!is.na(PX_LAST)) # Drop rows where PX_LAST is NA
goog <- goog %>% dplyr::select_if(~sum(!is.na(.)) > 0) %>% # Drop columns that contain only NAs
dplyr::filter(!is.na(PX_LAST)) # Drop rows where PX_LAST is NA
## Format date columns
tsla$Date <- as.Date(tsla$Date, "%m/%d/%Y")
goog$Date <- as.Date(goog$Date, "%m/%d/%Y")
## Plot prices versus time
tsla_plot <- ggplot2::ggplot() +
ggplot2::geom_line(data = tsla, ggplot2::aes(x = Date, y = PX_LAST)) + ggplot2::ggtitle("TSLA")
goog_plot <- ggplot2::ggplot() +
ggplot2::geom_line(data = goog, ggplot2::aes(x = Date, y = PX_LAST)) + ggplot2::ggtitle("GOOG") +
ggplot2::scale_x_date(limits = c(base::min(tsla$Date), base::max(tsla$Date))) # Align the x-axis with TSLA
gridExtra::grid.arrange(tsla_plot, goog_plot)
## TSLA
## Run linear interpolations
tmp <- zoo::na.approx(tsla[, base::c(14:22, 24:26)])
## Create empty matrix as placeholder for non-interpolated rows
row_diff <- base::nrow(tsla) - base::nrow(tmp)
empty <- base::matrix(base::rep(NA, row_diff * base::ncol(tmp)), nrow = row_diff, ncol = base::ncol(tmp))
base::colnames(empty) <- base::colnames(tmp)
tmp <- base::rbind(tmp, empty)
## Replace original data with interpolation
tsla[, base::c(14:22, 24:26)] <- tmp
## GOOG
## Run linear interpolations
tmp <- zoo::na.approx(goog[, 11:23])
## Create empty matrix as placeholder for non-interpolated rows
row_diff <- base::nrow(goog) - base::nrow(tmp)
empty <- base::matrix(base::rep(NA, row_diff * base::ncol(tmp)), nrow = row_diff, ncol = base::ncol(tmp))
base::colnames(empty) <- base::colnames(tmp)
tmp <- base::rbind(tmp, empty)
## Replace original data with interpolation
goog[, 11:23] <- tmp
require(dplyr)
totalRowTsla = base::nrow(tsla)
totalColTsla = base::ncol(tsla)
naTsla       = tsla %>%
base::sapply(.,function(y) base::sum(base::length(base::which(base::is.na(y))))) %>%
base::as.data.frame() %>%
tibble::rownames_to_column(., "Features")
totalRowGoog = base::nrow(goog)
totalColGoog = base::ncol(goog)
naGoog       = goog %>%
base::sapply(.,function(y) base::sum(base::length(base::which(base::is.na(y))))) %>%
base::as.data.frame() %>%
tibble::rownames_to_column(., "Features")
knitr::kable(
naTsla,
col.names = c("Features","Number of Missing Values"),
caption   = "Table 2-1: The number of Missing Values - Tesla",
align     = "lccrr"
)
knitr::kable(
naGoog,
col.names = c("Features","Number of Missing Values"),
caption   = "Table 2-2: The number of Missing Values - Google",
align     = "lccrr"
)
#Select a subset of original data for data transformation and PCA
tslaSelected = tsla %>%
.[,(which(naTsla[,2] < 100))] %>%
.[!(apply(.,1, function(y){any(is.na(y))})),] %>%
.[,-1] #remove dates in the first column
#Apply Log-transformation on tslaSelected$TURNOVER to avoid producing NaN in skewness computation
tslaSelected$TURNOVER = log(tslaSelected$TURNOVER)
base::names(tslaSelected) [6]= "log(TURNOVER)"
require(e1071)
skewnessTsla = apply(tslaSelected,2,e1071::skewness)
kurtosisTsla   = apply(tslaSelected,2,e1071::kurtosis)
skewnessTsla = skewnessTsla %>%
as.data.frame() %>%
tibble::rownames_to_column(., "features")
knitr::kable(
skewnessTsla,
col.names = c("Features","Skewness"),
caption   = "Table 2-3: Skewness of Selected Features - Tesla",
align     = "lccrr"
)
kurtosisTsla = kurtosisTsla %>%
as.data.frame() %>%
tibble::rownames_to_column(., "features")
knitr::kable(
kurtosisTsla,
col.names = c("Features","Kurtosis"),
caption   = "Table 2-4: Kurtosis of Selected Features - Tesla",
align     = "lccrr"
)
#Transform the selected data
(tslaTrans = caret::preProcess(tslaSelected, method = c("BoxCox","center","scale","pca")))
#Apply the transformations("BoxCox","center","scale","pca")
tslaPCA = stats::predict(tslaTrans,tslaSelected) #Outputs are PCA components
utils::head(tslaPCA)
#Summary of PCA results
tslaTrans_     = caret::preProcess(tslaSelected, method = c("BoxCox","center","scale"))
propVarTslaPCA = tslaSelected %>%
stats::predict(tslaTrans_,.) %>%
stats::prcomp() %>%
summary()
propVarTslaPCA #proportion of variance explained by each PCs
#Check extreme observations via PCA
ggplot(data = tslaPCA)+
geom_point(aes(x = PC1, y= PC2))
ggplot(data = tslaPCA)+
geom_point(aes(x = PC3, y= PC2))
ggplot(data = tslaPCA)+
geom_point(aes(x = PC1, y= PC3))
plot3D::scatter3D(tslaPCA$PC1, tslaPCA$PC2, tslaPCA$PC3, pch = 16,
theta = 20, phi = 20, main = "PCA - Tesla", xlab = "PC1",
ylab ="PC2", zlab = "PC3", bty = "g", ticktype = "detailed")
transformedTsla = predict(tslaTrans_,tslaSelected)
par(mfrow=c(2,2))
for (i in 1:ncol(tslaSelected)) {
hist(tslaSelected[,i], breaks=20, freq=FALSE,
main = paste("Density Plot - ",names(tslaSelected)[i],                            "(Before)"),xlab = " ")
hist(transformedTsla[,i], breaks=20, freq=FALSE,
main = paste("Density Plot - ",names(transformedTsla)[i],
"(After)"),xlab = " ")
}
#Select a subset of original data for data transformation and PCA
googSelected = goog %>%
.[,(which(naGoog[,2] < 100))] %>%
.[!(apply(.,1, function(y){any(is.na(y))})),] %>%
.[,-1] #remove dates in the first column
#Apply Log-transformation on googSelected$TURNOVER
googSelected$TURNOVER = base::log(googSelected$TURNOVER)
base::names(googSelected) [6]= "log(TURNOVER)"
#require(e1071)
skewnessGoog = apply(googSelected,2,e1071::skewness)
kurtosisGoog = apply(googSelected,2,e1071::kurtosis)
skewnessGoog = skewnessGoog%>%
as.data.frame() %>%
tibble::rownames_to_column(., "features")
knitr::kable(
skewnessGoog,
col.names = c("Features","Skewness"),
caption   = "Table 2-5: Skewness of Selected Features - Google",
align     = "lccrr"
)
kurtosisGoog = kurtosisGoog %>%
as.data.frame() %>%
tibble::rownames_to_column(., "features")
knitr::kable(
kurtosisGoog,
col.names = c("Features","Kurtosis"),
caption   = "Table 2-6: Kurtosis of Selected Features - Google",
align     = "lccrr"
)
#Transform the selected data
(googTrans = caret::preProcess(googSelected, method = c("BoxCox","center","scale","pca")))
#Apply the transformations("BoxCox","center","scale","pca")
googPCA = stats::predict(googTrans,googSelected) #Outputs are PCA components
utils::head(googPCA)
#Summary of PCA results
(googTrans_    = caret::preProcess(googSelected, method = c("BoxCox","center","scale")))
propVarGoogPCA = googSelected %>%
stats::predict(googTrans_,.) %>%
stats::prcomp() %>%
summary()
propVarGoogPCA #proportion of variance explained by each PCs
#Check extreme observations via PCA
ggplot(data = googPCA)+
geom_point(aes(x = PC1, y= PC2))
ggplot(data = googPCA)+
geom_point(aes(x = PC3, y= PC2))
ggplot(data = googPCA)+
geom_point(aes(x = PC1, y= PC3))
plot3D::scatter3D(googPCA$PC1, googPCA$PC2, googPCA$PC3, pch = 16,
theta = 20, phi = 20, main = "PCA - Alphabet", xlab = "PC1",
ylab ="PC2", zlab = "PC3", bty = "g", ticktype = "detailed")
transGoog = predict(googTrans_,googSelected)
par(mfrow=c(2,2))
for (i in 1:ncol(googSelected)) {
hist(googSelected[,i], breaks=20, freq=FALSE,
main = paste("Density Plot - ",names(googSelected)[i], "(After)"),
xlab = " ")
hist(transGoog[,i], breaks=20, freq=FALSE,
main = paste("Density Plot - ",names(transGoog)[i], "(Before)"),
xlab = " ")
}
library(corrplot)
corrTsla     = stats::cor(tslaSelected)
corrplot::corrplot(corrTsla, order="hclust")
#library(corrplot)
corrGoog     = stats::cor(googSelected)
corrplot::corrplot(corrGoog, order="hclust")
#Tsla
#str(tslaSelected)
sapply(tslaSelected,function(x){length(unique(x))})
#Goog
#str(googSelected)
sapply(googSelected,function(x){length(unique(x))})
#Tsla
#str(tslaSelected)
sapply(tsla,function(x){length(unique(x))})
#summary(tsla)
#Goog
#str(googSelected)
sapply(goog,function(x){length(unique(x))})
#summary(tslaSelected)
#Recall highly correlated variables before making changes
highCorrTsla = tslaSelected %>%
cor %>%
caret::findCorrelation(.8, names = TRUE)
highCorrTsla
corrplot::corrplot(cor(tslaSelected), order="hclust")
highCorrGoog = googSelected %>%
cor %>%
caret::findCorrelation(.8, names = TRUE)
highCorrGoog
corrplot::corrplot(cor(googSelected), order="hclust")
###TSLA
tslaTemp = tslaSelected %>%
dplyr::mutate(
PP = lag((PX_HIGH + PX_LOW + PX_LAST)/3), #Previous Day (High + Low + Close) / 3
R1 = 2 * PP - lag(PX_LOW),                #(Pivot x 2) – Previous Day Low
S1 = 2 * PP - lag(PX_HIGH),               #(Pivot x 2) – Previous Day High
R2 = PP + (R1 - S1),                      #Pivot + (R1 – S1)
S2 = PP - (R1 - S1),                      #Pivot - (R1 – S1)
R3 = lag(PX_HIGH) + 2 * (PP - lag(PX_LOW)),
#R3= Previous Day High + 2(PP – Previous Day Low)
S3 = lag(PX_LOW) - 2 * (lag(PX_HIGH) - PP),
#S3= Previous Day Low – 2(Previous Day High – Pivot)
diffHighLow  = PX_HIGH - PX_LOW,
diffLastOpen = PX_LAST - PX_OPEN,
stockReturn  = (PX_LAST - PX_OPEN)/PX_OPEN
)
highCorrF = function(dta, thred){
#Find highly correlated features
highCorr = dta %>%
cor %>%
caret::findCorrelation(thred, names = TRUE)
return(highCorr)
}
hclustPlotF = function(dta) {
#Correlation Plot
corrplot::corrplot(cor(dta), order="hclust")
}
###GOOG
tslaAddOBV = tslaTemp %>%
mutate(obv = TTR::OBV(PX_LAST, PX_VOLUME))
#TSLA
daysCMF = 21
tslaAddCMF = tslaAddOBV %>%
mutate(cmf = TTR::CMF(tslaAddOBV[,c("PX_HIGH","PX_LOW","PX_LAST")], PX_VOLUME, n = daysCMF))
#GOOG
#TSLA
daysEMA = 10 #EMA lengths
tslaAddEMA = tslaAddCMF %>%
mutate(emaPrice = TTR::EMA(tslaAddCMF$PX_LAST,daysEMA)) %>%
mutate(emaVolume = TTR::EMA(tslaAddCMF$PX_VOLUME,daysEMA))
###GOOG
###Tsla
daysRSI = 14
tslaAddRSI = tslaAddEMA %>%
mutate(rsi = TTR::RSI(PX_LAST, n=daysRSI, maType="WMA", wts=PX_VOLUME))
###GOOG
###Tsla
daysSMA = 10
tslaAddSMA = tslaAddRSI %>%
mutate(smaPrice = TTR::SMA(PX_LAST, n=daysSMA)) %>%
mutate(smaVolume = TTR::SMA(PX_VOLUME, n=daysSMA))
###GOOG
###Tsla
#Stochastic Momentum Index
daysK = 5 #%K is usually set to 5 and represents the main movements of price – slow line.
daysD = 3 #%D is the fast line, a simple moving average of the %K and is set to 3.
tslaHLC  = tslaSelected %>% dplyr::select(PX_HIGH, PX_LOW, PX_LAST)
tslaAddK = tslaAddSMA %>%
dplyr::mutate(smi_K = (stoch(tslaHLC, nFastK = daysK, nFastD = daysD, nSlowD = 3, bounded = TRUE,smooth = 1))[,1]) %>% #calculate fastK%
dplyr::mutate(smi_D = (stoch(tslaHLC, nFastK = daysK, nFastD = daysD, nSlowD = 3, bounded = TRUE,smooth = 1))[,2])  #calculate fastD%
#bounded:Logical, should current period’s values be used in the calculation? Set it as TRUE here. We will align Y's with past X's in Section xxx.
#Reference:https://library.tradingtechnologies.com/trade/chrt-ti-stochastic-momentum-index.html
###GOOG
daysMACDslow   = 26 #default nSlow
daysMACDfast   = 12 #default nFast
daysMACDsignal = 9  #default nSig
tslaAddMACD = tslaAddK %>%
mutate(macdPrice = (TTR::MACD(PX_LAST, nFast = daysMACDfast, nSlow = daysMACDslow, nSig = daysMACDsignal))[,1]) %>%
#mutate(macdPrice = TTR::MACD(nFast = 12, nSlow = 26, nSig = 9, maType="WMA", wts=PX_VOLUME)) %>% # weighted macdPrice
mutate(macdVolume = (TTR::MACD(PX_VOLUME, nFast = daysMACDfast, nSlow = daysMACDslow, nSig = daysMACDsignal))[,1])
daysR = 14 #default
#tslaHLC  = tslaSelected %>% dplyr::select(PX_HIGH, PX_LOW, PX_LAST)
tslaAddR = tslaAddMACD %>%
mutate(larryWilliamsR = TTR::WPR(tslaHLC, n = daysR))
tslaAddAD = tslaAddR %>%
mutate(williamsAD = TTR::williamsAD(tslaHLC))
daysCCI = 20
tslaAddCCI = tslaAddAD %>%
mutate(cci = TTR::CCI(tslaHLC, n = daysCCI))
#--End--#
#Summarize how many indicators we've added.
beforeAfterVar = tslaAddCCI[,(ncol(tslaSelected)+1):ncol(tslaAddCCI)]
names(beforeAfterVar)
tslaY  = tslaAddCCI %>%
na.omit() %>%
dplyr::select(diffHighLow, stockReturn) %>%
dplyr::as_tibble() %>%
dplyr::slice(-1)
tslaX    = tslaAddCCI %>%
na.omit() %>%
.[1:(nrow(.)-1),] %>%
dplyr::as_tibble(.)
names(tslaY)[1] = "diffHighLowTomorrow" #Y1
names(tslaY)[2] = "stockReturnTomorrow" #Y2
tslaFull = dplyr::as_tibble(cbind(tslaY,tslaX))
hclustPlotF(tslaX)
#It's suggested to use only quantitative variables in PCA regression
#Transform the selected data
(tslaXTrans = caret::preProcess(as.data.frame(tslaX), method = c("BoxCox","center","scale","pca")))
#Apply the transformations("BoxCox","center","scale","pca")
pcaTslaX = stats::predict(tslaXTrans,as.data.frame(tslaX)) #Outputs are PCA components
#head(pcaTslaX)
#Summary of PCA results
tslaXTrans_     = caret::preProcess(as.data.frame(tslaX), method = c("BoxCox","center","scale"))
propVar_pcaTslaX = as.data.frame(tslaX) %>%
stats::predict(tslaXTrans_,.) %>%
stats::prcomp() %>%
summary()
propVar_pcaTslaX #proportion of variance explained by each PCs
#Check extreme observations via PCA
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC1, y= PC2))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC3, y= PC2))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC1, y= PC3))
plot3D::scatter3D(pcaTslaX$PC1, pcaTslaX$PC2, pcaTslaX$PC3, pch = 16,
theta = 20, phi = 20, main = "PCA - Tesla", xlab = "PC1",
ylab ="PC2", zlab = "PC3", bty = "g", ticktype = "detailed")
#diffHighLow vs PCs
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC1, y=tslaY$diffHighLowTomorrow), color=ifelse(tslaY$diffHighLowTomorrow > mean(tslaY$diffHighLowTomorrow),"red", "blue"))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC1, y=tslaY$diffHighLowTomorrow)
, color=ifelse(tslaX$diffHighLow > mean(tslaX$diffHighLow),"red", "blue"))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC1, y=tslaY$diffHighLowTomorrow)
, color=ifelse(tslaX$stockReturn > mean(tslaX$stockReturn),"red", "blue"))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC2, y=tslaY$diffHighLowTomorrow), color=ifelse(tslaY$diffHighLowTomorrow > mean(tslaY$diffHighLowTomorrow),"red", "blue"))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC2, y=tslaY$diffHighLowTomorrow)
, color=ifelse(tslaX$diffHighLow > mean(tslaX$diffHighLow),"red", "blue"))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC2, y=tslaY$diffHighLowTomorrow)
, color=ifelse(tslaX$stockReturn > mean(tslaX$stockReturn),"red", "blue"))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC3, y=tslaY$diffHighLowTomorrow)
, color=ifelse(tslaY$diffHighLowTomorrow > mean(tslaY$diffHighLowTomorrow),"red", "blue"))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC3, y=tslaY$diffHighLowTomorrow)
, color=ifelse(tslaX$diffHighLow > mean(tslaX$diffHighLow),"red", "blue"))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC3, y=tslaY$diffHighLowTomorrow)
, color=ifelse(tslaX$stockReturn > mean(tslaX$stockReturn),"red", "blue"))
scatterplot3d::scatterplot3d(x = pcaTslaX$PC1, y = pcaTslaX$PC2,
z = tslaY$diffHighLowTomorrow, pch = 16, color = ifelse(tslaY$diffHighLowTomorrow > mean(tslaY$diffHighLowTomorrow),"red", "blue"))
#stockReturn vs PCs
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC1, y=tslaY$stockReturnTomorrow), color=ifelse(tslaX$stockReturn > mean(tslaX$stockReturn),"red", "blue"))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC1, y=tslaY$stockReturnTomorrow), color=ifelse(tslaX$diffHighLow > mean(tslaX$diffHighLow),"red", "blue"))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC1, y=tslaY$stockReturnTomorrow), color=ifelse(tslaX$stockReturn > mean(tslaX$stockReturn),"red", "blue"))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC2, y=tslaY$stockReturnTomorrow))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC3, y=tslaY$stockReturnTomorrow))
#hist(tslaReg$stockReturn, breaks=20, freq=FALSE,main = paste("Density Plot - ",names(tslaReg$stockReturn)),xlab = " ") # stock return is normally distributed.
XtslaAddLevels = tslaFull %>%
mutate(aboveR1 = factor(ifelse(PX_HIGH > R1, "Yes", "No"))) %>%
mutate(aboveR2 = factor(ifelse(PX_HIGH > R2, "Yes", "No"))) %>%
mutate(aboveR3 = factor(ifelse(PX_HIGH > R3, "Yes", "No"))) %>%
mutate(belowS1 = factor(ifelse(PX_LOW  < S1, "Yes", "No"))) %>%
mutate(belowS2 = factor(ifelse(PX_LOW  < S2, "Yes", "No"))) %>%
mutate(belowS3 = factor(ifelse(PX_LOW  < S3, "Yes", "No"))) %>%
select(aboveR1, aboveR2, aboveR3, belowS1, belowS2, belowS3)
XtslaDummyModel = caret::dummyVars(~ ., data = XtslaAddLevels, fullRank = TRUE)
YtslaAddLevels = as_tibble(factor(ifelse(tslaY$stockReturnTomorrow > 0, "Increased", "Decreased")))
YtslaDummyModel = caret::dummyVars(~ ., data = YtslaAddLevels, fullRank = TRUE)
XtslaDummy = as_tibble(predict(XtslaDummyModel, XtslaAddLevels))
YtslaDummy = as_tibble(predict(YtslaDummyModel, YtslaAddLevels))
names(YtslaDummy)[1] = "stockReturnTomorrowDummy" #Y2
tslaLogReg = tslaFull %>%
mutate(XtslaDummy) %>%
dplyr::select(-R1,-S1,-R2,-S2,-R3,-S3) %>%
#Drop PP, R1, R2, R3, S1, S2, S3
mutate(YtslaDummy)
#First, correct skewness
tslaXyeoJ = tslaX %>%
caret::preProcess(method = "YeoJohnson") %>%
predict(newdata = tslaX)
#hist(tslaY$diffHighLowTomorrow)
#hist(tslaY$stockReturnTomorrow)
tslaYyeoJ = tslaY %>%
caret::preProcess(method = "YeoJohnson") %>%
predict(newdata = tslaY)
#hist(tslaYyeoJ$diffHighLowTomorrow)
#hist(tslaYyeoJ$stockReturnTomorrow)
Ktsla = 10
cvIndexTsla = caret::createFolds(tslaYyeoJ$diffHighLowTomorrow, k = Ktsla, returnTrain = TRUE)
trControl = trainControl(method = "cv", index = cvIndexTsla)
XtslaPenalty = tslaXyeoJ %>%
caret::preProcess(method = c("center","scale")) %>%
predict(tslaXyeoJ) %>%
cbind(.,XtslaDummy) %>%
dplyr::select(-R1,-S1,-R2,-S2,-R3,-S3)
YtslaPenalty = tslaYyeoJ %>%
caret::preProcess(method = c("center","scale")) %>%
predict(newdata = tslaYyeoJ)
lmOutTsla = train(x = XtslaPenalty, y = YtslaPenalty$diffHighLowTomorrow, method = "lm", trControl = trControl)
lmOutTsla
#Errors in ridge and lasso regression are solved by removing highly correlated features in XtslaPenalty
highCorrTsla = XtslaPenalty %>% highCorrF(.,0.8) %>%
.[-c(25,27)] %>%
c(.,c("macdPrice","macdVolume"))
XtslaRegRemoveCorr = XtslaPenalty %>% select(-highCorrTsla)
names(XtslaPenalty)
names(XtslaLogRegRemoveCorr)
#ridge regression
ridgeOutTsla = train(x = XtslaRegRemoveCorr, y = YtslaPenalty$diffHighLowTomorrow, method = "ridge", tuneLength = 10,trControl = trControl)
ridgeOutTsla
ridgeOutTsla = train(x = XtslaPenalty, y = YtslaPenalty$diffHighLowTomorrow, method = "ridge", tuneLength = 10,trControl = trControl)
#lasso regression
lassoOutTsla = train(x = XtslaRegRemoveCorr, y = YtslaPenalty$diffHighLowTomorrow, method = "lasso", tuneLength = 10,trControl = trControl)
lassoOutTsla
#elastic net
gridLambdaAlpha = expand.grid(lambda = seq(1e-6, 0.05, length = 15), alpha = c(0,0.25,.5,.75,1))
enetOutTsla = train(x = XtslaPenalty, y = YtslaPenalty$diffHighLowTomorrow,
method = "glmnet", tuneGrid = gridLambdaAlpha, trControl = trControl)
enetOutTsla
plot(enetOutTsla, xlab = "Lambda (Elastic Net Penalty)", ylab = "RMSE (K-fold CV)" )
#Results of penalized linear model
names(enetOutTsla$finalModel)
alphaHatTsla  = enetOutTsla$finalModel$tuneValue$alpha
lambdaHatTsla = enetOutTsla$finalModel$tuneValue$lambda
glmnetOutTsla = glmnet::glmnet(x = as.matrix(XtslaPenalty), y = YtslaPenalty$diffHighLowTomorrow, alpha = alphaHatTsla, standardize = FALSE)
betaHatTsla = coef(glmnetOutTsla, s = lambdaHatTsla)
betaHatTsla
##Question: Collinearity in Elastic Net regression
set.seed(1989)
YtslaNN = YtslaPenalty %>% mutate(YtslaDummy)
trainIndex = caret::createDataPartition(YtslaNN$diffHighLowTomorrow, p = 0.25, list = FALSE)
YtslaTrain_DiffHighLow      = YtslaNN$diffHighLowTomorrow[trainIndex]
YtslaTrain_StockReturn      = YtslaNN$stockReturnTomorrow[trainIndex]
YtslaTrain_StockReturnDummy = YtslaNN$stockReturnTomorrowDummy[trainIndex]
YtslaTest_DiffHighLow       = YtslaNN$diffHighLowTomorrow[-trainIndex]
YtslaTest_StockReturn       = YtslaNN$stockReturnTomorrow[-trainIndex]
YtslaTest_StockReturnDummy  = YtslaNN$stockReturnTomorrowDummy [-trainIndex]
#Standardize quantitative features before fitting neural networks because NN is scale dependent.
XtslaNN = tslaLogReg %>%
select(-c(aboveR1.Yes,aboveR2.Yes,aboveR3.Yes,belowS1.Yes,belowS2.Yes,belowS3.Yes,diffHighLowTomorrow,stockReturnTomorrow,stockReturnTomorrowDummy))
XtslaNNScaledFit = caret::preProcess(XtslaNN,method = c("center","scale"))
XtslaNNScaled    = predict(XtslaNNScaledFit,XtslaNN)
XtslaTrain = XtslaNNScaled[trainIndex,]
XtslaTest  = XtslaNNScaled[-trainIndex,]
summary(XtslaNNScaled)
ncol(XtslaTrain)
tslaNNFit = keras::keras_model_sequential() %>%
keras::layer_flatten(input_shape = [41,1]) %>%
?layer_flatten()
tslaNNFit = keras::keras_model_sequential() %>%
keras::layer_flatten() %>%
keras::layer_dense(units = 16,activation = "relu", name = "L1") %>%
keras::layer_dense(units = 16,activation = "relu", name = "L2") %>%
keras::layer_dense(units = 2, activation = "softmax", name = "output")
n
save.image("D:/Mia/STAT/656/self-project/backup/working environment - backup16.RData")
