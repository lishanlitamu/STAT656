highCorrGoog
corrplot::corrplot(cor(googSelected), order="hclust")
###TSLA
tslaTemp = tslaSelected %>%
dplyr::mutate(
PP = lag((PX_HIGH + PX_LOW + PX_LAST)/3), #Previous Day (High + Low + Close) / 3
R1 = 2 * PP - lag(PX_LOW),                #(Pivot x 2) – Previous Day Low
S1 = 2 * PP - lag(PX_HIGH),               #(Pivot x 2) – Previous Day High
R2 = PP + (R1 - S1),                      #Pivot + (R1 – S1)
S2 = PP - (R1 - S1),                      #Pivot - (R1 – S1)
R3 = lag(PX_HIGH) + 2 * (PP - lag(PX_LOW)),
#R3= Previous Day High + 2(PP – Previous Day Low)
S3 = lag(PX_LOW) - 2 * (lag(PX_HIGH) - PP),
#S3= Previous Day Low – 2(Previous Day High – Pivot)
diffHighLow  = PX_HIGH - PX_LOW,
diffLastOpen = PX_LAST - PX_OPEN,
stockReturn  = (PX_LAST - PX_OPEN)/PX_OPEN
)
highCorrF = function(dta, thred){
#Find highly correlated features
highCorr = dta %>%
cor %>%
caret::findCorrelation(thred, names = TRUE)
return(highCorr)
}
hclustPlotF = function(dta) {
#Correlation Plot
corrplot::corrplot(cor(dta), order="hclust")
}
###GOOG
tslaAddOBV = tslaTemp %>%
mutate(obv = TTR::OBV(PX_LAST, PX_VOLUME))
#TSLA
daysCMF = 21
tslaAddCMF = tslaAddOBV %>%
mutate(cmf = TTR::CMF(tslaAddOBV[,c("PX_HIGH","PX_LOW","PX_LAST")], PX_VOLUME, n = daysCMF))
#GOOG
#TSLA
daysEMA = 10 #EMA lengths
tslaAddEMA = tslaAddCMF %>%
mutate(emaPrice = TTR::EMA(tslaAddCMF$PX_LAST,daysEMA)) %>%
mutate(emaVolume = TTR::EMA(tslaAddCMF$PX_VOLUME,daysEMA))
###GOOG
###Tsla
daysRSI = 14
tslaAddRSI = tslaAddEMA %>%
mutate(rsi = TTR::RSI(PX_LAST, n=daysRSI, maType="WMA", wts=PX_VOLUME))
###GOOG
###Tsla
daysSMA = 10
tslaAddSMA = tslaAddRSI %>%
mutate(smaPrice = TTR::SMA(PX_LAST, n=daysSMA)) %>%
mutate(smaVolume = TTR::SMA(PX_VOLUME, n=daysSMA))
###GOOG
###Tsla
#Stochastic Momentum Index
daysK = 5 #%K is usually set to 5 and represents the main movements of price – slow line.
daysD = 3 #%D is the fast line, a simple moving average of the %K and is set to 3.
tslaHLC  = tslaSelected %>% dplyr::select(PX_HIGH, PX_LOW, PX_LAST)
tslaAddK = tslaAddSMA %>%
dplyr::mutate(smi_K = (stoch(tslaHLC, nFastK = daysK, nFastD = daysD, nSlowD = 3, bounded = TRUE,smooth = 1))[,1]) %>% #calculate fastK%
dplyr::mutate(smi_D = (stoch(tslaHLC, nFastK = daysK, nFastD = daysD, nSlowD = 3, bounded = TRUE,smooth = 1))[,2])  #calculate fastD%
#bounded:Logical, should current period’s values be used in the calculation? Set it as TRUE here. We will align Y's with past X's in Section xxx.
#Reference:https://library.tradingtechnologies.com/trade/chrt-ti-stochastic-momentum-index.html
###GOOG
daysMACDslow   = 26 #default nSlow
daysMACDfast   = 12 #default nFast
daysMACDsignal = 9  #default nSig
tslaAddMACD = tslaAddK %>%
mutate(macdPrice = (TTR::MACD(PX_LAST, nFast = daysMACDfast, nSlow = daysMACDslow, nSig = daysMACDsignal))[,1]) %>%
#mutate(macdPrice = TTR::MACD(nFast = 12, nSlow = 26, nSig = 9, maType="WMA", wts=PX_VOLUME)) %>% # weighted macdPrice
mutate(macdVolume = (TTR::MACD(PX_VOLUME, nFast = daysMACDfast, nSlow = daysMACDslow, nSig = daysMACDsignal))[,1])
daysR = 14 #default
#tslaHLC  = tslaSelected %>% dplyr::select(PX_HIGH, PX_LOW, PX_LAST)
tslaAddR = tslaAddMACD %>%
mutate(larryWilliamsR = TTR::WPR(tslaHLC, n = daysR))
tslaAddAD = tslaAddR %>%
mutate(williamsAD = TTR::williamsAD(tslaHLC))
daysCCI = 20
tslaAddCCI = tslaAddAD %>%
mutate(cci = TTR::CCI(tslaHLC, n = daysCCI))
#--End--#
#Summarize how many indicators we've added.
beforeAfterVar = tslaAddCCI[,(ncol(tslaSelected)+1):ncol(tslaAddCCI)]
names(beforeAfterVar)
tslaY  = tslaAddCCI %>%
na.omit() %>%
dplyr::select(diffHighLow, stockReturn) %>%
dplyr::as_tibble() %>%
dplyr::slice(-1)
tslaX    = tslaAddCCI %>%
na.omit() %>%
.[1:(nrow(.)-1),] %>%
dplyr::as_tibble(.)
names(tslaY)[1] = "diffHighLowTomorrow" #Y1
names(tslaY)[2] = "stockReturnTomorrow" #Y2
tslaFull = dplyr::as_tibble(cbind(tslaY,tslaX))
hclustPlotF(tslaX)
#It's suggested to use only quantitative variables in PCA regression
#Transform the selected data
(tslaXTrans = caret::preProcess(as.data.frame(tslaX), method = c("BoxCox","center","scale","pca")))
#Apply the transformations("BoxCox","center","scale","pca")
pcaTslaX = stats::predict(tslaXTrans,as.data.frame(tslaX)) #Outputs are PCA components
#head(pcaTslaX)
#Summary of PCA results
tslaXTrans_     = caret::preProcess(as.data.frame(tslaX), method = c("BoxCox","center","scale"))
propVar_pcaTslaX = as.data.frame(tslaX) %>%
stats::predict(tslaXTrans_,.) %>%
stats::prcomp() %>%
summary()
propVar_pcaTslaX #proportion of variance explained by each PCs
#Check extreme observations via PCA
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC1, y= PC2))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC3, y= PC2))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC1, y= PC3))
plot3D::scatter3D(pcaTslaX$PC1, pcaTslaX$PC2, pcaTslaX$PC3, pch = 16,
theta = 20, phi = 20, main = "PCA - Tesla", xlab = "PC1",
ylab ="PC2", zlab = "PC3", bty = "g", ticktype = "detailed")
#diffHighLow vs PCs
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC1, y=tslaY$diffHighLowTomorrow), color=ifelse(tslaY$diffHighLowTomorrow > mean(tslaY$diffHighLowTomorrow),"red", "blue"))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC1, y=tslaY$diffHighLowTomorrow)
, color=ifelse(tslaX$diffHighLow > mean(tslaX$diffHighLow),"red", "blue"))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC1, y=tslaY$diffHighLowTomorrow)
, color=ifelse(tslaX$stockReturn > mean(tslaX$stockReturn),"red", "blue"))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC2, y=tslaY$diffHighLowTomorrow), color=ifelse(tslaY$diffHighLowTomorrow > mean(tslaY$diffHighLowTomorrow),"red", "blue"))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC2, y=tslaY$diffHighLowTomorrow)
, color=ifelse(tslaX$diffHighLow > mean(tslaX$diffHighLow),"red", "blue"))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC2, y=tslaY$diffHighLowTomorrow)
, color=ifelse(tslaX$stockReturn > mean(tslaX$stockReturn),"red", "blue"))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC3, y=tslaY$diffHighLowTomorrow)
, color=ifelse(tslaY$diffHighLowTomorrow > mean(tslaY$diffHighLowTomorrow),"red", "blue"))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC3, y=tslaY$diffHighLowTomorrow)
, color=ifelse(tslaX$diffHighLow > mean(tslaX$diffHighLow),"red", "blue"))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC3, y=tslaY$diffHighLowTomorrow)
, color=ifelse(tslaX$stockReturn > mean(tslaX$stockReturn),"red", "blue"))
scatterplot3d::scatterplot3d(x = pcaTslaX$PC1, y = pcaTslaX$PC2,
z = tslaY$diffHighLowTomorrow, pch = 16, color = ifelse(tslaY$diffHighLowTomorrow > mean(tslaY$diffHighLowTomorrow),"red", "blue"))
#stockReturn vs PCs
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC1, y=tslaY$stockReturnTomorrow), color=ifelse(tslaX$stockReturn > mean(tslaX$stockReturn),"red", "blue"))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC1, y=tslaY$stockReturnTomorrow), color=ifelse(tslaX$diffHighLow > mean(tslaX$diffHighLow),"red", "blue"))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC1, y=tslaY$stockReturnTomorrow), color=ifelse(tslaX$stockReturn > mean(tslaX$stockReturn),"red", "blue"))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC2, y=tslaY$stockReturnTomorrow))
ggplot(data = pcaTslaX)+
geom_point(aes(x = PC3, y=tslaY$stockReturnTomorrow))
#hist(tslaReg$stockReturn, breaks=20, freq=FALSE,main = paste("Density Plot - ",names(tslaReg$stockReturn)),xlab = " ") # stock return is normally distributed.
XtslaAddLevels = tslaFull %>%
mutate(aboveR1 = factor(ifelse(PX_HIGH > R1, "Yes", "No"))) %>%
mutate(aboveR2 = factor(ifelse(PX_HIGH > R2, "Yes", "No"))) %>%
mutate(aboveR3 = factor(ifelse(PX_HIGH > R3, "Yes", "No"))) %>%
mutate(belowS1 = factor(ifelse(PX_LOW  < S1, "Yes", "No"))) %>%
mutate(belowS2 = factor(ifelse(PX_LOW  < S2, "Yes", "No"))) %>%
mutate(belowS3 = factor(ifelse(PX_LOW  < S3, "Yes", "No"))) %>%
select(aboveR1, aboveR2, aboveR3, belowS1, belowS2, belowS3)
XtslaDummyModel = caret::dummyVars(~ ., data = XtslaAddLevels, fullRank = TRUE)
YtslaAddLevels = as_tibble(factor(ifelse(tslaY$stockReturnTomorrow > 0, "Increased", "Decreased")))
YtslaDummyModel = caret::dummyVars(~ ., data = YtslaAddLevels, fullRank = TRUE)
XtslaDummy = as_tibble(predict(XtslaDummyModel, XtslaAddLevels))
YtslaDummy = as_tibble(predict(YtslaDummyModel, YtslaAddLevels))
names(YtslaDummy)[1] = "stockReturnTomorrowDummy" #Y2
tslaLogReg = tslaFull %>%
mutate(XtslaDummy) %>%
dplyr::select(-R1,-S1,-R2,-S2,-R3,-S3) %>%
#Drop PP, R1, R2, R3, S1, S2, S3
mutate(YtslaDummy)
#First, correct skewness
tslaXyeoJ = tslaX %>%
caret::preProcess(method = "YeoJohnson") %>%
predict(newdata = tslaX)
#hist(tslaY$diffHighLowTomorrow)
#hist(tslaY$stockReturnTomorrow)
tslaYyeoJ = tslaY %>%
caret::preProcess(method = "YeoJohnson") %>%
predict(newdata = tslaY)
#hist(tslaYyeoJ$diffHighLowTomorrow)
#hist(tslaYyeoJ$stockReturnTomorrow)
Ktsla = 10
cvIndexTsla = caret::createFolds(tslaYyeoJ$diffHighLowTomorrow, k = Ktsla, returnTrain = TRUE)
trControl = trainControl(method = "cv", index = cvIndexTsla)
XtslaPenalty = tslaXyeoJ %>%
caret::preProcess(method = c("center","scale")) %>%
predict(tslaXyeoJ) %>%
cbind(.,XtslaDummy) %>%
dplyr::select(-R1,-S1,-R2,-S2,-R3,-S3)
YtslaPenalty = tslaYyeoJ %>%
caret::preProcess(method = c("center","scale")) %>%
predict(newdata = tslaYyeoJ)
lmOutTsla = train(x = XtslaPenalty, y = YtslaPenalty$diffHighLowTomorrow, method = "lm", trControl = trControl)
lmOutTsla
#Errors in ridge and lasso regression are solved by removing highly correlated features in XtslaPenalty
highCorrTsla = XtslaPenalty %>% highCorrF(.,0.8) %>%
.[-c(25,27)] %>%
c(.,c("macdPrice","macdVolume"))
XtslaRegRemoveCorr = XtslaPenalty %>% select(-highCorrTsla)
names(XtslaPenalty)
names(XtslaLogRegRemoveCorr)
#ridge regression
ridgeOutTsla = train(x = XtslaRegRemoveCorr, y = YtslaPenalty$diffHighLowTomorrow, method = "ridge", tuneLength = 10,trControl = trControl)
ridgeOutTsla
ridgeOutTsla = train(x = XtslaPenalty, y = YtslaPenalty$diffHighLowTomorrow, method = "ridge", tuneLength = 10,trControl = trControl)
#lasso regression
lassoOutTsla = train(x = XtslaRegRemoveCorr, y = YtslaPenalty$diffHighLowTomorrow, method = "lasso", tuneLength = 10,trControl = trControl)
lassoOutTsla
#elastic net
gridLambdaAlpha = expand.grid(lambda = seq(1e-6, 0.05, length = 15), alpha = c(0,0.25,.5,.75,1))
enetOutTsla = train(x = XtslaPenalty, y = YtslaPenalty$diffHighLowTomorrow,
method = "glmnet", tuneGrid = gridLambdaAlpha, trControl = trControl)
enetOutTsla
plot(enetOutTsla, xlab = "Lambda (Elastic Net Penalty)", ylab = "RMSE (K-fold CV)" )
#Results of penalized linear model
names(enetOutTsla$finalModel)
alphaHatTsla  = enetOutTsla$finalModel$tuneValue$alpha
lambdaHatTsla = enetOutTsla$finalModel$tuneValue$lambda
glmnetOutTsla = glmnet::glmnet(x = as.matrix(XtslaPenalty), y = YtslaPenalty$diffHighLowTomorrow, alpha = alphaHatTsla, standardize = FALSE)
betaHatTsla = coef(glmnetOutTsla, s = lambdaHatTsla)
betaHatTsla
##Question: Collinearity in Elastic Net regression
set.seed(1989)
YtslaNN = YtslaPenalty %>% mutate(YtslaDummy)
trainIndex = caret::createDataPartition(YtslaNN$diffHighLowTomorrow, p = 0.25, list = FALSE)
YtslaTrain_DiffHighLow      = YtslaNN$diffHighLowTomorrow[trainIndex]
YtslaTrain_StockReturn      = YtslaNN$stockReturnTomorrow[trainIndex]
YtslaTrain_StockReturnDummy = YtslaNN$stockReturnTomorrowDummy[trainIndex]
YtslaTest_DiffHighLow       = YtslaNN$diffHighLowTomorrow[-trainIndex]
YtslaTest_StockReturn       = YtslaNN$stockReturnTomorrow[-trainIndex]
YtslaTest_StockReturnDummy  = YtslaNN$stockReturnTomorrowDummy [-trainIndex]
#Standardize quantitative features before fitting neural networks because NN is scale dependent.
XtslaNN = tslaLogReg %>%
select(-c(aboveR1.Yes,aboveR2.Yes,aboveR3.Yes,belowS1.Yes,belowS2.Yes,belowS3.Yes,diffHighLowTomorrow,stockReturnTomorrow,stockReturnTomorrowDummy))
XtslaNNScaledFit = caret::preProcess(XtslaNN,method = c("center","scale"))
XtslaNNScaled    = predict(XtslaNNScaledFit,XtslaNN)
XtslaTrain = XtslaNNScaled[trainIndex,]
XtslaTest  = XtslaNNScaled[-trainIndex,]
summary(XtslaNNScaled)
ncol(XtslaTrain)
tslaNNFit = keras::keras_model_sequential() %>%
keras::layer_flatten(input_shape = [41,1]) %>%
?layer_flatten()
tslaNNFit = keras::keras_model_sequential() %>%
keras::layer_flatten() %>%
keras::layer_dense(units = 16,activation = "relu", name = "L1") %>%
keras::layer_dense(units = 16,activation = "relu", name = "L2") %>%
keras::layer_dense(units = 2, activation = "softmax", name = "output")
n
save.image("D:/Mia/STAT/656/self-project/backup/working environment - backup16.RData")
load("D:/Mia/STAT/656/self-project/backup/working environment - backup16.RData")
## Load libraries
library(bit64) # To read raw data
library(caret)
library(corrplot)
library(data.table) # Faster CSV reader than base
library(dplyr)
library(e1071)
library(ggplot2) # General plotting
library(newsanchor) # News API scrape
library(readxl)
library(rtweet) # Twitter scrape
library(rvest)
library(stringr) # Goggle news scrape
library(tau)
library(textdata)
library(plot3D)   #PCs plot
library(RcppRoll) #CMF
library(TTR)      #Calculate Indicators: EMA,SMA,RSI
library(leaps)    #Stepwise Model Selection
library(zoo)      # Interpolation
library(elasticnet) #ridge, lasso, elastic net regression
library(keras)    #Neural Networks
knitr::opts_chunk$set(echo = T)
install.packages("tensorflow")
library(tensorflow)
load("D:/Mia/STAT/656/self-project/backup/working environment - backup16.RData")
tslaNNFit = keras::keras_model_sequential() %>%
keras::layer_flatten() %>%
keras::layer_dense(units = 16,activation = "relu", name = "L1") %>%
keras::layer_dense(units = 16,activation = "relu", name = "L2") %>%
keras::layer_dense(units = 2, activation = "softmax", name = "output")
## Load libraries
library(bit64) # To read raw data
library(caret)
library(corrplot)
library(data.table) # Faster CSV reader than base
library(dplyr)
library(e1071)
library(ggplot2) # General plotting
library(newsanchor) # News API scrape
library(readxl)
library(rtweet) # Twitter scrape
library(rvest)
library(stringr) # Goggle news scrape
library(tau)
library(textdata)
library(plot3D)   #PCs plot
library(RcppRoll) #CMF
library(TTR)      #Calculate Indicators: EMA,SMA,RSI
library(leaps)    #Stepwise Model Selection
library(zoo)      # Interpolation
library(elasticnet) #ridge, lasso, elastic net regression
library(keras)    #Neural Networks
library(tensorflow)
knitr::opts_chunk$set(echo = T)
ncol(XtslaTrain)
tslaNNFit = keras::keras_model_sequential() %>%
keras::layer_flatten() %>%
keras::layer_dense(units = 16,activation = "relu", name = "L1") %>%
keras::layer_dense(units = 16,activation = "relu", name = "L2") %>%
keras::layer_dense(units = 2, activation = "softmax", name = "output")
tslaNNFit = keras::keras_model_sequential() %>%
conv_base %>%
layer_flatten() %>%
keras::layer_dense(units = 16,activation = "relu", name = "L1") %>%
keras::layer_dense(units = 16,activation = "relu", name = "L2") %>%
keras::layer_dense(units = 2, activation = "softmax", name = "output")
devtools::install_github("rstudio/tensorflow")
devtools::install_github("rstudio/keras")
install.packages("Rtools")
no
save.image("D:/Mia/STAT/656/self-project/backup/working environment - backup17.RData")
load("D:/Mia/STAT/656/self-project/backup/working environment - backup17.RData")
## Load libraries
library(bit64) # To read raw data
library(caret)
library(corrplot)
library(data.table) # Faster CSV reader than base
library(dplyr)
library(e1071)
library(ggplot2) # General plotting
library(newsanchor) # News API scrape
library(readxl)
library(rtweet) # Twitter scrape
library(rvest)
library(stringr) # Goggle news scrape
library(tau)
library(textdata)
library(plot3D)   #PCs plot
library(RcppRoll) #CMF
library(TTR)      #Calculate Indicators: EMA,SMA,RSI
library(leaps)    #Stepwise Model Selection
library(zoo)      # Interpolation
library(elasticnet) #ridge, lasso, elastic net regression
library(keras)    #Neural Networks
library(tensorflow)
knitr::opts_chunk$set(echo = T)
devtools::install_github("rstudio/tensorflow")
install.packages("devtools")
install.packages("devtools")
load("D:/Mia/STAT/656/self-project/backup/working environment - backup17.RData")
install.packages("devtools")
install.packages("devtools")
devtools::install_github("rstudio/tensorflow")
devtools::install_github("rstudio/tensorflow")
library(devtools)
install.packages("usethis")
library(devtools)
library(tensorflow)
tensorflow::install_tensorflow()
library(keras)
ncol(XtslaTrain)
tslaNNFit = keras::keras_model_sequential() %>%
keras::layer_flatten() %>%
keras::layer_dense(units = 16,activation = "relu", name = "L1") %>%
keras::layer_dense(units = 16,activation = "relu", name = "L2") %>%
keras::layer_dense(units = 2, activation = "softmax", name = "output")
devtools::install_github("rstudio/tensorflow")
devtools::install_github("rstudio/keras")
install.packages("tensorflow")
tslaNNFit = keras::keras_model_sequential() %>%
XtslaNNScaled %>%
layer_flatten() %>%
keras::layer_dense(units = 16,activation = "relu", name = "L1") %>%
keras::layer_dense(units = 16,activation = "relu", name = "L2") %>%
keras::layer_dense(units = 2, activation = "softmax", name = "output")
devtools::install_github("rstudio/tensorflow")
unlist()
unlist(.)
library(bit64) # To read raw data
library(caret)
library(corrplot)
library(data.table) # Faster CSV reader than base
library(dplyr)
library(e1071)
library(ggplot2) # General plotting
library(newsanchor) # News API scrape
library(readxl)
library(rtweet) # Twitter scrape
library(rvest)
library(stringr) # Goggle news scrape
library(tau)
library(textdata)
library(plot3D)   #PCs plot
library(RcppRoll) #CMF
library(TTR)      #Calculate Indicators: EMA,SMA,RSI
library(leaps)    #Stepwise Model Selection
library(zoo)      # Interpolation
library(elasticnet)
devtools::install_github("rstudio/tensorflow")
## Load libraries
library(bit64) # To read raw data
library(caret)
library(corrplot)
library(data.table) # Faster CSV reader than base
library(dplyr)
library(e1071)
library(ggplot2) # General plotting
library(newsanchor) # News API scrape
library(readxl)
library(rtweet) # Twitter scrape
library(rvest)
library(stringr) # Goggle news scrape
library(tau)
library(textdata)
library(plot3D)   #PCs plot
library(RcppRoll) #CMF
library(TTR)      #Calculate Indicators: EMA,SMA,RSI
library(leaps)    #Stepwise Model Selection
library(zoo)      # Interpolation
library(elasticnet) #ridge, lasso, elastic net regression
#library(keras)    #Neural Networks
#library(tensorflow)
knitr::opts_chunk$set(echo = T)
devtools::install_github("rstudio/tensorflow")
library(tensorflow)
tensorflow::install_tensorflow()
install.packages("reticulate")
reticulate::conda_create("my-environment")
reticulate::use_condaenv("my-environment", required = TRUE)
install_tensorflow()
tensorflow::install_tensorflow()
ncol(XtslaTrain)
tslaNNFit = keras::keras_model_sequential() %>%
keras::layer_flatten() %>%
keras::layer_dense(units = 16,activation = "relu", name = "L1") %>%
keras::layer_dense(units = 16,activation = "relu", name = "L2") %>%
keras::layer_dense(units = 2, activation = "softmax", name = "output")
## Load libraries
library(bit64) # To read raw data
library(caret)
library(corrplot)
library(data.table) # Faster CSV reader than base
library(dplyr)
library(e1071)
library(ggplot2) # General plotting
library(newsanchor) # News API scrape
library(readxl)
library(rtweet) # Twitter scrape
library(rvest)
library(stringr) # Goggle news scrape
library(tau)
library(textdata)
library(plot3D)   #PCs plot
library(RcppRoll) #CMF
library(TTR)      #Calculate Indicators: EMA,SMA,RSI
library(leaps)    #Stepwise Model Selection
library(zoo)      # Interpolation
library(elasticnet) #ridge, lasso, elastic net regression
#library(keras)    #Neural Networks
#library(tensorflow)
knitr::opts_chunk$set(echo = T)
tslaNNFit = keras::keras_model_sequential() %>%
keras::layer_flatten() %>%
keras::layer_dense(units = 16,activation = "relu", name = "L1") %>%
keras::layer_dense(units = 16,activation = "relu", name = "L2") %>%
keras::layer_dense(units = 2, activation = "softmax", name = "output")
tslaNNFit = keras::keras_model_sequential() %>%
keras::layer_flatten() %>%
keras::layer_dense(units = 16,activation = "relu", name = "L1") %>%
keras::layer_dense(units = 16,activation = "relu", name = "L2") %>%
keras::layer_dense(units = 2, activation = "softmax", name = "output")
tensorflow::install_tensorflow()
install.packages("keras")
keras::install_keras()
require(reticulate)
reticulate::use_python("D:/Programs/anaconda3/python.exe", required = TRUE)
reticulate::use_condaenv("D:/Programs/anaconda3")
keras::install_keras()
keras::install_keras()
remove.packages("keras")
remove.packages("tensorflow")
devtools::install_github("rstudio/keras", type = "source", dependencies = TRUE)
devtools::install_github("rstudio/tensorflow", type = "source", dependencies = TRUE)
remove.packages("keras")
remove.packages("tensorflow")
require(reticulate)
reticulate::use_python("D:/Programs/anaconda3/python.exe", required = TRUE)
reticulate::use_condaenv("D:/Programs/anaconda3")
reticulate::py_config()
devtools::install_github("rstudio/keras", type = "source", dependencies = TRUE)
reticulate::use_python("D:/Programs/anaconda3/python.exe", required = TRUE)
reticulate::use_condaenv("D:/Programs/anaconda3")
reticulate::py_config()
reticulate::use_python("D:/Programs/anaconda3/python.exe", required = TRUE)
reticulate::use_condaenv("D:/Programs/anaconda3")
remove.packages("keras")
remove.packages("tensorflow")
remove.packages("reticulate")
devtools::install_github("rstudio/keras", type = "source", dependencies = TRUE)
devtools::install_github("rstudio/tensorflow", type = "source", dependencies = TRUE)
