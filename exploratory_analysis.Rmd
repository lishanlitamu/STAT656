---
title: "Exploratory Analysis"
author: "Kyle Dixon, Mia Li, Caitlin Hennessey"
date: "9/4/2020"
output: html_document
---

## Project Topic: 
## Analyzing the impact of news and social media sentiment on stock prices.

### 1 - General review of raw data 
#### 1.1 Load and clean data
```{r initialize, include = F}
## Load libraries
library(bit64)
library(caret)
library(corrplot)
library(e1071)
library(data.table)
library(dplyr)
library(ggplot2)
library(rvest)
library(stringr)

knitr::opts_chunk$set(echo = T)
```

```{r clean_data}
## Load raw data into the global environment
tsla <- base::data.frame(data.table::fread("1 - Data/Tesla/tsla.csv", na.strings = c("#N/A N/A", "#N/A Invalid Field", "#N/A Requesting Data...")), stringsAsFactors = F)
goog <- base::data.frame(data.table::fread("1 - Data/Google/goog.csv", na.strings = c("#N/A N/A", "#N/A Invalid Field", "#N/A Requesting Data...")), stringsAsFactors = F)

## Clean raw data
tsla <- tsla %>% dplyr::select_if(~sum(!is.na(.)) > 0) %>% # Drop columns that contain only NAs
  dplyr::filter(!is.na(PX_LAST)) # Drop rows where PX_LAST is NA
goog <- goog %>% dplyr::select_if(~sum(!is.na(.)) > 0) %>% # Drop columns that contain only NAs
  dplyr::filter(!is.na(PX_LAST)) # Drop rows where PX_LAST is NA

## Format date columns
tsla$Date <- as.Date(tsla$Date, "%m/%d/%Y")
goog$Date <- as.Date(goog$Date, "%m/%d/%Y")
```

#### 1.2 Visualize data
```{r plot_data}
## Plot prices versus time
tsla_plot <- ggplot2::ggplot() + 
  ggplot2::geom_line(data = tsla, ggplot2::aes(x = Date, y = PX_LAST)) + ggplot2::ggtitle("TSLA")
goog_plot <- ggplot2::ggplot() + 
  ggplot2::geom_line(data = goog, ggplot2::aes(x = Date, y = PX_LAST)) + ggplot2::ggtitle("GOOG") + 
  ggplot2::scale_x_date(limits = c(base::min(tsla$Date), base::max(tsla$Date))) # Align the x-axis with TSLA
gridExtra::grid.arrange(tsla_plot, goog_plot)
```

### 2 - Data Preprocessing
#### 2.1 Count the number of Missing Values in each feature

```{r numNA, warning=FALSE}
require(dplyr)
totalRowTsla = base::nrow(tsla)
totalColTsla = base::ncol(tsla)

naTsla       = tsla %>%
               base::sapply(.,function(y) base::sum(base::length(base::which(base::is.na(y))))) %>%
               base::as.data.frame() %>%
               tibble::rownames_to_column(., "Features")
              

totalRowGoog = base::nrow(goog)
totalColGoog = base::ncol(goog)

naGoog       = goog %>%
               base::sapply(.,function(y) base::sum(base::length(base::which(base::is.na(y))))) %>%
               base::as.data.frame() %>%
               tibble::rownames_to_column(., "Features")
```

>__Tesla__

Total number of rows: `r totalRowTsla`

Total number of columns: `r totalColTsla`


```{r naTslaKnit, echo=FALSE}

knitr::kable(
 naTsla,
 col.names = c("Features","Number of Missing Values"),
 caption   = "Table 2-1: The number of Missing Values - Tesla",
 align     = "lccrr"
)
```

>__Google__

Total number of rows: `r totalRowGoog`

Total number of columns: `r totalColGoog`


```{r naGoogKnit, echo=FALSE}
knitr::kable(
 naGoog,
 col.names = c("Features","Number of Missing Values"),
 caption   = "Table 2-2: The number of Missing Values - Google",
 align     = "lccrr"
)
```


#### 2.2 Data Transformation 

##### 2.2.1 Data Filtering - Tesla
Features with less than 100 missing values will be included by deleting corresponding rows with missing values instead.
```{r filterTsla, warning=FALSE}
#Select a subset of original data for data transformation and PCA
tslaSelected = tsla %>%
  .[,(base::which(naTsla[,2] < 100))] %>%
  .[!(base::apply(.,1, function(y){any(is.na(y))})),] %>%
  .[,-1] #remove dates in the first column

#Apply Log-transformation on tslaSelected$TURNOVER to avoid producing NaN in skewness computation
tslaSelected$TURNOVER = base::log(tslaSelected$TURNOVER)
base::names(tslaSelected) [6]= "log(TURNOVER)"
```

##### 2.2.2 Calculate Skewness and Kurtosis - Tesla
```{r skewnessTsla, warning=FALSE}
require(e1071)
skewnessTsla = base::apply(tslaSelected,2,e1071::skewness)
kurtosisTsla   = base::apply(tslaSelected,2,e1071::kurtosis)
```

```{r skewnessTslaTable, warning=FALSE, echo=FALSE}
skewnessTsla = skewnessTsla %>%
               base::as.data.frame() %>%
               tibble::rownames_to_column(., "features")

knitr::kable(
 skewnessTsla,
 col.names = c("Features","Skewness"),
 caption   = "Table 2-3: Skewness of Selected Features - Tesla",
 align     = "lccrr"
)

kurtosisTsla = kurtosisTsla %>%
               base::as.data.frame() %>%
               tibble::rownames_to_column(., "features")

knitr::kable(
 kurtosisTsla,
 col.names = c("Features","Kurtosis"),
 caption   = "Table 2-4: Kurtosis of Selected Features - Tesla",
 align     = "lccrr"
)
```

##### 2.2.3 Data Transformation - Tesla
```{r dataTransTsla, warning=FALSE}
#Transform the selected data
(tslaTrans = caret::preProcess(tslaSelected, method = c("BoxCox","center","scale","pca")))

#Apply the transformations("BoxCox","center","scale","pca")
tslaPCA = stats::predict(tslaTrans,tslaSelected) #Outputs are PCA components
utils::head(tslaPCA)

#Summary of PCA results
tslaTrans_     = caret::preProcess(tslaSelected, method = c("BoxCox","center","scale"))
propVarTslaPCA = tslaSelected %>%
                 stats::predict(tslaTrans_,.) %>%
                 stats::prcomp() %>%
                 base::summary()
propVarTslaPCA #proportion of variance explained by each PCs
```

#
#### Fig. 2.1 Density Plots  - Tesla
```{r dataPlotsTsla, echo=FALSE}
transformedTsla = predict(tslaTrans_,tslaSelected)
par(mfrow=c(2,2))
for (i in 1:base::ncol(tslaSelected)) {
  hist(tslaSelected[,i], breaks=20, freq=FALSE, 
       main = base::paste("Density Plot - ",names(tslaSelected)[i],                            "(Before)"),xlab = " ")
  hist(transformedTsla[,i], breaks=20, freq=FALSE, 
       main = base::paste("Density Plot - ",names(transformedTsla)[i],
                          "(After)"),xlab = " ")
}
```



##### 2.2.4 Data Filtering - Google
Features with less than 100 missing values will be included by deleting corresponding rows with missing values instead.
```{r filterGoog, warning=FALSE}
#Select a subset of original data for data transformation and PCA
googSelected = goog %>%
  .[,(base::which(naGoog[,2] < 100))] %>%
  .[!(base::apply(.,1, function(y){any(is.na(y))})),] %>%
  .[,-1] #remove dates in the first column

#Apply Log-transformation on googSelected$TURNOVER
googSelected$TURNOVER = base::log(googSelected$TURNOVER)
base::names(googSelected) [6]= "log(TURNOVER)"
```


##### 2.2.5 Calculate Skewness and Kurtosis - Google
```{r skewnessGoog, warning=FALSE}
#require(e1071)
skewnessGoog = base::apply(googSelected,2,e1071::skewness)
kurtosisGoog = base::apply(googSelected,2,e1071::kurtosis)
```

```{r skewnessGoogTable, warning=FALSE, echo=FALSE}
skewnessGoog = skewnessGoog%>%
               base::as.data.frame() %>%
               tibble::rownames_to_column(., "features")

knitr::kable(
 skewnessGoog,
 col.names = c("Features","Skewness"),
 caption   = "Table 2-5: Skewness of Selected Features - Google",
 align     = "lccrr"
)


kurtosisGoog = kurtosisGoog %>%
               base::as.data.frame() %>%
               tibble::rownames_to_column(., "features")

knitr::kable(
 kurtosisGoog,
 col.names = c("Features","Kurtosis"),
 caption   = "Table 2-6: Kurtosis of Selected Features - Google",
 align     = "lccrr"
)

```


##### 2.2.6 Data Transformation - Google
```{r dataTransGoog, warning=FALSE}
#Transform the selected data
(googTrans = caret::preProcess(googSelected, method = c("BoxCox","center","scale","pca")))

#Apply the transformations("BoxCox","center","scale","pca")
googPCA = stats::predict(googTrans,googSelected) #Outputs are PCA components
utils::head(googPCA)

#Summary of PCA results
(googTrans_    = caret::preProcess(googSelected, method = c("BoxCox","center","scale")))
propVarGoogPCA = googSelected %>%
                 stats::predict(googTrans_,.) %>%
                 stats::prcomp() %>%
                 base::summary()
propVarGoogPCA #proportion of variance explained by each PCs
```

#
#### Fig. 2.2 Density Plots  - Google
```{r dataPlotsGoog, echo=FALSE}
transGoog = predict(googTrans_,googSelected)
par(mfrow=c(2,2))
for (i in 1:base::ncol(googSelected)) {
  hist(googSelected[,i], breaks=20, freq=FALSE, 
       main = base::paste("Density Plot - ",names(googSelected)[i], "(After)"),
  xlab = " ")
  hist(transGoog[,i], breaks=20, freq=FALSE, 
       main = base::paste("Density Plot - ",names(transGoog)[i], "(Before)"),
  xlab = " ")
}
```



### 2.3 Correlation Analysis 
>__Tesla__

```{r findCorrelationTsla, warning=FALSE}
library(corrplot)
corrTsla     = stats::cor(tslaSelected)
corrplot::corrplot(corrTsla, order="hclust")
```

#### Fig. 2.3 Correlations between features - Tesla

>__Google__

```{r findCorrelationGoog, warning=FALSE}
#library(corrplot)
corrGoog     = stats::cor(googSelected)
corrplot::corrplot(corrGoog, order="hclust")
```

#### Fig. 2.4 Correlations between features - Google

### 3 - News Scraping
```{r news_scrape}
## Define search strings on Google News
tsla_search <- read_html("https://news.google.com/search?q=TSLA%20when%3A10y&hl=en-US&gl=US&ceid=US%3Aen")
goog_search <- read_html("https://news.google.com/search?q=GOOG%20when%3A10y&hl=en-US&gl=US&ceid=US%3Aen")

## Extract headlines
tsla_headlines <- tsla_search %>% 
  rvest::html_nodes("article") %>% rvest::html_text("span") %>%
  stringr::str_split("(?<=[a-z0-9!?\\.])(?=[A-Z])") # Clean strings
tsla_headlines <- base::sapply(tsla_headlines, function(x) x[1]) # Extract only the first elements

goog_headlines <- goog_search %>% 
  rvest::html_nodes("article") %>% rvest::html_text("span") %>%
  stringr::str_split("(?<=[a-z0-9!?\\.])(?=[A-Z])") # Clean strings
goog_headlines <- base::sapply(goog_headlines, function(x) x[1]) # Extract only the first elements

## Extract the time since the headline
tsla_time <- tsla_search %>% rvest::html_nodes("div article div div time") %>% rvest::html_text()
goog_time <- goog_search %>% rvest::html_nodes("div article div div time") %>% rvest::html_text()

## Create data frame
tsla_news <- base::data.frame("Date" = tsla_time, "Headline" = tsla_headlines, stringsAsFactors = F)
goog_news <- base::data.frame("Date" = goog_time, "Headline" = goog_headlines, stringsAsFactors = F)

## Format date columns
for (row in 1:base::nrow(tsla_news)) {
  # If news was hours ago, set date as today
  if (base::grepl("hours ago", tsla_news[row, ]$Date)) {tsla_news[row, ]$Date <- Sys.Date()}
  #
  else if (base::grepl("Yesterday", tsla_news[row, ]$Date)) {tsla_news[row, ]$Date <- Sys.Date() - 1}
  # If news was days ago, set date as today minus the number of days
  else if (base::grepl("days ago", tsla_news[row, ]$Date)) {tsla_news[row, ]$Date <- Sys.Date() - base::as.numeric(base::substr(tsla_news[row, ]$Date, 1, 1))}
  # If news has a date, format it as a date
  else {tsla_news[row, ]$Date <- base::as.Date(paste0(tsla_news[row, ]$Date, " 2020"), "%b %d %Y")}
}
tsla_news$Date <- base::as.Date(base::as.numeric(tsla_news$Date), origin = "1970-01-01")

for (row in 1:base::nrow(goog_news)) {
  # If news was hours ago, set date as today
  if (base::grepl("hours ago", goog_news[row, ]$Date)) {goog_news[row, ]$Date <- Sys.Date()}
  #
  else if (base::grepl("Yesterday", goog_news[row, ]$Date)) {goog_news[row, ]$Date <- Sys.Date() - 1}
  # If news was days ago, set date as today minus the number of days
  else if (base::grepl("days ago", goog_news[row, ]$Date)) {goog_news[row, ]$Date <- Sys.Date() - base::as.numeric(base::substr(goog_news[row, ]$Date, 1, 1))}
  # If news has a date, format it as a date
  else {goog_news[row, ]$Date <- base::as.Date(paste0(goog_news[row, ]$Date, " 2020"), "%b %d %Y")}
}
goog_news$Date <- base::as.Date(base::as.numeric(goog_news$Date), origin = "1970-01-01")
```
