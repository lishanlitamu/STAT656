---
title: "Exploratory Analysis"
author: "Kyle Dixon, Mia Li, Caitlin Hennessey"
date: "9/4/2020"
output: html_document
---

## Project Topic:
## Analyzing the impact of news and social media sentiment on stock prices.

### 1 - General review of raw data
#### 1.1 Load and clean data
```{r initialize, include = F}
## Load libraries
library(bit64) # To read raw data
library(caret)
library(corrplot)
library(data.table) # Faster CSV reader than base
library(doParallel)
library(dplyr)
library(e1071)
library(ggplot2) # General plotting
library(GuardianR) # Guardian API scrape
library(newsanchor) # News API scrape
library(parallel)
library(readxl)
library(rtweet) # Twitter scrape
library(rvest)
library(stringr) # Goggle news scrape
library(tau)
library(textdata)
library(plot3D)   #PCs plot
#library(RcppRoll) #CMF
library(TTR)      #Calculate Indicators: EMA,SMA,RSI
library(leaps)    #Stepwise Model Selection
library(zoo)      # Interpolation
library(elasticnet) #ridge, lasso, elastic net regression
library(earth)    #MARS, multivariate adaptive regression splines
library(mda)
library(vip)      #Variable importance, lecture 27
library(glmnet)   #Elastic net regression
#library(keras)    #Neural Networks
#library(tensorflow)
library(foreach)
library(kknn) #knn regression
library(pROC) #ROC curve
library(rpart) #tree
library(microbenchmark) #randomforest
library(xgboost) #boosting
library(ranger)
library(kernlab)

knitr::opts_chunk$set(echo = T)
```

```{r clean_data}
## Load raw data into the global environment
tsla <- base::data.frame(data.table::fread("1 - Data/Tesla/tsla.csv", na.strings = c("#N/A N/A", "#N/A Invalid Field", "#N/A Requesting Data...")), stringsAsFactors = F)
goog <- base::data.frame(data.table::fread("1 - Data/Google/goog.csv", na.strings = c("#N/A N/A", "#N/A Invalid Field", "#N/A Requesting Data...")), stringsAsFactors = F)

## Clean raw data
tsla <- tsla %>% dplyr::select_if(~sum(!is.na(.)) > 0) %>% # Drop columns that contain only NAs
  dplyr::filter(!is.na(PX_LAST)) # Drop rows where PX_LAST is NA
goog <- goog %>% dplyr::select_if(~sum(!is.na(.)) > 0) %>% # Drop columns that contain only NAs
  dplyr::filter(!is.na(PX_LAST)) # Drop rows where PX_LAST is NA

## Format date columns
tsla$Date <- as.Date(tsla$Date, "%m/%d/%Y")
goog$Date <- as.Date(goog$Date, "%m/%d/%Y")
```

#### 1.2 Visualize data

```{r plot_data}
## Plot prices versus time
tsla_plot <- ggplot2::ggplot() +
  ggplot2::geom_line(data = tsla, ggplot2::aes(x = Date, y = PX_LAST)) + ggplot2::ggtitle("TSLA")
goog_plot <- ggplot2::ggplot() +
  ggplot2::geom_line(data = goog, ggplot2::aes(x = Date, y = PX_LAST)) + ggplot2::ggtitle("GOOG") +
  ggplot2::scale_x_date(limits = c(base::min(tsla$Date), base::max(tsla$Date))) # Align the x-axis with TSLA
gridExtra::grid.arrange(tsla_plot, goog_plot)
```

### 2 - Data Preprocessing (Missingness and Collinearity)
#### 2.1 Data Interpolation

As we have both daily and quarterly updated features aligned in the original data set, quarterly updated features contains mainly missing values. Instead of deleting those features, missing values are interpolated between quarters.   

``` {r interpolation}
## TSLA
## Run linear interpolations
tmp <- zoo::na.approx(tsla[, base::c(14:22, 24:26)])

## Create empty matrix as placeholder for non-interpolated rows
row_diff <- base::nrow(tsla) - base::nrow(tmp)
empty <- base::matrix(base::rep(NA, row_diff * base::ncol(tmp)), nrow = row_diff, ncol = base::ncol(tmp))
base::colnames(empty) <- base::colnames(tmp)  
tmp <- base::rbind(tmp, empty)

## Replace original data with interpolation
tsla[, base::c(14:22, 24:26)] <- tmp

## GOOG
## Run linear interpolations
tmp <- zoo::na.approx(goog[, 11:23])

## Create empty matrix as placeholder for non-interpolated rows
row_diff <- base::nrow(goog) - base::nrow(tmp)
empty <- base::matrix(base::rep(NA, row_diff * base::ncol(tmp)), nrow = row_diff, ncol = base::ncol(tmp))
base::colnames(empty) <- base::colnames(tmp)  
tmp <- base::rbind(tmp, empty)

## Replace original data with interpolation
goog[, 11:23] <- tmp
```

#### 2.2 Count the number of Missing Values in each feature

```{r numNA, warning=FALSE}
require(dplyr)
totalRowTsla = base::nrow(tsla)
totalColTsla = base::ncol(tsla)

naTsla       = tsla %>%
               base::sapply(.,function(y) base::sum(base::length(base::which(base::is.na(y))))) %>%
               base::as.data.frame() %>%
               tibble::rownames_to_column(., "Features")


totalRowGoog = base::nrow(goog)
totalColGoog = base::ncol(goog)

naGoog       = goog %>%
               base::sapply(.,function(y) base::sum(base::length(base::which(base::is.na(y))))) %>%
               base::as.data.frame() %>%
               tibble::rownames_to_column(., "Features")
```

>__Tesla__

Total number of rows: `r totalRowTsla`

Total number of columns: `r totalColTsla`


```{r naTslaKnit, echo=FALSE}
knitr::kable(
 naTsla,
 col.names = c("Features","Number of Missing Values"),
 caption   = "Table 2-1: The number of Missing Values - Tesla",
 align     = "lccrr"
)
```

>__Google__

Total number of rows: `r totalRowGoog`

Total number of columns: `r totalColGoog`


```{r naGoogKnit, echo=FALSE}
knitr::kable(
 naGoog,
 col.names = c("Features","Number of Missing Values"),
 caption   = "Table 2-2: The number of Missing Values - Google",
 align     = "lccrr"
)
```


#### 2.3 Data Transformation

##### 2.3.1 Data Filtering - Tesla
Features with less than 100 missing values will be included by deleting corresponding rows with missing values instead.
```{r filterTsla, warning=FALSE}
#Select a subset of original data for data transformation and PCA
tslaSelected = tsla %>%
  .[,(which(naTsla[,2] < 100))] %>%
  .[!(apply(.,1, function(y){any(is.na(y))})),] 

#Apply Log-transformation on tslaSelected$TURNOVER to avoid producing NaN in skewness computation
tslaSelected$TURNOVER = log(tslaSelected$TURNOVER)
base::names(tslaSelected) [7]= "log(TURNOVER)"
```

##### 2.3.2 Calculate Skewness and Kurtosis - Tesla
```{r skewnessTsla, warning=FALSE}
require(e1071)
skewnessTsla = apply(tslaSelected,2,e1071::skewness)
kurtosisTsla   = apply(tslaSelected,2,e1071::kurtosis)
```

```{r skewnessTslaTable, warning=FALSE, echo=FALSE}
skewnessTsla = skewnessTsla %>%
               as.data.frame() %>%
               tibble::rownames_to_column(., "features")

knitr::kable(
 skewnessTsla,
 col.names = c("Features","Skewness"),
 caption   = "Table 2-3: Skewness of Selected Features - Tesla",
 align     = "lccrr"
)

kurtosisTsla = kurtosisTsla %>%
               as.data.frame() %>%
               tibble::rownames_to_column(., "features")

knitr::kable(
 kurtosisTsla,
 col.names = c("Features","Kurtosis"),
 caption   = "Table 2-4: Kurtosis of Selected Features - Tesla",
 align     = "lccrr"
)
```

##### 2.3.3 Data Transformation - Tesla
```{r dataTransTsla, warning=FALSE}
#Transform the selected data
(tslaTrans = caret::preProcess(tslaSelected, method = c("BoxCox","center","scale","pca")))

#Apply the transformations("BoxCox","center","scale","pca")
tslaPCA = stats::predict(tslaTrans,tslaSelected) #Outputs are PCA components
utils::head(tslaPCA)

#Summary of PCA results
tslaTrans_     = caret::preProcess(tslaSelected, method = c("BoxCox","center","scale"))
propVarTslaPCA = tslaSelected %>%
                 stats::predict(tslaTrans_,.) %>%
                 stats::prcomp() %>%
                 summary()
propVarTslaPCA #proportion of variance explained by each PCs

#Check extreme observations via PCA

ggplot(data = tslaPCA)+
  geom_point(aes(x = PC1, y= PC2))

ggplot(data = tslaPCA)+
  geom_point(aes(x = PC3, y= PC2))

ggplot(data = tslaPCA)+
  geom_point(aes(x = PC1, y= PC3))


plot3D::scatter3D(tslaPCA$PC1, tslaPCA$PC2, tslaPCA$PC3, pch = 16,  
                  theta = 20, phi = 20, main = "PCA - Tesla", xlab = "PC1", 
                  ylab ="PC2", zlab = "PC3", bty = "g", ticktype = "detailed")

```

#### Fig. 2.1 Density Plots  - Tesla
```{r dataPlotsTsla, echo=FALSE}
transformedTsla = predict(tslaTrans_,tslaSelected)
par(mfrow=c(2,2))
for (i in 1:ncol(tslaSelected)) {
  hist(tslaSelected[,i], breaks=20, freq=FALSE,
       main = paste("Density Plot - ",names(tslaSelected)[i],                            "(Before)"),xlab = " ")
  hist(transformedTsla[,i], breaks=20, freq=FALSE,
       main = paste("Density Plot - ",names(transformedTsla)[i],
                          "(After)"),xlab = " ")
}
```

##### 2.3.4 Data Filtering - Google
Features with less than 100 missing values will be included by deleting corresponding rows with missing values instead.
```{r filterGoog, warning=FALSE}
#Select a subset of original data for data transformation and PCA
googSelected = goog %>%
  .[,(which(naGoog[,2] < 100))] %>%
  .[!(apply(.,1, function(y){any(is.na(y))})),] 

#Apply Log-transformation on googSelected$TURNOVER
googSelected$TURNOVER = base::log(googSelected$TURNOVER)
base::names(googSelected) [7]= "log(TURNOVER)"
```

##### 2.3.5 Calculate Skewness and Kurtosis - Google
```{r skewnessGoog, warning=FALSE}
#require(e1071)
skewnessGoog = apply(googSelected,2,e1071::skewness)
kurtosisGoog = apply(googSelected,2,e1071::kurtosis)
```

```{r skewnessGoogTable, warning=FALSE, echo=FALSE}
skewnessGoog = skewnessGoog%>%
               as.data.frame() %>%
               tibble::rownames_to_column(., "features")

knitr::kable(
 skewnessGoog,
 col.names = c("Features","Skewness"),
 caption   = "Table 2-5: Skewness of Selected Features - Google",
 align     = "lccrr"
)


kurtosisGoog = kurtosisGoog %>%
               as.data.frame() %>%
               tibble::rownames_to_column(., "features")

knitr::kable(
 kurtosisGoog,
 col.names = c("Features","Kurtosis"),
 caption   = "Table 2-6: Kurtosis of Selected Features - Google",
 align     = "lccrr"
)

```

##### 2.3.6 Data Transformation - Google
```{r dataTransGoog, warning=FALSE}
#Transform the selected data
(googTrans = caret::preProcess(googSelected, method = c("BoxCox","center","scale","pca")))

#Apply the transformations("BoxCox","center","scale","pca")
googPCA = stats::predict(googTrans,googSelected) #Outputs are PCA components
utils::head(googPCA)

#Summary of PCA results
(googTrans_    = caret::preProcess(googSelected, method = c("BoxCox","center","scale")))
propVarGoogPCA = googSelected %>%
                 stats::predict(googTrans_,.) %>%
                 stats::prcomp() %>%
                 summary()
propVarGoogPCA #proportion of variance explained by each PCs

#Check extreme observations via PCA
ggplot(data = googPCA)+
  geom_point(aes(x = PC1, y= PC2))

ggplot(data = googPCA)+
  geom_point(aes(x = PC3, y= PC2))

ggplot(data = googPCA)+
  geom_point(aes(x = PC1, y= PC3))

plot3D::scatter3D(googPCA$PC1, googPCA$PC2, googPCA$PC3, pch = 16,  
                  theta = 20, phi = 20, main = "PCA - Alphabet", xlab = "PC1", 
                  ylab ="PC2", zlab = "PC3", bty = "g", ticktype = "detailed")

```

#### Fig. 2.2 Density Plots  - Google
```{r dataPlotsGoog, echo=FALSE}
transGoog = predict(googTrans_,googSelected)
par(mfrow=c(2,2))
for (i in 1:ncol(googSelected)) {
  hist(googSelected[,i], breaks=20, freq=FALSE,
       main = paste("Density Plot - ",names(googSelected)[i], "(After)"),
  xlab = " ")
  hist(transGoog[,i], breaks=20, freq=FALSE,
       main = paste("Density Plot - ",names(transGoog)[i], "(Before)"),
  xlab = " ")
}
```

#### 2.4 Correlation Analysis
>__Tesla__

```{r findCorrelationTsla, warning=FALSE}
library(corrplot)
corrTsla     = stats::cor(tslaSelected)
corrplot::corrplot(corrTsla, order="hclust")
```

#### Fig. 2.3 Correlations between features - Tesla

>__Google__

```{r findCorrelationGoog, warning=FALSE}
#library(corrplot)
corrGoog     = stats::cor(googSelected)
corrplot::corrplot(corrGoog, order="hclust")
```

#### Fig. 2.4 Correlations between features - Google

### 3 - News Scraping

```{r nees_scrape}
## Guardian API key
#api_key <- "d02efa1b-b4a4-4e20-a7f5-eee62d80cbf6"

## Query Guardian for TSLA news
#tsla_news <- GuardianR::get_guardian("Tesla", section = base::c("business", "technology", 
#                                                                "money", "world"), 
#                                     from.date = "2015-10-02", to.date = "2020-09-01", api.key = api_key)
#tsla_news <- tsla_news[, 4:5] # Extract relevant columns only

## Format date column
#tsla_news$webPublicationDate <- base::as.Date(base::substr(tsla_news$webPublicationDate, 1, 10), 
#                                              "%Y-%m-%d")

## Query Guardian for GOOG news
#goog_news <- GuardianR::get_guardian("Alphabet", section = base::c("business", "technology", 
#                                                                   "money", "world"), 
#                                     from.date = "2015-10-02", to.date = "2020-09-01", api.key = api_key)
#goog_news <- goog_news[, 4:5] # Extract relevant columns only

## Format date column
#goog_news$webPublicationDate <- base::as.Date(base::substr(goog_news$webPublicationDate, 1, 10), 
#                                              "%Y-%m-%d")

## Pull in news headlines from XLSX
tsla_news <- readxl::read_excel("1 - Data/Tesla/tesla news headlines from reuter 09052019-09092020.xlsx")
goog_news <- readxl::read_excel("1 - Data/Google/alphabet inc. news headlines from reuter 07112019-10302020.xlsx")

#tsla_news <- readxl::read_excel("tesla news headlines from reuter 09052019-09092020.xlsx")
#goog_news <- readxl::read_excel("alphabet inc. news headlines from reuter 07112019-10302020.xlsx")

## Format date columns
tsla_news$date <- base::as.Date(tsla_news$date, "%B %d,%Y")
goog_news$date <- base::as.Date(goog_news$date, "%B %d, %Y")

## Rename headline columns to match previous code
base::names(tsla_news) <- c("Date", "Time", "webTitle", "Keywords")
base::names(goog_news) <- c("Date", "Time", "webTitle", "Keywords")

## Get positive and negative words from Loughran and McDonald
positive_words <- base::data.frame(
  readxl::read_excel("2 - Word Lists/LoughranMcDonald_SentimentWordLists_2018.xlsx",
                     sheet = "Positive", col_names = F))$...1

negative_words <- base::data.frame(
  readxl::read_excel("2 - Word Lists/LoughranMcDonald_SentimentWordLists_2018.xlsx",
                     sheet = "Negative", col_names = F))$...1

## Calculate sentiment for TSLA
tsla_news$Sentiment <- base::as.numeric(NA)
for (row in 1:base::nrow(tsla_news)) {
  tmp <- base::strsplit(tsla_news[row, ]$webTitle, "[[:space:]]|(?=[.!?])", perl = T)[[1]]
  
  sentiment <- 0
  for (word in tmp) {
    if (base::nchar(word) > 1 & !(base::grepl("\\(", word)) & !(base::grepl("\\)", word))) {
      if (base::any(stringr::str_detect(positive_words, stringr::regex(word, ignore_case = T)))) {
        sentiment <- sentiment + 1
      } else if (base::any(stringr::str_detect(negative_words, stringr::regex(word, ignore_case = T)))) {
        sentiment <- sentiment - 1
      }
    }
  }
  tsla_news[row, ]$Sentiment <- sentiment
}

## Calculate sentiment for GOOG
goog_news$Sentiment <- base::as.numeric(NA)
for (row in 1:base::nrow(goog_news)) {
  tmp <- base::strsplit(goog_news[row, ]$webTitle, "[[:space:]]|(?=[.!?])", perl = T)[[1]]
  
  sentiment <- 0
  for (word in tmp) {
    if (base::nchar(word) > 1 & !(base::grepl("\\(", word)) & !(base::grepl("\\)", word))) {
      if (base::any(stringr::str_detect(positive_words, stringr::regex(word, ignore_case = T)))) {
        sentiment <- sentiment + 1
      } else if (base::any(stringr::str_detect(negative_words, stringr::regex(word, ignore_case = T)))) {
        sentiment <- sentiment - 1
      }
    }
  }
  goog_news[row, ]$Sentiment <- sentiment
}

goog_news$Ticker <- "GOOG"
tsla_news$Ticker <- "TSLA"
plot_data <- dplyr::bind_rows(goog_news, tsla_news)
mu <- plyr::ddply(plot_data, "Ticker", summarise, grp.mean = mean(Sentiment))
ggplot2::ggplot(data = plot_data, ggplot2::aes(x = Sentiment, fill = Ticker)) + 
  ggplot2::geom_density(alpha = 0.5, adjust = 1.5) + 
  ggplot2::geom_vline(data = mu, ggplot2::aes(xintercept = grp.mean, color = Ticker),
                      linetype = "dashed") +
  ggplot2::scale_color_manual(values = c("#5f506b", "#86bbbd")) + 
  ggplot2::scale_fill_manual(values = c("#5f506b", "#86bbbd"))
```


### 4 - Twitter Scraping

```{r twitter_scrape}
cl = makeCluster(8)
registerDoParallel(cl)
## Twitter API keys and secrets
api_key <- "zElIwld33bNohcb28j7si3aBW"
api_secret_key <- "a5yDRmHeFpq2tpqk4u687rAyDuApzUe2ZffYir3disyqa98QGb"
bearer_token <- "AAAAAAAAAAAAAAAAAAAAAH2iGAEAAAAApwFAjq60a%2Ba8gOG2URX2scAHOo0%3DPXz3xx1Z5i8YuqNzRt6wSAINxOkqNrArIESFlnxWCToPHhEcRH"
access_token <- "1271553006522306568-Azxsa0o7nHOCNpvRjRdocbWPYz0D6w"
access_token_secret <- "PwT1GB0Ogj0poevifeUShWB4lEZAODXHWfm8HyXRz2J7e"

## Create Twitter token
twitter_token <- rtweet::create_token(app = "BNC Sentiment Analysis", consumer_key = api_key, consumer_secret = api_secret_key, access_token = access_token, access_secret = access_token_secret)

## Get positive and negative words from Loughran and McDonald
positive_words <- base::data.frame(
  readxl::read_excel("2 - Word Lists/LoughranMcDonald_SentimentWordLists_2018.xlsx",
                     sheet = "Positive", col_names = F))$...1

negative_words <- base::data.frame(
  readxl::read_excel("2 - Word Lists/LoughranMcDonald_SentimentWordLists_2018.xlsx",
                     sheet = "Negative", col_names = F))

## Loop through tickers and pull tweets
sentiment <- base::data.frame("Ticker" = base::character(),
                              "Date" = base::as.Date(base::character()),
                              "Sentiment" = base::numeric(), stringsAsFactors = F)

for (index in 1:2) {
  tickers <- c("TSLA", "GOOG"); ticker <- tickers[index]
  
  ## Pull tweets (this will throw an authentication page the first time)
  search <- base::ifelse(ticker == "TSLA", "Tesla", "Google")
  tweets <- rtweet::search_tweets(q = search, n = 1000, include_rts = F,
                                  retryonratelimit = T)
  
  tweets$sentiment <- as.numeric(NA)
  for (i in 1:base::nrow(tweets)) {
    values <- base::numeric()
    for (word in base::strsplit(tweets[i, ]$text, "[[:punct:] ]")[[1]]) {
      if (word %in% positive_words) {values <- append(values, 1)}
      else if (word %in% negative_words) {values <- append(values, -1)}
      else {values <- append(values, 0)}
    }
    tweets[i, ]$sentiment <- base::sum(values)
    print(i)
  }

  ## Check sentiment
  tweets$sentiment <- base::round(stats::weighted.mean(tweets$sentiment,
                                                 w = tweets$favorite_count + tweets$favorite_count),
                            digits = 1)
  tweets$created_at <- base::as.Date(tweets$created_at, "%Y-%m-%d")
  tmp <- tweets %>% dplyr::group_by(created_at) %>% dplyr::summarize("sentiment" = base::sum(sentiment))
  sentiment <- base::append(sentiment, tmp)
}

names(sentiment) <- c("TSLA", "GOOG")

ggplot2::ggplot(sentiment, ggplot2::aes(x = Date, y = Sentiment, color = Ticker)) + ggplot2::geom_line() + ggplot2::ggtitle("Twitter Sentiment Over Time")



```



```{r newVar}
###TSLA
tslaTemp = tslaSelected %>% 
  dplyr::mutate(
         PP = lag((PX_HIGH + PX_LOW + PX_LAST)/3), #Previous Day (High + Low + Close) / 3
         R1 = 2 * PP - lag(PX_LOW),                #(Pivot x 2) – Previous Day Low
         S1 = 2 * PP - lag(PX_HIGH),               #(Pivot x 2) – Previous Day High
         R2 = PP + (R1 - S1),                      #Pivot + (R1 – S1)
         S2 = PP - (R1 - S1),                      #Pivot - (R1 – S1)
         R3 = lag(PX_HIGH) + 2 * (PP - lag(PX_LOW)),    
         #R3= Previous Day High + 2(PP – Previous Day Low)
         S3 = lag(PX_LOW) - 2 * (lag(PX_HIGH) - PP),
         #S3= Previous Day Low – 2(Previous Day High – Pivot)
         diffHighLow  = PX_HIGH - PX_LOW,
         diffLastOpen = PX_LAST - PX_OPEN,
         stockReturn  = (PX_LAST - PX_OPEN)/PX_OPEN
         )

highCorrF = function(dta, thred){
  #Find highly correlated features
  highCorr = dta %>%
  cor %>%
  caret::findCorrelation(thred, names = TRUE)
  return(highCorr)
}


hclustPlotF = function(dta) {
  #Correlation Plot
  corrplot::corrplot(cor(dta), order="hclust")
}

###GOOG
googTemp = googSelected %>% 
  dplyr::mutate(
         PP = lag((PX_HIGH + PX_LOW + PX_LAST)/3), #Previous Day (High + Low + Close) / 3
         R1 = 2 * PP - lag(PX_LOW),                #(Pivot x 2) – Previous Day Low
         S1 = 2 * PP - lag(PX_HIGH),               #(Pivot x 2) – Previous Day High
         R2 = PP + (R1 - S1),                      #Pivot + (R1 – S1)
         S2 = PP - (R1 - S1),                      #Pivot - (R1 – S1)
         R3 = lag(PX_HIGH) + 2 * (PP - lag(PX_LOW)),    
         #R3= Previous Day High + 2(PP – Previous Day Low)
         S3 = lag(PX_LOW) - 2 * (lag(PX_HIGH) - PP),
         #S3= Previous Day Low – 2(Previous Day High – Pivot)
         diffHighLow  = PX_HIGH - PX_LOW,
         diffLastOpen = PX_LAST - PX_OPEN,
         stockReturn  = (PX_LAST - PX_OPEN)/PX_OPEN
         )
```


```{r OnBalanceVolume}
###TSLA

tslaAddOBV = tslaTemp %>% 
  mutate(obv = TTR::OBV(PX_LAST, PX_VOLUME))

###GOOG
googAddOBV = googTemp %>% 
  mutate(obv = TTR::OBV(PX_LAST, PX_VOLUME))

```



```{r chaikinMoneyFlow}
#TSLA
daysCMF = 21
tslaAddCMF = tslaAddOBV %>%
  mutate(cmf = TTR::CMF(tslaAddOBV[,c("PX_HIGH","PX_LOW","PX_LAST")], PX_VOLUME, n = daysCMF))
#GOOG
daysCMF = 21
googAddCMF = googAddOBV %>%
  mutate(cmf = TTR::CMF(googAddOBV[,c("PX_HIGH","PX_LOW","PX_LAST")], PX_VOLUME, n = daysCMF))
```



```{r exponentialMovingAverage}
#TSLA
daysEMA = 10 #EMA lengths
tslaAddEMA = tslaAddCMF %>%
  mutate(emaPrice = TTR::EMA(tslaAddCMF$PX_LAST,daysEMA)) %>%
  mutate(emaVolume = TTR::EMA(tslaAddCMF$PX_VOLUME,daysEMA))

###GOOG
daysEMA = 10 #EMA lengths
googAddEMA = googAddCMF %>%
  mutate(emaPrice = TTR::EMA(googAddCMF$PX_LAST,daysEMA)) %>%
  mutate(emaVolume = TTR::EMA(googAddCMF$PX_VOLUME,daysEMA))
```

```{r relativeStrengthIndex(RSI)}
###Tsla
daysRSI = 14
tslaAddRSI = tslaAddEMA %>%
  mutate(rsi = TTR::RSI(PX_LAST, n=daysRSI, maType="WMA", wts=PX_VOLUME))
###GOOG
daysRSI = 14
googAddRSI = googAddEMA %>%
  mutate(rsi = TTR::RSI(PX_LAST, n=daysRSI, maType="WMA", wts=PX_VOLUME))
```


```{r simpleMovingAverage(SMA)}
###Tsla
daysSMA = 10
tslaAddSMA = tslaAddRSI %>%
  mutate(smaPrice = TTR::SMA(PX_LAST, n=daysSMA)) %>%
  mutate(smaVolume = TTR::SMA(PX_VOLUME, n=daysSMA))
###GOOG
daysSMA = 10
googAddSMA = googAddRSI %>%
  mutate(smaPrice = TTR::SMA(PX_LAST, n=daysSMA)) %>%
  mutate(smaVolume = TTR::SMA(PX_VOLUME, n=daysSMA))
```

```{r momentumStochasticIndex(K% and D%)}
###Tsla
#Stochastic Momentum Index
daysK = 5 #%K is usually set to 5 and represents the main movements of price – slow line.
daysD = 3 #%D is the fast line, a simple moving average of the %K and is set to 3.
tslaHLC  = tslaSelected %>% dplyr::select(PX_HIGH, PX_LOW, PX_LAST)
tslaAddK = tslaAddSMA %>%
 dplyr::mutate(smi_K = (stoch(tslaHLC, nFastK = daysK, nFastD = daysD, nSlowD = 3, bounded = TRUE,smooth = 1))[,1]) %>% #calculate fastK%
 dplyr::mutate(smi_D = (stoch(tslaHLC, nFastK = daysK, nFastD = daysD, nSlowD = 3, bounded = TRUE,smooth = 1))[,2])  #calculate fastD%

###GOOG
daysK = 5 #%K is usually set to 5 and represents the main movements of price – slow line.
daysD = 3 #%D is the fast line, a simple moving average of the %K and is set to 3.
googHLC  = googSelected %>% dplyr::select(PX_HIGH, PX_LOW, PX_LAST)
googAddK = googAddSMA %>%
 dplyr::mutate(smi_K = (stoch(googHLC, nFastK = daysK, nFastD = daysD, nSlowD = 3, bounded = TRUE,smooth = 1))[,1]) %>% #calculate fastK%
 dplyr::mutate(smi_D = (stoch(googHLC, nFastK = daysK, nFastD = daysD, nSlowD = 3, bounded = TRUE,smooth = 1))[,2])  #calculate fastD%
```


```{r MACD}
###TSLA
daysMACDslow   = 26 #default nSlow
daysMACDfast   = 12 #default nFast
daysMACDsignal = 9  #default nSig

tslaAddMACD = tslaAddK %>%
  mutate(macdPrice = (TTR::MACD(PX_LAST, nFast = daysMACDfast, nSlow = daysMACDslow, nSig = daysMACDsignal))[,1]) %>%
  #mutate(macdPrice = TTR::MACD(nFast = 12, nSlow = 26, nSig = 9, maType="WMA", wts=PX_VOLUME)) %>% # weighted macdPrice
  mutate(macdVolume = (TTR::MACD(PX_VOLUME, nFast = daysMACDfast, nSlow = daysMACDslow, nSig = daysMACDsignal))[,1])

###GOOG
daysMACDslow   = 26 #default nSlow
daysMACDfast   = 12 #default nFast
daysMACDsignal = 9  #default nSig

googAddMACD = googAddK %>%
  mutate(macdPrice = (TTR::MACD(PX_LAST, nFast = daysMACDfast, nSlow = daysMACDslow, nSig = daysMACDsignal))[,1]) %>%
  #mutate(macdPrice = TTR::MACD(nFast = 12, nSlow = 26, nSig = 9, maType="WMA", wts=PX_VOLUME)) %>% # weighted macdPrice
  mutate(macdVolume = (TTR::MACD(PX_VOLUME, nFast = daysMACDfast, nSlow = daysMACDslow, nSig = daysMACDsignal))[,1])
```

```{r LarryWilliam's R%}
###TSLA
daysR = 14 #default
#tslaHLC  = tslaSelected %>% dplyr::select(PX_HIGH, PX_LOW, PX_LAST)
tslaAddR = tslaAddMACD %>%
  mutate(larryWilliamsR = TTR::WPR(tslaHLC, n = daysR))

###GOOG
daysR = 14 #default
#googHLC  = googSelected %>% dplyr::select(PX_HIGH, PX_LOW, PX_LAST)
googAddR = googAddMACD %>%
  mutate(larryWilliamsR = TTR::WPR(googHLC, n = daysR))

```


```{r Accumulation/Distribution}
###TSLA
tslaAddAD = tslaAddR %>%
  mutate(williamsAD = TTR::williamsAD(tslaHLC))
###GOOG
googAddAD = googAddR %>%
  mutate(williamsAD = TTR::williamsAD(googHLC))

```



```{r CommodityChannelIndex(CCI)}
###TSLA
daysCCI = 20
tslaAddCCI = tslaAddAD %>%
  mutate(cci = TTR::CCI(tslaHLC, n = daysCCI))

###GOOG
daysCCI = 20
googAddCCI = googAddAD %>%
  mutate(cci = TTR::CCI(googHLC, n = daysCCI))

#--End--#

#Summarize how many indicators we've added. 

beforeAfterVarTsla = tslaAddCCI[,(ncol(tslaSelected)+1):ncol(tslaAddCCI)]
names(beforeAfterVarTsla)

beforeAfterVarGoog = googAddCCI[,(ncol(googSelected)+1):ncol(googAddCCI)]
names(beforeAfterVarGoog)
```

```{r additionMeasuresOnStockTrend}
###TSLA
#Calculate stock price trend supported with significant volume increase
tslaAddVolYesterday = addLaggedVarF(tslaAddCCI$PX_VOLUME,tslaAddCCI, "pastVolume", 1)
tslaAddPx_lastYesterday = addLaggedVarF(tslaAddVolYesterday$PX_LAST,tslaAddVolYesterday, "pastLastPrice", 1)

tslaAddVolTemp1 = tslaAddPx_lastYesterday %>%
  mutate(diffVolume = PX_VOLUME - pastVolume1) %>%
  dplyr::slice(-1) %>%
  mutate(increasedVolume = rep(0.01, nrow(.)))

for (i in 1:nrow(tslaAddVolTemp1)) {
  if (tslaAddVolTemp1$diffVolume[i] <=0 ) {
    tslaAddVolTemp1$increasedVolume[i] = 0
  } else {
    tslaAddVolTemp1$increasedVolume[i] = 1*tslaAddVolTemp1$diffVolume[i] 
  }
}


varPastVolumesF = function(featureVolume,lagsize) {
  pastVol_upper = rep(0.0123, length(featureVolume))
  for (d in 1:(length(featureVolume) - lagsize + 1)) {
    pastVol = featureVolume[d:(d + lagsize - 1)]
    pastVol_upper[d+lagsize - 1] = mean(pastVol) + 1.28*var(pastVol)**.5 
    #80% confidence
  }
  return(pastVol_upper)
}

pastVol_upperTsla = varPastVolumesF(tslaAddVolTemp1$PX_VOLUME,5) 
#pastVol_upper[1:20]

tslaAddVolTemp2 = tslaAddVolTemp1 %>%
  mutate(pastVol_upperTsla) %>%
  mutate(afterHourDiffPriceRatio = (PX_OPEN - pastLastPrice1)/pastLastPrice1) %>% 
  #afterHourDiffPrice = closePrice_yesterday - openPrice_today
  mutate(largerThanUpperVol = rep(0.0123, nrow(.)))

#Valid volume increase (when the current volume is larger than the upper bound of volumes in past five days including the current date.)

for (i in 1:nrow(tslaAddVolTemp2)) {
  if (tslaAddVolTemp2$PX_VOLUME[i] < tslaAddVolTemp2$pastVol_upper[i]) {
    tslaAddVolTemp2$largerThanUpperVol[i] = 0
  } else {
    tslaAddVolTemp2$largerThanUpperVol[i] = 1*tslaAddVolTemp2$diffVolume[i] 
  }
}

#names(tslaAddVolTemp2)
#Add interaction terms
tslaAddVolTrend = tslaAddVolTemp2 %>% 
  mutate(increaseTrend = diffLastOpen * increasedVolume) %>%
  mutate(strongIncreaseTrend = diffLastOpen * largerThanUpperVol) %>%
  select(- c(pastVolume1,pastLastPrice1,diffVolume,increasedVolume,pastVol_upperTsla,largerThanUpperVol))



###GOOG
#Calculate stock price trend supported with significant volume increase
googAddVolYesterday = addLaggedVarF(googAddCCI$PX_VOLUME,googAddCCI, "pastVolume", 1)
googAddPx_lastYesterday = addLaggedVarF(googAddVolYesterday$PX_LAST,googAddVolYesterday, "pastLastPrice", 1)

googAddVolTemp1 = googAddPx_lastYesterday %>%
  mutate(diffVolume = PX_VOLUME - pastVolume1) %>%
  dplyr::slice(-1) %>%
  mutate(increasedVolume = rep(0.01, nrow(.)))

for (i in 1:nrow(googAddVolTemp1)) {
  if (googAddVolTemp1$diffVolume[i] <=0 ) {
    googAddVolTemp1$increasedVolume[i] = 0
  } else {
    googAddVolTemp1$increasedVolume[i] = 1*googAddVolTemp1$diffVolume[i] 
  }
}

pastVol_upperGoog = varPastVolumesF(googAddVolTemp1$PX_VOLUME,5) 
#pastVol_upper[1:20]

googAddVolTemp2 = googAddVolTemp1 %>%
  mutate(pastVol_upperGoog) %>%
  mutate(afterHourDiffPriceRatio = (PX_OPEN - pastLastPrice1)/pastLastPrice1) %>% 
  #afterHourDiffPrice = closePrice_yesterday - openPrice_today
  mutate(largerThanUpperVol = rep(0.0123, nrow(.)))

#Valid volume increase (when the current volume is larger than the upper bound of volumes in past five days including the current date.)

for (i in 1:nrow(googAddVolTemp2)) {
  if (googAddVolTemp2$PX_VOLUME[i] < googAddVolTemp2$pastVol_upperGoog[i]) {
    googAddVolTemp2$largerThanUpperVol[i] = 0
  } else {
    googAddVolTemp2$largerThanUpperVol[i] = 1*googAddVolTemp2$diffVolume[i] 
  }
}

#names(googAddVolTemp2)
#Add interaction terms
googAddVolTrend = googAddVolTemp2 %>% 
  mutate(increaseTrend = diffLastOpen * increasedVolume) %>%
  mutate(strongIncreaseTrend = diffLastOpen * largerThanUpperVol) %>%
  select(- c(pastVolume1,pastLastPrice1,diffVolume,increasedVolume,pastVol_upperGoog,largerThanUpperVol))

```

Up till now, we added:
*TSLA stock indicators
`r names(beforeAfterVarTsla)`

*GOOG stock indicators
`r names(beforeAfterVarGoog)`

```{r addLaggedVariablesFunctions}
#Add lagged values of features. 
addLaggedVarF = function(feature, dataForModification, featureName,lagSize ) {
  for (lags in 1:lagSize) { 
    newColName = paste0(featureName, lags)
    dataForModification = dataForModification %>%
      dplyr::mutate(!!sym(newColName) := dplyr::lag(feature, n = lags))
  }
  return(dataForModification)
}


addDiffVarF = function(dataForModification,nColumn) {
  #"tslaSelected" is created to remove features with too many missing values from the original data
  #Purpose: Take the first difference of features in "tslaSelected"
  diffFeature = as_tibble(matrix(rep(0,((nrow(dataForModification)-1)*nColumn)),ncol = nColumn))
  featureName = names(dataForModification)[1:nColumn]
  
  for (j in 1:nColumn) {
    diffFeature[,j] = as_tibble(matrix(diff(dataForModification[,j]), ncol = 1))
    names(diffFeature)[j] = paste0(featureName[j],"_diffPreviousDay")
  }
 diffFeature = lag(diffFeature) #Use the difference between today and yesterday to predict tomorrow; first two rows should be NAs. It will be taken care later with na.omit()
 dataForModification_ = dataForModification[2:nrow(dataForModification),]
 laggedDiff = cbind(dataForModification_,diffFeature)
 laggedDiff %>% transmute()
 return(laggedDiff)
}

#tslaAddDiff =  addDiffVarF(tslaSelected,ncol(tslaSelected))
``` 


###Final Task

```{r dailySentiments}
tslaSentiments = tsla_news %>%
  group_by(Date) %>%
  summarise(tslaSentimentsSum = sum(Sentiment, na.rm = TRUE),
            tslaSentimentsMean = mean(Sentiment, na.rm = TRUE))

googSentiments = goog_news %>%
  group_by(Date) %>%
  summarise(googSentimentsSum = sum(Sentiment, na.rm = TRUE), 
            googSentimentsMean = mean(Sentiment, na.rm = TRUE))
```

```{r assignYandX}
tslaAddVolTrendRemoveNA = tslaAddVolTrend %>%
  na.omit(.)
tslaFullStandardized =  tslaAddVolTrendRemoveNA %>%
  caret::preProcess(method = c("center","scale")) %>%
  predict(newdata =tslaAddVolTrendRemoveNA)


###TSLA
tslaY  = tslaFullStandardized %>%
  dplyr::select(Date,diffHighLow, stockReturn) %>%
  dplyr::as_tibble() %>%
  dplyr::slice(-1) %>%
  mutate(stockReturnDummy = if_else(stockReturn >= 0, 1, 0))

tslaX    = tslaFullStandardized %>%
  .[1:(nrow(.)-1),] %>%
  dplyr::as_tibble(.) 

names(tslaY)[2] = "diffHighLowTomorrow" #Y1
names(tslaY)[3] = "stockReturnTomorrow" #Y2
names(tslaY)[4] = "stockReturnTomorrowDummy" #Y3

colnames(tslaX)

#####Dummy Variables
###TSLA
XtslaAddLevels = tslaX %>%
  mutate(aboveR1 = factor(ifelse(PX_HIGH > R1, "Yes", "No"))) %>%
  mutate(aboveR2 = factor(ifelse(PX_HIGH > R2, "Yes", "No"))) %>%
  mutate(aboveR3 = factor(ifelse(PX_HIGH > R3, "Yes", "No"))) %>%
  mutate(belowS1 = factor(ifelse(PX_LOW  < S1, "Yes", "No"))) %>%
  mutate(belowS2 = factor(ifelse(PX_LOW  < S2, "Yes", "No"))) %>%
  mutate(belowS3 = factor(ifelse(PX_LOW  < S3, "Yes", "No"))) %>%
  select(aboveR1, aboveR2, aboveR3, belowS1, belowS2, belowS3)            
XtslaDummyModel = caret::dummyVars(~ ., data = XtslaAddLevels, fullRank = TRUE)


YtslaAddLevels = as_tibble(factor(ifelse(tslaY$stockReturnTomorrow > 0, "Increased", "Decreased"))) 
YtslaDummyModel = caret::dummyVars(~ ., data = YtslaAddLevels, fullRank = TRUE)



XtslaDummy = as_tibble(predict(XtslaDummyModel, XtslaAddLevels))

YtslaDummy = as_tibble(predict(YtslaDummyModel, YtslaAddLevels))
names(YtslaDummy)[1] = "stockReturnTomorrowDummy" #Y2

nrow(XtslaDummy)
nrow(YtslaDummy)

#tslaFullWithDummy = tslaFullStandardized %>% 
#  mutate(XtslaDummy) %>% 
#  dplyr::select(-R1,-S1,-R2,-S2,-R3,-S3) %>% 
#  #Drop PP, R1, R2, R3, S1, S2, S3 
#  mutate(YtslaDummy) 

XtslaWithDummy = tslaX %>%
  mutate(XtslaDummy) %>% 
  dplyr::select(-R1,-S1,-R2,-S2,-R3,-S3)

XtslaWithoutDummy = tslaX %>%
  dplyr::select(-R1,-S1,-R2,-S2,-R3,-S3)

YtslaWithDummy = tslaY %>% mutate(YtslaDummy) 

#X:20190909 - 20200828
#Y:20190910 - 20200831
XtslaWithDummy_subset = XtslaWithDummy[2164:nrow(XtslaWithDummy),] 
YtslaWithDummy_subset = YtslaWithDummy[2164:nrow(YtslaWithDummy),]
YtslaWithDummy_subsetWithoutDate = YtslaWithDummy_subset[,-1]

tslaFull = cbind(YtslaWithDummy_subsetWithoutDate,XtslaWithDummy_subset) 
tslaFullWithSentiments = merge(tslaFull,tslaSentiments)

XtslaWithSentiments = tslaFullWithSentiments %>%
  select(-c(Date,diffHighLowTomorrow,stockReturnTomorrow,stockReturnTomorrowDummy))
YtslaWithSentiments = tslaFullWithSentiments %>%
  select(c(Date,diffHighLowTomorrow,stockReturnTomorrow,stockReturnTomorrowDummy))



##GOOG

googAddVolTrendRemoveNA = googAddVolTrend %>%
  na.omit(.)
googFullStandardized =  googAddVolTrendRemoveNA %>%
  caret::preProcess(method = c("center","scale")) %>%
  predict(newdata =googAddVolTrendRemoveNA)

googY  = googFullStandardized %>%
  dplyr::select(Date,diffHighLow, stockReturn) %>%
  dplyr::as_tibble() %>%
  dplyr::slice(-1) %>%
  mutate(stockReturnDummy = if_else(stockReturn >= 0, 1, 0))

googX    = googFullStandardized %>%
  .[1:(nrow(.)-1),] %>%
  dplyr::as_tibble(.) 

names(googY)[2] = "diffHighLowTomorrow" #Y1
names(googY)[3] = "stockReturnTomorrow" #Y2
names(googY)[4] = "stockReturnTomorrowDummy" #Y3

#####Dummy Variables

###GOOG
XgoogAddLevels = googX %>%
  mutate(aboveR1 = factor(ifelse(PX_HIGH > R1, "Yes", "No"))) %>%
  mutate(aboveR2 = factor(ifelse(PX_HIGH > R2, "Yes", "No"))) %>%
  mutate(aboveR3 = factor(ifelse(PX_HIGH > R3, "Yes", "No"))) %>%
  mutate(belowS1 = factor(ifelse(PX_LOW  < S1, "Yes", "No"))) %>%
  mutate(belowS2 = factor(ifelse(PX_LOW  < S2, "Yes", "No"))) %>%
  mutate(belowS3 = factor(ifelse(PX_LOW  < S3, "Yes", "No"))) %>%
  select(aboveR1, aboveR2, aboveR3, belowS1, belowS2, belowS3)            
XgoogDummyModel = caret::dummyVars(~ ., data = XgoogAddLevels, fullRank = TRUE)



YgoogAddLevels = as_tibble(factor(ifelse(googY$stockReturnTomorrow > 0, "Increased", "Decreased"))) 
YgoogDummyModel = caret::dummyVars(~ ., data = YgoogAddLevels, fullRank = TRUE)


XgoogDummy = as_tibble(predict(XgoogDummyModel, XgoogAddLevels))
YgoogDummy = as_tibble(predict(YgoogDummyModel, YgoogAddLevels))

names(YgoogDummy)[1] = "stockReturnTomorrowDummy" #Y2


XgoogWithDummy = googX %>%
  mutate(XgoogDummy) %>% 
  dplyr::select(-R1,-S1,-R2,-S2,-R3,-S3)

XgoogWithoutDummy = googX %>%
  dplyr::select(-R1,-S1,-R2,-S2,-R3,-S3)

YgoogWithDummy = googY %>% mutate(YgoogDummy) 

#X:20190711 - 20200828
#Y:20190712 - 20200831

XgoogWithDummy_subset = XgoogWithDummy[1306:nrow(XgoogWithDummy),] 
YgoogWithDummy_subset = YgoogWithDummy[1306:nrow(YgoogWithDummy),]
YgoogWithDummy_subsetWithoutDate = YgoogWithDummy_subset[,-1]

googFull = cbind(YgoogWithDummy_subsetWithoutDate,XgoogWithDummy_subset) 
googFullWithSentiments = merge(googFull,googSentiments)

XgoogWithSentiments = googFullWithSentiments %>%
  select(-c(Date,diffHighLowTomorrow,stockReturnTomorrow,stockReturnTomorrowDummy))
YgoogWithSentiments = googFullWithSentiments %>%
  select(c(Date,diffHighLowTomorrow,stockReturnTomorrow,stockReturnTomorrowDummy))
```


###### 7 - Final Task without sentiments (updated from Task 3) 

```{r dataSplitFinalTask}
#Line 990
#Superviors:
  #Y1: YtslaWithSentiments$diffHighLowTomorrow
  #Y2: YtslaWithSentiments$stockReturnTomorrow
  #Y3: YtslaWithSentiments$stockReturnTomorrowDummy

#Features wtihtout Sentiments:
XtslaWithoutSentiments = XtslaWithSentiments %>%
  select(-c(tslaSentimentsSum,tslaSentimentsMean))
XgoogWithoutSentiments = XgoogWithSentiments %>%
  select(-c(googSentimentsSum,googSentimentsMean))

#Data Split
##TSLA

set.seed(2020)
inTrain_tslaHL = caret::createDataPartition(YtslaWithSentiments$diffHighLowTomorrow, p = 4/5, list = FALSE) #Y1
inTrain_tslaSR = caret::createDataPartition(YtslaWithSentiments$stockReturnTomorrow, p = 4/5, list = FALSE) #Y2
inTrain_tslaSRdummy = caret::createDataPartition(YtslaWithSentiments$stockReturnTomorrowDummy, p = 4/5, list = FALSE) #Y3


Ytrain_tslaHL = YtslaWithSentiments$diffHighLowTomorrow[inTrain_tslaHL]
Ytest_tslaHL  = YtslaWithSentiments$diffHighLowTomorrow[-inTrain_tslaHL]
Ytrain_tslaSR = YtslaWithSentiments$stockReturnTomorrow[inTrain_tslaSR]
Ytest_tslaSR  = YtslaWithSentiments$stockReturnTomorrow[-inTrain_tslaSR]
Ytrain_tslaSRdummy = YtslaWithSentiments$stockReturnTomorrowDummy[inTrain_tslaSRdummy]
Ytest_tslaSRdummy  = YtslaWithSentiments$stockReturnTomorrowDummy[-inTrain_tslaSRdummy]


Xtrain_tslaHL = XtslaWithoutSentiments[inTrain_tslaHL,] 
Xtest_tslaHL  = XtslaWithoutSentiments[-inTrain_tslaHL,]
Xtrain_tslaSR = XtslaWithoutSentiments[inTrain_tslaSR,] 
Xtest_tslaSR  = XtslaWithoutSentiments[-inTrain_tslaSR,]
Xtrain_tslaSRdummy = XtslaWithoutSentiments[inTrain_tslaSRdummy,]
Xtest_tslaSRdummy  = XtslaWithoutSentiments[-inTrain_tslaSRdummy,]

###GOOG

set.seed(2020)
inTrain_googHL = caret::createDataPartition(YgoogWithSentiments$diffHighLowTomorrow, p = 4/5, list = FALSE) #Y1
inTrain_googSR = caret::createDataPartition(YgoogWithSentiments$stockReturnTomorrow, p = 4/5, list = FALSE) #Y2
inTrain_googSRdummy = caret::createDataPartition(YgoogWithSentiments$stockReturnTomorrowDummy, p = 4/5, list = FALSE) #Y3


Ytrain_googHL = YgoogWithSentiments$diffHighLowTomorrow[inTrain_googHL]
Ytest_googHL  = YgoogWithSentiments$diffHighLowTomorrow[-inTrain_googHL]
Ytrain_googSR = YgoogWithSentiments$stockReturnTomorrow[inTrain_googSR]
Ytest_googSR  = YgoogWithSentiments$stockReturnTomorrow[-inTrain_googSR]
Ytrain_googSRdummy = YgoogWithSentiments$stockReturnTomorrowDummy[inTrain_googSRdummy]
Ytest_googSRdummy  = YgoogWithSentiments$stockReturnTomorrowDummy[-inTrain_googSRdummy]


Xtrain_googHL = XgoogWithoutSentiments[inTrain_googHL,]
Xtest_googHL  = XgoogWithoutSentiments[-inTrain_googHL,]
Xtrain_googSR = XgoogWithoutSentiments[inTrain_googSR,]
Xtest_googSR  = XgoogWithoutSentiments[-inTrain_googSR,]
Xtrain_googSRdummy = XgoogWithoutSentiments[inTrain_googSRdummy,]
Xtest_googSRdummy  = XgoogWithoutSentiments[-inTrain_googSRdummy,]

```


```{r setupFinalTask}

#Repeated cross validation
trControl = caret::trainControl(method = "repeatedcv", repeats = 5, number = 10)

XtrainMat_tslaHL      = as.matrix(Xtrain_tslaHL)
XtestMat_tslaHL       = as.matrix(Xtest_tslaHL)
XtrainMat_tslaSR      = as.matrix(Xtrain_tslaSR)
XtestMat_tslaSR       = as.matrix(Xtest_tslaSR)
XtrainMat_tslaSRdummy = as.matrix(Xtrain_tslaSRdummy)
XtestMat_tslaSRdummy  = as.matrix(Xtest_tslaSRdummy)

####GOOG
#Feature transformations
XtrainMat_googHL      = as.matrix(Xtrain_googHL)
XtestMat_googHL       = as.matrix(Xtest_googHL)
XtrainMat_googSR      = as.matrix(Xtrain_googSR)
XtestMat_googSR       = as.matrix(Xtest_googSR)
XtrainMat_googSRdummy = as.matrix(Xtrain_googSRdummy)
XtestMat_googSRdummy  = as.matrix(Xtest_googSRdummy)

#Parallelism
#cl = parallel::makeCluster(8)
#doParallel::registerDoParallel(cl)
```


```{r elasticNetTuningParameters}
set.seed(2020)
cl = parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
####Supervisor Y1 = YtslaWithSentiments$diffHighLowTomorrow
####TSLA
trControl = caret::trainControl(method = "repeatedcv", repeats = 5, number = 10)

lassoGridTslaHL = expand.grid(lambda = c(0.0001,0.001, 0.01, 0.05, 0.1, 0.2),
                            alpha = c(0.05,0.5,1))


elasticOutTslaHL = train(x = XtrainMat_tslaHL, y = Ytrain_tslaHL, 
                       method = 'glmnet',
                       tuneGrid = lassoGridTslaHL, 
                       trControl = trControl)
plot(elasticOutTslaHL, main = "Elastic Net - TSLA diffHighLow")

####GOOG
#trControl = caret::trainControl(method = "repeatedcv", repeats = 2, number = 10)

lassoGridGoogHL = expand.grid(lambda = c(0.0001,0.001, 0.01, 0.05, 0.1, 0.2),
                            alpha = c(0.05,0.5,1))


elasticOutGoogHL = train(x = XtrainMat_googHL, y = Ytrain_googHL, 
                       method = 'glmnet',
                       tuneGrid = lassoGridGoogHL, 
                       trControl = trControl)
plot(elasticOutGoogHL, main = "Elastic Net - GOOG diffHighLow")



####Supervisor Y2 = YtslaWithSentiments$stockReturnTomorrow
####TSLA
#trControl = caret::trainControl(method = "repeatedcv", repeats = 2, number = 10)

lassoGridTslaSR = expand.grid(lambda = c(0.0001,0.001, 0.01, 0.05, 0.1, 0.2),
                            alpha = c(0.05,0.5,1))


elasticOutTslaSR = train(x = XtrainMat_tslaSR, y = Ytrain_tslaSR, 
                       method = 'glmnet',
                       tuneGrid = lassoGridTslaSR, 
                       trControl = trControl)
plot(elasticOutTslaSR, main = "Elastic Net - TSLA stockReturn")

####GOOG
#trControl = caret::trainControl(method = "repeatedcv", repeats = 2, number = 10)

lassoGridGoogSR = expand.grid(lambda = c(0.0001,0.001, 0.01, 0.05, 0.1, 0.2),
                            alpha = c(0.05,0.5,1))


elasticOutGoogSR = train(x = XtrainMat_googSR, y = Ytrain_googSR, 
                       method = 'glmnet',
                       tuneGrid = lassoGridGoogSR, 
                       trControl = trControl)
plot(elasticOutGoogSR, main = "Elastic Net - GOOG stockReturn")


#List of turning parameters
tunePara = rbind(
  elasticOutTslaHL$bestTune,
  elasticOutTslaSR$bestTune,
  elasticOutGoogHL$bestTune,
  elasticOutGoogSR$bestTune
  )

row.names(tunePara) = c("TSLA - diffHighLow", "TSLA - stockReturn",
                "GOOG - diffHighLow", "GOOG - stockReturn")

knitr::kable(
 tunePara,
 col.names = c("alpha","lambda"),
 caption   = "Table 1: Optimal tuning parameters for Elastic Penalized  regression",
 align     = "lccrr"
)

```


```{r elasticNet}
####Supervisor Y1 = YtslaStandardizedWithDummy$diffHighLowTomorrow
####TSLA
glmnetOutTslaHL       = glmnet(x = XtrainMat_tslaHL, y = Ytrain_tslaHL, 
                               alpha = elasticOutTslaHL$bestTune$alpha)
betaHatGlmnetTslaHL   = coef(glmnetOutTslaHL, 
                             s = elasticOutTslaHL$bestTune$lambda)
YhatTrainGlmnetTslaHL = predict(glmnetOutTslaHL, XtrainMat_tslaHL, 
                                s = elasticOutTslaHL$bestTune$lambda)

residualsTslaHL = Ytrain_tslaHL - YhatTrainGlmnetTslaHL
plot(YhatTrainGlmnetTslaHL, residualsTslaHL, 
     xlab = "Traning predictions - TSLA diffHighLow",
     ylab = "Residuals", main = "Residual Plot - TSLA diffHighLow")

####GOOG
glmnetOutGoogHL       = glmnet(x = XtrainMat_googHL, y = Ytrain_googHL, 
                               alpha = elasticOutGoogHL$bestTune$alpha)
betaHatGlmnetGoogHL   = coef(glmnetOutGoogHL, 
                             s = elasticOutGoogHL$bestTune$lambda)
YhatTrainGlmnetGoogHL = predict(glmnetOutGoogHL, XtrainMat_googHL, 
                                s = elasticOutGoogHL$bestTune$lambda )

residualsGoogHL = Ytrain_googHL - YhatTrainGlmnetGoogHL
plot(YhatTrainGlmnetGoogHL, residualsGoogHL, 
     xlab = "Traning predictions - GOOG diffHighLow",
     ylab = "Residuals", main = "Residual Plot - GOOG diffHighLow")

####Supervisor Y2 = YtslaStandardizedWithDummy$stockReturnTomorrow
####TSLA
glmnetOutTslaSR       = glmnet(x = XtrainMat_tslaSR, y = Ytrain_tslaSR, 
                               alpha = elasticOutTslaSR$bestTune$alpha)
betaHatGlmnetTslaSR   = coef(glmnetOutTslaSR, 
                             s = elasticOutTslaSR$bestTune$lambda)
YhatTrainGlmnetTslaSR = predict(glmnetOutTslaSR, XtrainMat_tslaSR, 
                                s = elasticOutTslaSR$bestTune$lambda)

residualsTslaSR = Ytrain_tslaSR - YhatTrainGlmnetTslaSR
plot(YhatTrainGlmnetTslaSR, residualsTslaSR, 
     xlab = "Traning predictions - TSLA Stock Return",
     ylab = "Residuals", main = "Residual Plot - TSLA stockReturn")

####GOOG
glmnetOutGoogSR       = glmnet(x = XtrainMat_googSR, y = Ytrain_googSR,
                               alpha = elasticOutGoogSR$bestTune$alpha)
betaHatGlmnetGoogSR   = coef(glmnetOutGoogSR, 
                             s = elasticOutGoogSR$bestTune$lambda)
YhatTrainGlmnetGoogSR = predict(glmnetOutGoogSR, XtrainMat_googSR, 
                                s = elasticOutGoogSR$bestTune$lambda)

residualsGoogSR = Ytrain_googSR - YhatTrainGlmnetGoogSR
plot(YhatTrainGlmnetGoogSR, residualsGoogSR, 
     xlab = "Traning predictions - GOOG Stock Return",
     ylab = "Residuals", main = "Residual Plot - GOOG stockReturn")

```

####Logistic Classification
```{r logisticClassification}
set.seed(2020)
trControl = caret::trainControl(method = "repeatedcv", repeats = 5, number = 10)
tuneGridTslaSRdummy = expand.grid('alpha' = c(0,.25,.5,.75,1),
                                  'lambda' = seq(0.000001, .001, length.out = 30))
elasticOutTslaSRdummy = train(x = Xtrain_tslaSRdummy, 
                              y = as.factor(Ytrain_tslaSRdummy),
                              method = 'glmnet',
                              trControl = trControl, 
                              tuneGrid = tuneGridTslaSRdummy)
elasticOutTslaSRdummy$bestTune$alpha

glmnetOutTslaSRdummy = glmnet(x = XtrainMat_tslaSRdummy, 
                              y = as.factor(Ytrain_tslaSRdummy),
                              alpha = 0.25,
                              family = 'binomial')
probHatTest_TslaSRdummy = predict(glmnetOutTslaSRdummy, XtestMat_tslaSRdummy,
                                  s = elasticOutTslaSRdummy$bestTune$lambda,
                                  type = 'response')

YhatTestGlmnet_TslaSRdummy = ifelse(probHatTest_TslaSRdummy > 0.5, '1', '0')
YhatTest_TslaSRdummy       = predict(elasticOutTslaSRdummy,XtestMat_tslaSRdummy,
                                     s = elasticOutTslaSRdummy$lambda, 
                                     type = 'raw')

#Cross-check they're the same. #Lecture 23 notes.
table(YhatTest_TslaSRdummy,YhatTest_TslaSRdummy)

betaHatGlmnetTslaSRdummy = coef(glmnetOutTslaSRdummy, 
                                s = elasticOutTslaSRdummy$bestTune$lambda)
#Accuracy
accuracyLinear_TslaSRdummy = mean(YhatTest_TslaSRdummy==Ytest_tslaSRdummy)
probHatTest_TslaSRdummy_ = predict(elasticOutTslaSRdummy,XtestMat_tslaSRdummy,
                                   s = elasticOutTslaSRdummy$bestTune$lambda,
                                   type = 'prob')
rocOut_TslaSRdummy = pROC::roc(response = Ytest_tslaSRdummy,                   
                               probHatTest_TslaSRdummy_[,2])

plot(rocOut_TslaSRdummy, main = "ROC Plot - TSLA Stock Return (Dummy)")


####GOOG
set.seed(2020)

tuneGridGoogSRdummy = expand.grid('alpha' = c(0,.25,.5,.75,1),
                                  'lambda' = seq(0.000001, .001, length.out = 30))
elasticOutGoogSRdummy = train(x = Xtrain_googSRdummy, 
                              y = as.factor(Ytrain_googSRdummy),
                              method = 'glmnet',
                              trControl = trControl, 
                              tuneGrid = tuneGridGoogSRdummy)
elasticOutGoogSRdummy$bestTune$alpha

glmnetOutGoogSRdummy = glmnet(x = XtrainMat_googSRdummy, 
                              y = as.factor(Ytrain_googSRdummy),
                              alpha = 0.25,
                              family = 'binomial')
probHatTest_GoogSRdummy = predict(glmnetOutGoogSRdummy, XtestMat_googSRdummy,
                                  s = elasticOutGoogSRdummy$bestTune$lambda,
                                  type = 'response')

YhatTestGlmnet_GoogSRdummy = ifelse(probHatTest_GoogSRdummy > 0.5, '1', '0')
YhatTest_GoogSRdummy       = predict(elasticOutGoogSRdummy,XtestMat_googSRdummy,
                                     s = elasticOutGoogSRdummy$lambda, 
                                     type = 'raw')

#Cross-check they're the same. #Lecture 23 notes.
table(YhatTest_GoogSRdummy,YhatTest_GoogSRdummy)

betaHatGlmnetGoogSRdummy = coef(glmnetOutGoogSRdummy, 
                                s = elasticOutGoogSRdummy$bestTune$lambda)
#Accuracy
accuracyLinear_GoogSRdummy = mean(YhatTest_GoogSRdummy==Ytest_googSRdummy)
probHatTest_GoogSRdummy_ = predict(elasticOutGoogSRdummy,XtestMat_googSRdummy,
                                   s = elasticOutGoogSRdummy$bestTune$lambda,
                                   type = 'prob')
rocOut_GoogSRdummy = pROC::roc(response = Ytest_googSRdummy,                   
                               probHatTest_GoogSRdummy_[,2])

plot(rocOut_GoogSRdummy, main = "ROC Plot - GOOG Stock Return (Dummy)")



#List of Accuracy
accuracyLinear = rbind(
  accuracyLinear_TslaSRdummy,
  accuracyLinear_GoogSRdummy
  )

row.names(accuracyLinear) = c("TSLA - Stock Return(dummy)", 
                "GOOG - Stock Return(dummy)")

knitr::kable(
 accuracyLinear,
 col.names = c("Accuracy based on Testing data"),
 caption   = "Table 2: Accuracy - Logistic Elastic Net",
 align     = "lccrr"
)

```

####Nonlinear Methods

####MARS
```{r MARS_Task3}
set.seed(2020)
#trControl = caret::trainControl(method = "repeatedcv", repeats = 5, number = 10)

###TSLA
#Y1
tuneGridTslaHL      = expand.grid(degree = 1:3,
                                  nprune = 10:35)
marsOutTslaHL = train(x = XtrainMat_tslaHL, y = Ytrain_tslaHL,
                      method = 'earth', metric = 'RMSE',
                      tuneGrid = tuneGridTslaHL,
                      trControl = trControl)
marsOutTslaHL$bestTune

plot(marsOutTslaHL, main = "MARS Regression - TSLA diffHighLow")
ggplot(marsOutTslaHL)+labs( title= "MARS Regression - TSLA diffHighLow")


#Y2
tuneGridTslaSR      = expand.grid(degree = 1:3,
                                  nprune = 10:35)
marsOutTslaSR = train(x = XtrainMat_tslaSR, y = Ytrain_tslaSR,
                      method = 'earth', metric = 'RMSE',
                      tuneGrid = tuneGridTslaSR,
                      trControl = trControl)
marsOutTslaSR$bestTune
plot(marsOutTslaSR, main = "MARS Regression - TSLA stockReturn")


#Y3
tuneGridTslaSRdummy = expand.grid(degree = 1:3,
                                  nprune = c(10,20,50,100))

#trControl_tslaSRdummy = caret::trainControl(method = "repeatedcv", repeats = 2, 
#                                number = 5, classProbs = TRUE)

Ytrain_tslaSRdummy_ = as.factor(Ytrain_tslaSRdummy[Ytrain_tslaSRdummy == '1'|
                                                   Ytrain_tslaSRdummy == '0'])
Ytrain_tslaSRdummy_ = relevel(Ytrain_tslaSRdummy_, ref = '0')
levels(Ytrain_tslaSRdummy_) = c("No", "Yes")

nrow(XtrainMat_tslaSRdummy)
length(Ytrain_tslaSRdummy_)
library(mda)
set.seed(888)
marsOutTslaSRdummy = train(x = XtrainMat_tslaSRdummy, 
                           y = Ytrain_tslaSRdummy_,
                      method = 'fda',
                      metric = 'Accuracy',
                      tuneGrid = tuneGridTslaSRdummy,
                      trControl = trainControl(method = "CV",  
                                               number = 2, classProbs = TRUE))
marsOutTslaSRdummy$bestTune
plot(marsOutTslaSRdummy)



###GOOG
#Y1
tuneGridGoogHL      = expand.grid(degree = 1:3,
                                  nprune = 10:35)
marsOutGoogHL = train(x = XtrainMat_googHL, y = Ytrain_googHL,
                      method = 'earth', metric = 'RMSE',
                      tuneGrid = tuneGridGoogHL,
                      trControl = trControl)
marsOutGoogHL$bestTune
ggplot(marsOutGoogHL)+labs( title= "MARS Regression - GOOG diffHighLow")

#summary(marsOutGoogHL) %>% .$coefficients %>% head(10)


#Y2
tuneGridGoogSR      = expand.grid(degree = 1:3,
                                  nprune = 10:35)
marsOutGoogSR = train(x = XtrainMat_googSR, y = Ytrain_googSR,
                      method = 'earth', metric = 'RMSE',
                      tuneGrid = tuneGridGoogSR,
                      trControl = trControl)
marsOutGoogSR$bestTune
plot(marsOutGoogSR, main = "MARS Regression - GOOG stockReturn")
#Y3
tuneGridGoogSRdummy = expand.grid(degree = 1:3,
                                  nprune = c(10,20,50,100))
trControl_googSRdummy = caret::trainControl(method = "repeatedcv", repeats = 2, 
                                number = 10, classProbs = TRUE)
Ytrain_googSRdummy_ = as.factor(Ytrain_googSRdummy[Ytrain_googSRdummy == '1'|
                                                   Ytrain_googSRdummy == '0'])
Ytrain_googSRdummy_ = relevel(Ytrain_googSRdummy_, ref = '0')


levels(Ytrain_googSRdummy_) = c("No", "Yes")
library(mda)
set.seed(888)
marsOutGoogSRdummy = train(x = XtrainMat_googSRdummy, 
                           y = Ytrain_googSRdummy_,
                      method = 'fda',
                      metric = 'Accuracy',
                      tuneGrid = tuneGridGoogSRdummy,
                      trControl = trControl_googSRdummy)

marsOutGoogSRdummy$bestTune
plot(marsOutGoogSRdummy)


###Summary
ggplot(marsOutTslaHL)+labs( title= "MARS Regression - TSLA diffHighLow")
ggplot(marsOutTslaSR)+labs( title= "MARS Regression - TSLA stockReturn")
ggplot(marsOutTslaSRdummy)+labs(title= "MARS Classification - TSLA stockReturn(dummy)")
ggplot(marsOutGoogHL)+labs( title= "MARS Regression - GOOG diffHighLow")
ggplot(marsOutGoogSR)+labs( title= "MARS Regression - GOOG stockReturn")
ggplot(marsOutGoogSRdummy)+labs(title= "MARS Classification - GOOG stockReturn(dummy)")

#List of Tuning Parameters
tuneParaMars = rbind(
  marsOutTslaHL$bestTune,
  marsOutTslaSR$bestTune,
  marsOutTslaSRdummy$bestTune,
  marsOutGoogHL$bestTune,
  marsOutGoogSR$bestTune,
  marsOutGoogSRdummy$bestTune
  )


row.names(tuneParaMars) = c("TSLA - diffHighLow", "TSLA - stockReturn", 
                            "TSLA - stockReturn(Dummy)","GOOG - diffHighLow", 
                            "GOOG - stockReturn","GOOG - stockReturn(Dummy)")

knitr::kable(
 tuneParaMars,
 col.names = c("nprune", "degree"),
 caption   = "Table 3: MARS regression and Classification - Tuning Parameters",
 align     = "lccrr"
)

#Importance

marsTslaHLvip = vip(marsOutTslaHL, num_features = 50, bar = FALSE, value = "gcv") +
  ggtitle("Plot of Variable Importance: TSLA - diffHighLow")
plot(marsTslaHLvip)

marsTslaSRvip = vip(marsOutTslaSR, num_features = 50, bar = FALSE, value = "gcv") +
  ggtitle("Plot of Variable Importance: TSLA - stockReturn")
plot(marsTslaSRvip)

marsTslaSRdummyvip = vip(marsOutTslaSRdummy, num_features = 50, bar = FALSE, value = "gcv") + ggtitle("Plot of Variable Importance: TSLA - stockReturn(dummy)")
plot(marsTslaSRdummyvip)


marsGoogHLvip = vip(marsOutGoogHL, num_features = 50, bar = FALSE, value = "gcv") +
  ggtitle("Plot of Variable Importance: GOOG - diffHighLow")
plot(marsGoogHLvip)

marsGoogSRvip = vip(marsOutGoogSR, num_features = 50, bar = FALSE, value = "gcv") +
  ggtitle("Plot of Variable Importance: GOOG - stockReturn")
plot(marsGoogSRvip)

marsGoogSRdummyvip = vip(marsOutGoogSRdummy, num_features = 50, bar = FALSE, value = "gcv") + ggtitle("Plot of Variable Importance: GOOG - stockReturn(dummy)")
plot(marsGoogSRdummyvip)


```

####Classification Tree

```{r classificationTree}
set.seed(2022)
cl = parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
####TSLA
#trControl = caret::trainControl(method = "repeatedcv", repeats = 5, 
#                                number = 10, classProbs = TRUE)
#Y1
tuneGridTree_TslaHL = expand.grid(cp = c(0.0001,0.001,0.01,0.1,0.15,0.5,1))
rpartOut_TslaHL     = train(x = XtrainMat_tslaHL, y = Ytrain_tslaHL,
                            method = "rpart",
                            tuneGrid = tuneGridTree_TslaHL,
                            trControl = trControl)
plot(rpartOut_TslaHL$finalModel, margin = rep(.1,4),
     main = "Classification Tree - TSLA diffHighLow")
text(rpartOut_TslaHL$finalModel, cex = 0.6, digits = 1)


#Y2
tuneGridTree_TslaSR = expand.grid(cp = c(0.0001,0.001,0.01,0.1,0.15,0.5,1))
rpartOut_TslaSR     = train(x = XtrainMat_tslaSR, y = Ytrain_tslaSR,
                            method = "rpart",
                            tuneGrid = tuneGridTree_TslaSR,
                            trControl = trControl,
                            control = rpart.control(minsplit = 1, minbucket = 1))
rpartOut_TslaSR$finalModel #just a root
#plot(rpartOut_TslaSR$finalModel, margin = rep(.1,4))
#text(rpartOut_TslaSR$finalModel, cex = 0.6, digits = 1)


#Y3
tuneGridTree_TslaSRdummy = expand.grid(cp = c(0,0.0001,0.001,0.01,0.1,0.15,0.5,1))
rpartOut_TslaSRdummy     = train(x = XtrainMat_tslaSRdummy, 
                                 y = Ytrain_tslaSRdummy_,
                            method = "rpart",
                            #parms = list(prior = c(.65,.35),split = "gini"),
                            parms = list(split = "gini"),
                            tuneGrid = tuneGridTree_TslaSRdummy,
                            trControl = trControl)
#plot(rpartOut_TslaSRdummy$finalModel, margin = rep(.1,4),
#     main = "Classification Tree - TSLA stockReturn(dummy)")
#text(rpartOut_TslaSRdummy$finalModel, cex = 0.6, digits = 1)



####GOOG
#trControl = caret::trainControl(method = "repeatedcv", repeats = 5, 
                               # number = 10, classProbs = TRUE)
#Y1
tuneGridTree_GoogHL = expand.grid(cp = c(0,0.0001,0.001,0.01,0.1,0.15,0.5,1))
rpartOut_GoogHL     = train(x = XtrainMat_googHL, y = Ytrain_googHL,
                            method = "rpart",
                            tuneGrid = tuneGridTree_GoogHL,
                            trControl = trControl,
                            control = rpart.control(minsplit = 1, 
                                                    minbucket = 1))
plot(rpartOut_GoogHL$finalModel, margin = rep(.1,4),
     main = "Classification Tree - GOOG diffHighLow")
text(rpartOut_GoogHL$finalModel, cex = 0.6, digits = 1)
#Y2
tuneGridTree_GoogSR = expand.grid(cp = c(0,0.0001,0.001,0.01,0.1,0.15,0.5,1))
rpartOut_GoogSR     = train(x = XtrainMat_googSR, y = Ytrain_googSR,
                            method = "rpart",
                            tuneGrid = tuneGridTree_GoogSR,
                            trControl = trControl,
                            control = rpart.control(minsplit = 1, minbucket = 1))
rpartOut_GoogSR$finalModel #just a root
#plot(rpartOut_GoogSR$finalModel, margin = rep(.1,4))
#text(rpartOut_TslaSR$finalModel, cex = 0.6, digits = 1)


#Y3
tuneGridTree_GoogSRdummy = expand.grid(cp = c(0,0.0001,0.001,0.01,0.05,0.1,0.15,1))
rpartOut_GoogSRdummy     = train(x = XtrainMat_googSRdummy, 
                                 y = Ytrain_googSRdummy_,
                            method = "rpart",
                            parms = list(split = "gini"),
                            tuneGrid = tuneGridTree_GoogSRdummy,
                            trControl = trControl,
                            control = rpart.control(minsplit = 1, minbucket = 1))
#one root
rpartOut_GoogSRdummy$finalModel
#plot(rpartOut_GoogSRdummy$finalModel, margin = rep(.1,4))
#text(rpartOut_GoogSRdummy$finalModel, cex = 0.6, digits = 1)


```

####Random Forest

```{r randomForest}
set.seed(2020)
cl = parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
####TSLA
#trControl = caret::trainControl(method = "repeatedcv", repeats = 5, 
#                                number = 10, classProbs = TRUE)
#Y1
tuneGridRanger_TslaHL = data.frame(splitrule = "variance", min.node.size = 5,
                                   mtry = round(sqrt(ncol(Xtrain_tslaHL))))
rfOut_tslaHL  = train(x = XtrainMat_tslaHL, y = Ytrain_tslaHL, 
                      method = "ranger",
                      num.trees = 500,
                      tuneGrid = tuneGridRanger_TslaHL, 
                      importance = "permutation",
                      trControl = trControl)
rfOut_tslaHL$finalModel

#print(rfOut_tslaHL)
#Y2
tuneGridRanger_TslaSR = data.frame(splitrule = "variance", min.node.size = 5,
                                   mtry = round(sqrt(ncol(Xtrain_tslaSR))))
rfOut_tslaSR  = train(x = XtrainMat_tslaSR, y = Ytrain_tslaSR, 
                      method = "ranger",
                      num.trees = 500,
                      tuneGrid = tuneGridRanger_TslaSR, 
                      importance = "permutation",
                      trControl = trControl)
rfOut_tslaSR$finalModel

#Y3
tuneGridRanger_TslaSRdummy = data.frame(splitrule = "gini", min.node.size = 10,
                                   mtry = round(sqrt(ncol(Xtrain_tslaSRdummy))))
rfOut_tslaSRdummy  = train(x = XtrainMat_tslaSRdummy, 
                           y = as.matrix(Ytrain_tslaSRdummy_) , 
                      method = "ranger",
                      num.trees = 500,
                      tuneGrid = tuneGridRanger_TslaSRdummy, 
                      importance = "permutation",
                      trControl = trControl,
                      classification = TRUE)
rfOut_tslaSRdummy$finalModel

####GOOG
#trControl = caret::trainControl(method = "repeatedcv", repeats = 5, 
#                                number = 10, classProbs = TRUE)
#Y1
tuneGridRanger_GoogHL = data.frame(splitrule = "variance", min.node.size = 5,
                                   mtry = round(sqrt(ncol(Xtrain_googHL))))
rfOut_googHL  = train(x = XtrainMat_googHL, y = Ytrain_googHL, 
                      method = "ranger",
                      num.trees = 500,
                      tuneGrid = tuneGridRanger_GoogHL, 
                      importance = "permutation",
                      trControl = trControl)
rfOut_googHL$finalModel

#Y2
tuneGridRanger_GoogSR = data.frame(splitrule = "variance", min.node.size = 5,
                                   mtry = round(sqrt(ncol(Xtrain_googSR))))
rfOut_googSR  = train(x = XtrainMat_googSR, y = Ytrain_googSR, 
                      method = "ranger",
                      num.trees = 500,
                      tuneGrid = tuneGridRanger_GoogSR, 
                      importance = "permutation",
                      trControl = trControl)
rfOut_googSR$finalModel

#Y3

tuneGridRanger_GoogSRdummy = data.frame(splitrule = "gini", min.node.size = 10,
                                   mtry = round(sqrt(ncol(Xtrain_googSRdummy))))
rfOut_googSRdummy  = train(x = XtrainMat_googSRdummy, y =as.matrix(Ytrain_googSRdummy_), 
                      method = "ranger",
                      num.trees = 500,
                      tuneGrid = tuneGridRanger_GoogSRdummy, 
                      importance = "permutation",
                      trControl = trControl)
rfOut_googSRdummy$finalModel


#List of Tuning Parameters
tuneParaRF = rbind(
  rfOut_tslaHL$bestTune,
  rfOut_tslaSR$bestTune,
  rfOut_tslaSRdummy$bestTune,
  rfOut_googHL$bestTune,
  rfOut_googSR$bestTune,
  rfOut_googSRdummy$bestTune
  )


row.names(tuneParaRF) = c("TSLA - diffHighLow", "TSLA - stockReturn", 
                            "TSLA - stockReturn(Dummy)","GOOG - diffHighLow", 
                            "GOOG - stockReturn","GOOG - stockReturn(Dummy)")

knitr::kable(
 tuneParaRF,
 col.names = c("mtry", "splitrule", "min.node.size"),
 caption   = "Table 4: Random Forest regression and Classification - Tuning Parameters",
 align     = "lccrr"
)

```

####Boosting

```{r boosting}
set.seed(2020)
cl = parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
####TSLA
#Y1
tuneGridRandom_TslaHL = expand.grid('nrounds'= c(50,150,500,1000,2000,3000),
                                   'max_depth' = 6,
                                   'eta' = c(0.01,0.03,0.05),
                                   'gamma' = 0,
                                   'colsample_bytree' = 1,
                                   'min_child_weight' = 0,
                                   'subsample' = c(0.5, 0.8))

boostOutRandom_TslaHL = train(x = Xtrain_tslaHL, y = Ytrain_tslaHL,
                              method = 'xgbTree', verbose = 0,
                              tuneGrid = tuneGridRandom_TslaHL,
                              trControl = trControl)
plot(boostOutRandom_TslaHL)

#Y2

tuneGridRandom_TslaSR = expand.grid('nrounds'= c(50,150,500,1000,2000,3000),
                                   'max_depth' = 6,
                                   'eta' = c(0.01,0.03,0.05),
                                   'gamma' = 0,
                                   'colsample_bytree' = 1,
                                   'min_child_weight' = 0,
                                   'subsample' = c(0.5, 0.8))

boostOutRandom_TslaSR = train(x = Xtrain_tslaSR, y = Ytrain_tslaSR,
                              method = 'xgbTree', verbose = 0,
                              tuneGrid = tuneGridRandom_TslaSR,
                              trControl = trControl)
plot(boostOutRandom_TslaSR)
boostOutRandom_TslaSR$bestTune$nrounds

#Y3
cl = parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
tuneGridRandom_TslaSRdummy = expand.grid(
                                   'nrounds'= c(50,150,500,1000,2000,3000),
                                   'max_depth' = 6,
                                   'eta' = c(0.01,0.03,0.05),
                                   'gamma' = 0,
                                   'colsample_bytree' = 1,
                                   'min_child_weight' = 0,
                                   'subsample' = c(0.5, 0.8))

boostOutRandom_TslaSRdummy = train(x = Xtrain_tslaSRdummy, 
                                   y = Ytrain_tslaSRdummy_,
                              method = 'xgbTree', verbose = 0,
                              tuneGrid = tuneGridRandom_TslaSRdummy,
                              trControl = trControl)
plot(boostOutRandom_TslaSRdummy)






####GOOG
#Y1
tuneGridRandom_GoogHL = expand.grid('nrounds'= c(50,150,500,1000,2000,3000),
                                   'max_depth' = 6,
                                   'eta' = c(0.01,0.03,0.05),
                                   'gamma' = 0,
                                   'colsample_bytree' = 1,
                                   'min_child_weight' = 0,
                                   'subsample' = c(0.5, 0.8))

boostOutRandom_GoogHL = train(x = Xtrain_googHL, y = Ytrain_googHL,
                              method = 'xgbTree', verbose = 0,
                              tuneGrid = tuneGridRandom_GoogHL,
                              trControl = trControl)
plot(boostOutRandom_GoogHL)

#Y2
tuneGridRandom_GoogSR = expand.grid('nrounds'= c(50,150,500,1000,2000,3000),
                                   'max_depth' = 6,
                                   'eta' = c(0.01,0.03,0.05),
                                   'gamma' = 0,
                                   'colsample_bytree' = 1,
                                   'min_child_weight' = 0,
                                   'subsample' = c(0.5, 0.8))

boostOutRandom_GoogSR = train(x = Xtrain_googSR, y = Ytrain_googSR,
                              method = 'xgbTree', verbose = 0,
                              tuneGrid = tuneGridRandom_GoogSR,
                              trControl = trControl)
plot(boostOutRandom_GoogSR)
boostOutRandom_GoogSR$bestTune$nrounds

#Y3
tuneGridRandom_GoogSRdummy = expand.grid(
                                   'nrounds'= c(50,150,500,1000,2000,3000),
                                   'max_depth' = 6,
                                   'eta' = c(0.01,0.03,0.05),
                                   'gamma' = 0,
                                   'colsample_bytree' = 1,
                                   'min_child_weight' = 0,
                                   'subsample' = c(0.5, 0.8))

boostOutRandom_GoogSRdummy = train(x = Xtrain_googSRdummy, 
                                   y = Ytrain_googSRdummy_,
                              method = 'xgbTree', verbose = 0,
                              tuneGrid = tuneGridRandom_GoogSRdummy,
                              trControl = trControl)
plot(boostOutRandom_GoogSRdummy)

boostOutRandom_GoogSRdummy$bestTune

###Overview

plot(boostOutRandom_TslaHL, main = "Boosting: TSLA diffHighLow")
plot(boostOutRandom_TslaSR, main = "Boosting: TSLA stockReturn")
plot(boostOutRandom_TslaSRdummy, main = "Boosting: TSLA stockReturn(Dummy)")

plot(boostOutRandom_GoogHL, main = "Boosting: GOOG diffHighLow")
plot(boostOutRandom_GoogSR, main = "Boosting: GOOG stockReturn")
plot(boostOutRandom_GoogSRdummy, main = "Boosting: GOOG stockReturn(Dummy)")


#List of Tuning Parameters
tuneParaBoost = rbind(
  boostOutRandom_TslaHL$bestTune,
  boostOutRandom_TslaSR$bestTune,
  boostOutRandom_TslaSRdummy$bestTune,
  boostOutRandom_GoogHL$bestTune,
  boostOutRandom_GoogSR$bestTune,
  boostOutRandom_GoogSRdummy$bestTune
  )


row.names(tuneParaBoost) = c("TSLA - diffHighLow", "TSLA - stockReturn", 
                            "TSLA - stockReturn(Dummy)","GOOG - diffHighLow", 
                            "GOOG - stockReturn","GOOG - stockReturn(Dummy)")

knitr::kable(
 tuneParaBoost,
 col.names = c("nrounds","max_depth","eta","gamma","colsample_bytree",
               "min_child_weight","subsample"),
 caption   = "Table 5: Boosting regression and Classification - Tuning Parameters",
 align     = "lccrr"
)

```

####Performance Review

```{r importanceBoosting}
####TSLA
(boostImportance_TslaHL = xgboost::xgb.importance(model = boostOutRandom_TslaHL$finalModel))

(boostImportance_TslaSR = xgboost::xgb.importance(model = boostOutRandom_TslaSR$finalModel))

(boostImportance_TslaSRdummy = xgboost::xgb.importance(model = boostOutRandom_TslaSRdummy$finalModel))

####GOOG
(boostImportance_GoogHL = xgboost::xgb.importance(model = boostOutRandom_GoogHL$finalModel))

(boostImportance_GoogSR = xgboost::xgb.importance(model = boostOutRandom_GoogSR$finalModel))

(boostImportance_GoogSRdummy = xgboost::xgb.importance(model = boostOutRandom_GoogSRdummy$finalModel))
```

```{r judgePerformance}
set.seed(2020)
################Regression
####TSLA
#Y1
resultsTest_TslaHL  = data.frame(
  YhatGlmnet = c(predict(glmnetOutTslaHL, XtestMat_tslaHL,
                         s = elasticOutTslaHL$bestTune$lambda)),
  YhatMARS   = c(predict(marsOutTslaHL, XtestMat_tslaHL)),
  YhatTrees  = predict(rpartOut_TslaHL, XtestMat_tslaHL),
  YhatRF     = predict(rfOut_tslaHL, XtestMat_tslaHL),
  YhatBoost  = predict(boostOutRandom_TslaHL, XtestMat_tslaHL)
)

par(mar=c(7,5,4,2))
plot(1:length(resultsTest_TslaHL), 
     sapply(resultsTest_TslaHL, function(Yhat){mean((Yhat - Ytest_tslaHL)^2)}),
     xlab = '', xaxt = 'n', pch = 16, ylab = 'test error', 
     main = 'TSLA - Supervisor = difference between highest and lowest prices')
axis(1, labels = names(resultsTest_TslaHL), at = 1:ncol(resultsTest_TslaHL), las = 3)

#Y2
resultsTest_TslaSR  = data.frame(
  YhatGlmnet = c(predict(glmnetOutTslaSR, XtestMat_tslaSR,
                         s = elasticOutTslaSR$bestTune$lambda)),
  YhatMARS   = c(predict(marsOutTslaSR, XtestMat_tslaSR)),
  YhatTrees  = predict(rpartOut_TslaSR, XtestMat_tslaSR),
  YhatRF     = predict(rfOut_tslaSR, XtestMat_tslaSR),
  YhatBoost  = predict(boostOutRandom_TslaSR, XtestMat_tslaSR)
)

par(mar=c(7,5,4,2))
plot(1:length(resultsTest_TslaSR), 
     sapply(resultsTest_TslaSR, function(Yhat){mean((Yhat - Ytest_tslaSR)^2)}),
     xlab = '', xaxt = 'n', pch = 16, ylab = 'test error', 
     main = 'TSLA - Supervisor = stock return')
axis(1, labels = names(resultsTest_TslaSR), at = 1:ncol(resultsTest_TslaSR), las = 3)

####GOOG
#Y1
resultsTest_GoogHL  = data.frame(
  YhatGlmnet = c(predict(glmnetOutGoogHL, XtestMat_googHL,
                         s = elasticOutGoogHL$bestTune$lambda)),
  YhatMARS   = c(predict(marsOutGoogHL, XtestMat_googHL)),
  YhatTrees  = predict(rpartOut_GoogHL, XtestMat_googHL),
  YhatRF     = predict(rfOut_googHL, XtestMat_googHL),
  YhatBoost  = predict(boostOutRandom_GoogHL, XtestMat_googHL)
)

par(mar=c(7,5,4,2))
plot(1:length(resultsTest_GoogHL), 
     sapply(resultsTest_GoogHL, function(Yhat){mean((Yhat - Ytest_googHL)^2)}),
     xlab = '', xaxt = 'n', pch = 16, ylab = 'test error', 
     main = 'GOOG - Supervisor = difference between highest and lowest prices')
axis(1, labels = names(resultsTest_GoogHL), at = 1:ncol(resultsTest_GoogHL), las = 3)

#Y2
resultsTest_GoogSR  = data.frame(
  YhatGlmnet = c(predict(glmnetOutGoogSR, XtestMat_googSR,
                         s = elasticOutGoogSR$bestTune$lambda)),
  YhatMARS   = c(predict(marsOutGoogSR, XtestMat_googSR)),
  YhatTrees  = predict(rpartOut_GoogSR, XtestMat_googSR),
  YhatRF     = predict(rfOut_googSR, XtestMat_googSR),
  YhatBoost  = predict(boostOutRandom_GoogSR, XtestMat_googSR)
)

par(mar=c(7,5,4,2))
plot(1:length(resultsTest_GoogSR), 
     sapply(resultsTest_GoogSR, function(Yhat){mean((Yhat - Ytest_googSR)^2)}),
     xlab = '', xaxt = 'n', pch = 16, ylab = 'test error', 
     main = 'GOOG - Supervisor = stock return')
axis(1, labels = names(resultsTest_GoogSR), at = 1:ncol(resultsTest_GoogSR), las = 3)










###################Classification
####TSLA
#TSLA MARS(FDA)- Y3
YhatTestFDA_TslaSRdummyProb = predict(marsOutTslaSRdummy, Xtest_tslaSRdummy,
                                  type = 'prob')
YhatTestFDA_TslaSRdummy     = ifelse(YhatTestFDA_TslaSRdummyProb[,2] > 0.5, '1','0')

table(YhatTestFDA_TslaSRdummy, Ytest_tslaSRdummy)
(TslaSRdummy_accuracyFDA = sum(diag(table(YhatTestFDA_TslaSRdummy, Ytest_tslaSRdummy)))/length(Ytest_tslaSRdummy))

#TSLA Classification Tree - Y3
YhatTestTree_TslaSRdummyProb = predict(rpartOut_TslaSRdummy, Xtest_tslaSRdummy,
                                  type = 'prob')
YhatTestTree_TslaSRdummy     = ifelse(YhatTestTree_TslaSRdummyProb[,2] > 0.5, '1','0')
table(YhatTestTree_TslaSRdummy, Ytest_tslaSRdummy)
(TslaSRdummy_accuracyTree = sum(diag(table(YhatTestTree_TslaSRdummy, Ytest_tslaSRdummy)))/length(Ytest_tslaSRdummy))

#TSLA Random Forest - Y3

YhatTestRF_TslaSRdummyRaw = predict(rfOut_tslaSRdummy, XtestMat_tslaSRdummy,
                                  type = 'raw')
YhatTestRF_TslaSRdummy     = ifelse(YhatTestRF_TslaSRdummyRaw == "Yes", '1','0')

table(YhatTestRF_TslaSRdummy, Ytest_tslaSRdummy)
(TslaSRdummy_accuracyRF = sum(diag(table(YhatTestRF_TslaSRdummy, Ytest_tslaSRdummy)))/length(Ytest_tslaSRdummy))

#TSLA Boosting - Y3
YhatTestBoost_TslaSRdummyProb = predict(boostOutRandom_TslaSRdummy,
                                        XtestMat_tslaSRdummy,type = 'prob')
YhatTestBoost_TslaSRdummy     = ifelse(YhatTestBoost_TslaSRdummyProb[,2] > 0.5, '1','0')

table(YhatTestBoost_TslaSRdummy, Ytest_tslaSRdummy)
(TslaSRdummy_accuracyBoost = sum(diag(table(YhatTestBoost_TslaSRdummy, Ytest_tslaSRdummy)))/length(Ytest_tslaSRdummy))

#Summary - TSLA - Classification
resultsTestClass_Tsla = data.frame(
  accuracyFDA  = TslaSRdummy_accuracyFDA,
  accuracyTree = TslaSRdummy_accuracyTree,
  accuracyRF = TslaSRdummy_accuracyRF,
  accuracyBoost = TslaSRdummy_accuracyBoost
)
par(mar=c(7,5,4,2))
plot(1:length(resultsTestClass_Tsla), 
     resultsTestClass_Tsla,
     xlab = '', xaxt = 'n', pch = 16, ylab = 'accuracy', 
     main = 'TSLA - Supervisor = stock return (dummy)')
axis(1, labels = names(resultsTestClass_Tsla), at = 1:ncol(resultsTestClass_Tsla), las = 3)


####GOOG
#GOOG MARS(FDA) - Y3
YhatTestFDA_GoogSRdummyProb = predict(marsOutGoogSRdummy, Xtest_googSRdummy,
                                  type = 'prob')

YhatTestFDA_GoogSRdummy     = ifelse(YhatTestFDA_GoogSRdummyProb[,2] > 0.5, '1','0')

table(YhatTestFDA_GoogSRdummy, Ytest_googSRdummy)
(GoogSRdummy_accuracyFDA = sum(diag(table(YhatTestFDA_GoogSRdummy, Ytest_googSRdummy)))/length(Ytest_googSRdummy))

#GOOG Classification Tree - Y3
YhatTestTree_GoogSRdummyProb = predict(rpartOut_GoogSRdummy, Xtest_googSRdummy,
                                  type = 'prob')
YhatTestTree_GoogSRdummy     = ifelse(YhatTestTree_GoogSRdummyProb[,2] > 0.5, '1','0')
table(YhatTestTree_GoogSRdummy, Ytest_googSRdummy)
(GoogSRdummy_accuracyTree = sum(diag(table(YhatTestTree_GoogSRdummy, Ytest_googSRdummy)))/length(Ytest_googSRdummy))

#GOOG Random Forest - Y3
YhatTestRF_GoogSRdummyRaw = predict(rfOut_googSRdummy, Xtest_googSRdummy,
                                  type = 'raw')

YhatTestRF_GoogSRdummy     = ifelse(YhatTestRF_GoogSRdummyRaw == "Yes", '1','0')

table(YhatTestRF_GoogSRdummy, Ytest_googSRdummy)
(GoogSRdummy_accuracyRF = sum(diag(table(YhatTestRF_GoogSRdummy, Ytest_googSRdummy)))/length(Ytest_googSRdummy))


#GOOG Boosting - Y3
YhatTestBoost_GoogSRdummyProb = predict(boostOutRandom_GoogSRdummy,
                                        XtestMat_googSRdummy,type = 'prob')
YhatTestBoost_GoogSRdummy     = ifelse(YhatTestBoost_GoogSRdummyProb[,2] > 0.5, '1','0')

table(YhatTestBoost_GoogSRdummy, Ytest_googSRdummy)
(GoogSRdummy_accuracyBoost = sum(diag(table(YhatTestBoost_GoogSRdummy, Ytest_googSRdummy)))/length(Ytest_googSRdummy))


#Summary - GOOG - Classification
resultsTestClass_Goog = data.frame(
  accuracyFDA   = GoogSRdummy_accuracyFDA,
  accuracyTree  = GoogSRdummy_accuracyTree,
  accuracyRF    = GoogSRdummy_accuracyRF,
  accuracyBoost = GoogSRdummy_accuracyBoost
)

par(mar=c(7,5,4,2))
plot(1:length(resultsTestClass_Goog), 
     resultsTestClass_Goog,
     xlab = '', xaxt = 'n', pch = 16,  ylab = 'accuracy', 
     main = 'GOOG - Supervisor = stock return (dummy)')
axis(1, labels = names(resultsTestClass_Goog), at = 1:ncol(resultsTestClass_Goog), las = 3)

```




































###### 8 - Final Task with sentiments sum


```{r dataSplitFinalTaskSum}
#Line 990
#Superviors:
  #Y1: YtslaWithSentiments$diffHighLowTomorrow
  #Y2: YtslaWithSentiments$stockReturnTomorrow
  #Y3: YtslaWithSentiments$stockReturnTomorrowDummy

#Features wtiht Sentiments:
XtslaWithSentimentsSum = XtslaWithSentiments %>%
  select(-tslaSentimentsMean)
XgoogWithSentimentsSum = XgoogWithSentiments %>%
  select(-googSentimentsMean)

#Data Split
##TSLA

#set.seed(2020)
#inTrain_tslaHL = caret::createDataPartition(YtslaWithSentiments$diffHighLowTomorrow, p = 4/5, list = FALSE) #Y1
#inTrain_tslaSR = caret::createDataPartition(YtslaWithSentiments$stockReturnTomorrow, p = 4/5, list = FALSE) #Y2
#inTrain_tslaSRdummy = caret::createDataPartition(YtslaWithSentiments$stockReturnTomorrowDummy, p = 4/5, list = FALSE) #Y3


Ytrain_tslaHL = YtslaWithSentiments$diffHighLowTomorrow[inTrain_tslaHL]
Ytest_tslaHL  = YtslaWithSentiments$diffHighLowTomorrow[-inTrain_tslaHL]
Ytrain_tslaSR = YtslaWithSentiments$stockReturnTomorrow[inTrain_tslaSR]
Ytest_tslaSR  = YtslaWithSentiments$stockReturnTomorrow[-inTrain_tslaSR]
Ytrain_tslaSRdummy = YtslaWithSentiments$stockReturnTomorrowDummy[inTrain_tslaSRdummy]
Ytest_tslaSRdummy  = YtslaWithSentiments$stockReturnTomorrowDummy[-inTrain_tslaSRdummy]


XtrainSentiSum_tslaHL = XtslaWithSentimentsSum[inTrain_tslaHL,] 
XtestSentiSum_tslaHL  = XtslaWithSentimentsSum[-inTrain_tslaHL,]
XtrainSentiSum_tslaSR = XtslaWithSentimentsSum[inTrain_tslaSR,] 
XtestSentiSum_tslaSR  = XtslaWithSentimentsSum[-inTrain_tslaSR,]
XtrainSentiSum_tslaSRdummy = XtslaWithSentimentsSum[inTrain_tslaSRdummy,]
XtestSentiSum_tslaSRdummy  = XtslaWithSentimentsSum[-inTrain_tslaSRdummy,]

###GOOG

#set.seed(2020)
#inTrain_googHL = caret::createDataPartition(YgoogWithSentiments$diffHighLowTomorrow, p = 4/5, list = FALSE) #Y1
#inTrain_googSR = caret::createDataPartition(YgoogWithSentiments$stockReturnTomorrow, p = 4/5, list = FALSE) #Y2
#inTrain_googSRdummy = caret::createDataPartition(YgoogWithSentiments$stockReturnTomorrowDummy, p = 4/5, list = FALSE) #Y3


Ytrain_googHL = YgoogWithSentiments$diffHighLowTomorrow[inTrain_googHL]
Ytest_googHL  = YgoogWithSentiments$diffHighLowTomorrow[-inTrain_googHL]
Ytrain_googSR = YgoogWithSentiments$stockReturnTomorrow[inTrain_googSR]
Ytest_googSR  = YgoogWithSentiments$stockReturnTomorrow[-inTrain_googSR]
Ytrain_googSRdummy = YgoogWithSentiments$stockReturnTomorrowDummy[inTrain_googSRdummy]
Ytest_googSRdummy  = YgoogWithSentiments$stockReturnTomorrowDummy[-inTrain_googSRdummy]


XtrainSentiSum_googHL = XgoogWithSentimentsSum[inTrain_googHL,]
XtestSentiSum_googHL  = XgoogWithSentimentsSum[-inTrain_googHL,]
XtrainSentiSum_googSR = XgoogWithSentimentsSum[inTrain_googSR,]
XtestSentiSum_googSR  = XgoogWithSentimentsSum[-inTrain_googSR,]
XtrainSentiSum_googSRdummy = XgoogWithSentimentsSum[inTrain_googSRdummy,]
XtestSentiSum_googSRdummy  =XgoogWithSentimentsSum[-inTrain_googSRdummy,]

```


```{r setupFinalTaskSum}

#Repeated cross validation
trControl = caret::trainControl(method = "repeatedcv", repeats = 5, number = 10)

XtrainMatSentiSum_tslaHL      = as.matrix(XtrainSentiSum_tslaHL)
XtestMatSentiSum_tslaHL       = as.matrix(XtestSentiSum_tslaHL)
XtrainMatSentiSum_tslaSR      = as.matrix(XtrainSentiSum_tslaSR)
XtestMatSentiSum_tslaSR       = as.matrix(XtestSentiSum_tslaSR)
XtrainMatSentiSum_tslaSRdummy = as.matrix(XtrainSentiSum_tslaSRdummy)
XtestMatSentiSum_tslaSRdummy  = as.matrix(XtestSentiSum_tslaSRdummy)

####GOOG
#Feature transformations
XtrainMatSentiSum_googHL      = as.matrix(XtrainSentiSum_googHL)
XtestMatSentiSum_googHL       = as.matrix(XtestSentiSum_googHL)
XtrainMatSentiSum_googSR      = as.matrix(XtrainSentiSum_googSR)
XtestMatSentiSum_googSR       = as.matrix(XtestSentiSum_googSR)
XtrainMatSentiSum_googSRdummy = as.matrix(XtrainSentiSum_googSRdummy)
XtestMatSentiSum_googSRdummy  = as.matrix(XtestSentiSum_googSRdummy)

#Parallelism
#cl = parallel::makeCluster(8)
#doParallel::registerDoParallel(cl)
```


```{r elasticNetTuningParameters}
set.seed(2020)
cl = parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
####Supervisor Y1 = YtslaWithSentiments$diffHighLowTomorrow
####TSLA
trControl = caret::trainControl(method = "repeatedcv", repeats = 5, number = 10)

lassoGridTslaHL_SentiSum = expand.grid(lambda = c(0.0001,0.001, 0.01, 0.05, 0.1, 0.2),
                            alpha = c(0.05,0.5,1))


elasticOutTslaHL_SentiSum = train(x = XtrainMatSentiSum_tslaHL, y = Ytrain_tslaHL, 
                       method = 'glmnet',
                       tuneGrid = lassoGridTslaHL_SentiSum, 
                       trControl = trControl)
plot(elasticOutTslaHL_SentiSum, main = "Elastic Net - TSLA diffHighLow with Sentiments(Sum)")

####GOOG
#trControl = caret::trainControl(method = "repeatedcv", repeats = 2, number = 10)

lassoGridGoogHL_SentiSum = expand.grid(lambda = c(0.0001,0.001, 0.01, 0.05, 0.1, 0.2),
                            alpha = c(0.05,0.5,1))


elasticOutGoogHL_SentiSum = train(x = XtrainMatSentiSum_googHL, y = Ytrain_googHL, 
                       method = 'glmnet',
                       tuneGrid = lassoGridGoogHL_SentiSum, 
                       trControl = trControl)
plot(elasticOutGoogHL_SentiSum, main = "Elastic Net - GOOG diffHighLow with Sentiments(Sum)")



####Supervisor Y2 = YtslaWithSentiments$stockReturnTomorrow
####TSLA
#trControl = caret::trainControl(method = "repeatedcv", repeats = 2, number = 10)

lassoGridTslaSR_SentiSum = expand.grid(lambda = c(0.0001,0.001, 0.01, 0.05, 0.1, 0.2),
                            alpha = c(0.05,0.5,1))


elasticOutTslaSR_SentiSum = train(x = XtrainMatSentiSum_tslaSR, y = Ytrain_tslaSR, 
                       method = 'glmnet',
                       tuneGrid = lassoGridTslaSR_SentiSum, 
                       trControl = trControl)
plot(elasticOutTslaSR_SentiSum, main = "Elastic Net - TSLA stockReturn with Sentiments(Sum)")

####GOOG
#trControl = caret::trainControl(method = "repeatedcv", repeats = 2, number = 10)

lassoGridGoogSR_SentiSum = expand.grid(lambda = c(0.0001,0.001, 0.01, 0.05, 0.1, 0.2),
                            alpha = c(0.05,0.5,1))


elasticOutGoogSR_SentiSum = train(x = XtrainMatSentiSum_googSR, y = Ytrain_googSR, 
                       method = 'glmnet',
                       tuneGrid = lassoGridGoogSR_SentiSum, 
                       trControl = trControl)
plot(elasticOutGoogSR_SentiSum, main = "Elastic Net - GOOG stockReturn with Sentiments(Sum)")


#List of turning parameters
tunePara = rbind(
  elasticOutTslaHL_SentiSum$bestTune,
  elasticOutTslaSR_SentiSum$bestTune,
  elasticOutGoogHL_SentiSum$bestTune,
  elasticOutGoogSR_SentiSum$bestTune
  )

row.names(tunePara) = c("TSLA - diffHighLow", "TSLA - stockReturn",
                "GOOG - diffHighLow", "GOOG - stockReturn")

knitr::kable(
 tunePara,
 col.names = c("alpha","lambda"),
 caption   = "Table 1: Optimal tuning parameters for Elastic Penalized  regression with Sentiments Sum",
 align     = "lccrr"
)

```


```{r elasticNet}
####Supervisor Y1 = YtslaStandardizedWithDummy$diffHighLowTomorrow
####TSLA
glmnetOutTslaHL_SentiSum       = glmnet(x = XtrainMatSentiSum_tslaHL, y = Ytrain_tslaHL, 
                               alpha = elasticOutTslaHL_SentiSum$bestTune$alpha)
betaHatGlmnetTslaHL_SentiSum   = coef(glmnetOutTslaHL_SentiSum, 
                             s = elasticOutTslaHL_SentiSum$bestTune$lambda)
YhatTrainGlmnetTslaHL_SentiSum = predict(glmnetOutTslaHL_SentiSum, XtrainMatSentiSum_tslaHL, 
                                s = elasticOutTslaHL_SentiSum$bestTune$lambda)

residualsTslaHL_SentiSum = Ytrain_tslaHL - YhatTrainGlmnetTslaHL_SentiSum
plot(YhatTrainGlmnetTslaHL_SentiSum, residualsTslaHL_SentiSum, 
     xlab = "Traning predictions - TSLA diffHighLow",
     ylab = "Residuals", main = "Residual Plot - TSLA diffHighLow with Sentiments(Sum)")

####GOOG

glmnetOutGoogHL_SentiSum       = glmnet(x = XtrainMatSentiSum_googHL, y = Ytrain_googHL, 
                               alpha = elasticOutGoogHL_SentiSum$bestTune$alpha)
betaHatGlmnetGoogHL_SentiSum   = coef(glmnetOutGoogHL_SentiSum, 
                             s = elasticOutGoogHL_SentiSum$bestTune$lambda)
YhatTrainGlmnetGoogHL_SentiSum = predict(glmnetOutGoogHL_SentiSum, XtrainMatSentiSum_googHL, 
                                s = elasticOutGoogHL_SentiSum$bestTune$lambda )

residualsGoogHL_SentiSum = Ytrain_googHL - YhatTrainGlmnetGoogHL_SentiSum
plot(YhatTrainGlmnetGoogHL_SentiSum, residualsGoogHL_SentiSum, 
     xlab = "Traning predictions - GOOG diffHighLow",
     ylab = "Residuals", main = "Residual Plot - GOOG diffHighLow with Sentiments(Sum)")

####Supervisor Y2 = YtslaStandardizedWithDummy$stockReturnTomorrow
####TSLA
glmnetOutTslaSR_SentiSum       = glmnet(x = XtrainMatSentiSum_tslaSR, y = Ytrain_tslaSR, 
                               alpha = elasticOutTslaSR_SentiSum$bestTune$alpha)
betaHatGlmnetTslaSR_SentiSum   = coef(glmnetOutTslaSR_SentiSum, 
                             s = elasticOutTslaSR_SentiSum$bestTune$lambda)
YhatTrainGlmnetTslaSR_SentiSum = predict(glmnetOutTslaSR_SentiSum, XtrainMatSentiSum_tslaSR, 
                                s = elasticOutTslaSR_SentiSum$bestTune$lambda)

residualsTslaSR_SentiSum = Ytrain_tslaSR - YhatTrainGlmnetTslaSR_SentiSum
plot(YhatTrainGlmnetTslaSR_SentiSum, residualsTslaSR_SentiSum, 
     xlab = "Traning predictions - TSLA Stock Return",
     ylab = "Residuals", main = "Residual Plot - TSLA stockReturn with Sentiments(Sum)")

####GOOG
glmnetOutGoogSR_SentiSum       = glmnet(x = XtrainMatSentiSum_googSR, y = Ytrain_googSR,
                               alpha = elasticOutGoogSR_SentiSum$bestTune$alpha)
betaHatGlmnetGoogSR_SentiSum   = coef(glmnetOutGoogSR_SentiSum, 
                             s = elasticOutGoogSR_SentiSum$bestTune$lambda)
YhatTrainGlmnetGoogSR_SentiSum = predict(glmnetOutGoogSR_SentiSum, XtrainMatSentiSum_googSR, 
                                s = elasticOutGoogSR_SentiSum$bestTune$lambda)

residualsGoogSR_SentiSum = Ytrain_googSR - YhatTrainGlmnetGoogSR
plot(YhatTrainGlmnetGoogSR, residualsGoogSR_SentiSum, 
     xlab = "Traning predictions - GOOG Stock Return",
     ylab = "Residuals", main = "Residual Plot - GOOG stockReturn with Sentiments(Sum)")

```

####Logistic Classification
```{r logisticClassificationSum}
set.seed(2020)
trControl = caret::trainControl(method = "repeatedcv", repeats = 5, number = 10)
tuneGridTslaSRdummy = expand.grid('alpha' = c(0,.25,.5,.75,1),
                                  'lambda' = seq(0.000001, .001, length.out = 30))
elasticOutTslaSRdummy_SentiSum = train(x = XtrainSentiSum_tslaSRdummy, 
                              y = as.factor(Ytrain_tslaSRdummy_),
                              method = 'glmnet',
                              trControl = trControl, 
                              tuneGrid = tuneGridTslaSRdummy)

glmnetOutTslaSRdummy_SentiSum = glmnet(x = XtrainMatSentiSum_tslaSRdummy, 
                              y = as.factor(Ytrain_tslaSRdummy_),
                              alpha = 0.25,
                              family = 'binomial')
probHatTestSentiSum_TslaSRdummy = predict(glmnetOutTslaSRdummy_SentiSum,
                                  XtestMatSentiSum_tslaSRdummy,
                                  s = elasticOutTslaSRdummy_SentiSum$bestTune$lambda,
                                  type = 'response')

YhatTestGlmnetSentiSum_TslaSRdummy = ifelse(probHatTestSentiSum_TslaSRdummy > 0.5, '1', '0')
YhatTestSentiSum_TslaSRdummy       = predict(elasticOutTslaSRdummy_SentiSum,
                                             XtestMatSentiSum_tslaSRdummy,
                                     s = elasticOutTslaSRdummy_SentiSum$lambda, 
                                     type = 'raw')

#Cross-check they're the same. #Lecture 23 notes.
table(YhatTestSentiSum_TslaSRdummy,YhatTestSentiSum_TslaSRdummy)


betaHatGlmnetTslaSRdummy_SentiSum = coef(glmnetOutTslaSRdummy_SentiSum, 
                                s = elasticOutTslaSRdummy_SentiSum$bestTune$lambda)
#Accuracy
accuracyLinearSentiSum_TslaSRdummy = mean(YhatTestSentiSum_TslaSRdummy==Ytest_tslaSRdummy)

probHatTestSentiSum_TslaSRdummy_ = predict(elasticOutTslaSRdummy_SentiSum,
                                           XtestMatSentiSum_tslaSRdummy,
                                   s = elasticOutTslaSRdummy_SentiSum$bestTune$lambda,
                                   type = 'prob')
rocOutSentiSum_TslaSRdummy = pROC::roc(response = Ytest_tslaSRdummy,                   
                               probHatTestSentiSum_TslaSRdummy_[,2])

plot(rocOutSentiSum_TslaSRdummy, main = "ROC Plot - TSLA Stock Return (Dummy) with Sentiments(Sum)")






####GOOG
set.seed(2020)

tuneGridGoogSRdummy = expand.grid('alpha' = c(0,.25,.5,.75,1),
                                  'lambda' = seq(0.000001, .001, length.out = 30))
elasticOutGoogSRdummy_SentiSum = train(x = XtrainSentiSum_googSRdummy, 
                              y = as.factor(Ytrain_googSRdummy),
                              method = 'glmnet',
                              trControl = trControl, 
                              tuneGrid = tuneGridGoogSRdummy)


glmnetOutGoogSRdummy_SentiSum = glmnet(x = XtrainMatSentiSum_googSRdummy, 
                              y = as.factor(Ytrain_googSRdummy),
                              alpha = 0.25,
                              family = 'binomial')
probHatTestSentiSum_GoogSRdummy = predict(glmnetOutGoogSRdummy_SentiSum,
                                           XtestMatSentiSum_googSRdummy,
                                  s = elasticOutGoogSRdummy_SentiSum$bestTune$lambda,
                                  type = 'response')

YhatTestGlmnetSentiSum_GoogSRdummy = ifelse(probHatTest_GoogSRdummy_SentiSum > 0.5,
                                             '1', '0')
YhatTestSentiSum_GoogSRdummy       = predict(elasticOutGoogSRdummy_SentiSum,
                                             XtestMatSentiSum_googSRdummy,
                                     s = elasticOutGoogSRdummy_SentiSum$lambda, 
                                     type = 'raw')

#Cross-check they're the same. #Lecture 23 notes.
table(YhatTestSentiSum_GoogSRdummy,YhatTestSentiSum_GoogSRdummy)

betaHatGlmnetGoogSRdummy_SentiSum = coef(glmnetOutGoogSRdummy_SentiSum, 
                                s = elasticOutGoogSRdummy_SentiSum$bestTune$lambda)
#Accuracy
accuracyLinearSentiSum_GoogSRdummy = mean(YhatTestSentiSum_GoogSRdummy==Ytest_googSRdummy)
probHatTestSentiSum_GoogSRdummy_ = predict(elasticOutGoogSRdummy_SentiSum,
                                           XtestMatSentiSum_googSRdummy,
                                   s = elasticOutGoogSRdummy_SentiSum$bestTune$lambda,
                                   type = 'prob')
rocOutSentiSum_GoogSRdummy = pROC::roc(response = Ytest_googSRdummy,                   
                                       probHatTestSentiSum_GoogSRdummy_[,2])

plot(rocOutSentiSum_GoogSRdummy, 
     main = "ROC Plot - GOOG Stock Return (Dummy) with Sentiments(Sum)")



#List of Accuracy
accuracyLinearSentiSum = rbind(
  accuracyLinearSentiSum_TslaSRdummy,
  accuracyLinearSentiSum_GoogSRdummy
  )

row.names(accuracyLinearSentiSum) = c("TSLA - Stock Return(dummy)", 
                "GOOG - Stock Return(dummy)")

knitr::kable(
 accuracyLinearSentiSum,
 col.names = c("Accuracy based on Testing data"),
 caption   = "Table 2: Accuracy - Logistic Elastic Net with Sentiments(Sum)",
 align     = "lccrr"
)

```

####Nonlinear Methods

####MARS
```{r MARS_Sum}
set.seed(2020)
cl = parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
trControl = caret::trainControl(method = "repeatedcv", repeats = 5, number = 10)

###TSLA
#Y1
tuneGridTslaHL      = expand.grid(degree = 1:3,
                                  nprune = 10:35)
marsOutTslaHL_SentiSum = train(x = XtrainMatSentiSum_tslaHL, y = Ytrain_tslaHL,
                      method = 'earth', metric = 'RMSE',
                      tuneGrid = tuneGridTslaHL,
                      trControl = trControl)

#plot(marsOutTslaHL_SentiSum, 
#     main = "MARS Regression - TSLA diffHighLow with Sentiments(Sum)")
#ggplot(marsOutTslaHL_SentiSum)+labs( title= "MARS Regression - TSLA diffHighLow")


#Y2
tuneGridTslaSR      = expand.grid(degree = 1:3,
                                  nprune = 10:35)
marsOutTslaSR_SentiSum = train(x = XtrainMatSentiSum_tslaSR, y = Ytrain_tslaSR,
                      method = 'earth', metric = 'RMSE',
                      tuneGrid = tuneGridTslaSR,
                      trControl = trControl)

#plot(marsOutTslaSR_SentiSum, 
#     main = "MARS Regression - TSLA stockReturn with Sentiments(Sum)")


#Y3
tuneGridTslaSRdummy = expand.grid(degree = 1:3,
                                  nprune = c(10,20,50,100))

trControl_tslaSRdummy = caret::trainControl(method = "repeatedcv", repeats = 2, 
                                 number = 10, classProbs = TRUE)

Ytrain_tslaSRdummy_ = as.factor(Ytrain_tslaSRdummy[Ytrain_tslaSRdummy == '1'|
                                                   Ytrain_tslaSRdummy == '0'])
Ytrain_tslaSRdummy_ = relevel(Ytrain_tslaSRdummy_, ref = '0')
levels(Ytrain_tslaSRdummy_) = c("No", "Yes")


library(mda)
set.seed(888)
marsOutTslaSRdummy_SentiSum = train(x = XtrainMatSentiSum_tslaSRdummy, 
                           y = Ytrain_tslaSRdummy_,
                      method = 'fda',
                      metric = 'Accuracy',
                      tuneGrid = tuneGridTslaSRdummy,
                      trControl = trainControl(method = "CV",  
                                               number = 2, classProbs = TRUE))

#plot(marsOutTslaSRdummy,
#     main = "MARS Regression - TSLA stockReturnDummy with Sentiments(Sum)")



###GOOG
#Y1
tuneGridGoogHL      = expand.grid(degree = 1:3,
                                  nprune = 10:35)
marsOutGoogHL_SentiSum = train(x = XtrainMatSentiSum_googHL, y = Ytrain_googHL,
                      method = 'earth', metric = 'RMSE',
                      tuneGrid = tuneGridGoogHL,
                      trControl = trControl)

#ggplot(marsOutGoogHL_SentiSum)+labs(title= "MARS Regression - GOOG diffHighLow with Sentiments(Sum)")

#summary(marsOutGoogHL) %>% .$coefficients %>% head(10)


#Y2
tuneGridGoogSR      = expand.grid(degree = 1:3,
                                  nprune = 10:35)
marsOutGoogSR_SentiSum = train(x = XtrainMatSentiSum_googSR, y = Ytrain_googSR,
                      method = 'earth', metric = 'RMSE',
                      tuneGrid = tuneGridGoogSR,
                      trControl = trControl)

#plot(marsOutGoogSR_SentiSum, 
#     main = "MARS Regression - GOOG stockReturn with Sentiments(Sum)")
#Y3
tuneGridGoogSRdummy = expand.grid(degree = 1:3,
                                  nprune = c(10,20,50,100))
trControl_googSRdummy = caret::trainControl(method = "repeatedcv", repeats = 2, 
                                number = 10, classProbs = TRUE)
Ytrain_googSRdummy_ = as.factor(Ytrain_googSRdummy[Ytrain_googSRdummy == '1'|
                                                   Ytrain_googSRdummy == '0'])
Ytrain_googSRdummy_ = relevel(Ytrain_googSRdummy_, ref = '0')


levels(Ytrain_googSRdummy_) = c("No", "Yes")
library(mda)
set.seed(888)
marsOutGoogSRdummy_SentiSum = train(x = XtrainMatSentiSum_googSRdummy, 
                           y = Ytrain_googSRdummy_,
                      method = 'fda',
                      metric = 'Accuracy',
                      tuneGrid = tuneGridGoogSRdummy,
                      trControl = trControl_googSRdummy)



###Summary
ggplot(marsOutTslaHL_SentiSum)+labs( title= "MARS Regression - TSLA diffHighLow with Sentiments(Sum)")
ggplot(marsOutTslaSR_SentiSum)+labs( title= "MARS Regression - TSLA stockReturn with Sentiments(Sum)")
ggplot(marsOutTslaSRdummy_SentiSum)+labs(title= "MARS Classification - TSLA stockReturn(dummy) with Sentiments(Sum)")
ggplot(marsOutGoogHL_SentiSum)+labs( title= "MARS Regression - GOOG diffHighLow with Sentiments(Sum)")
ggplot(marsOutGoogSR_SentiSum)+labs( title= "MARS Regression - GOOG stockReturn with Sentiments(Sum)")
ggplot(marsOutGoogSRdummy_SentiSum)+labs(title= "MARS Classification - GOOG stockReturn(dummy) with Sentiments(Sum)")

#List of Tuning Parameters
tuneParaMars_SentiSum = rbind(
  marsOutTslaHL_SentiSum$bestTune,
  marsOutTslaSR_SentiSum$bestTune,
  marsOutTslaSRdummy_SentiSum$bestTune,
  marsOutGoogHL_SentiSum$bestTune,
  marsOutGoogSR_SentiSum$bestTune,
  marsOutGoogSRdummy_SentiSum$bestTune
  )


row.names(tuneParaMars_SentiSum) = c("TSLA - diffHighLow", "TSLA - stockReturn", 
                            "TSLA - stockReturn(Dummy)","GOOG - diffHighLow", 
                            "GOOG - stockReturn","GOOG - stockReturn(Dummy)")

knitr::kable(
 tuneParaMars_SentiSum,
 col.names = c("nprune", "degree"),
 caption   = "Table 3: MARS regression and Classification - Tuning Parameters ( with Sentiments(Sum))",
 align     = "lccrr"
)

#Importance

marsTslaHLvip_SentiSum = vip(marsOutTslaHL_SentiSum, num_features = 50, 
                             bar = FALSE, value = "gcv") +
  ggtitle("Plot of Variable Importance with Sentiments(Sum): TSLA - diffHighLow")
plot(marsTslaHLvip_SentiSum)

marsTslaSRvip_SentiSum = vip(marsOutTslaSR_SentiSum, num_features = 50, 
                             bar = FALSE, value = "gcv") +
  ggtitle("Plot of Variable Importance with Sentiments(Sum): TSLA - stockReturn")
plot(marsTslaSRvip_SentiSum)

marsTslaSRdummyvip_SentiSum = vip(marsOutTslaSRdummy_SentiSum, num_features = 50, 
                                  bar = FALSE, value = "gcv") + ggtitle("Plot of Variable Importance with Sentiments(Sum): TSLA - stockReturn(dummy)")
plot(marsTslaSRdummyvip_SentiSum)


marsGoogHLvip_SentiSum = vip(marsOutGoogHL_SentiSum, num_features = 50, 
                             bar = FALSE, value = "gcv") +
  ggtitle("Plot of Variable Importance with Sentiments(Sum): GOOG - diffHighLow")
plot(marsGoogHLvip_SentiSum)

marsGoogSRvip_SentiSum = vip(marsOutGoogSR_SentiSum, num_features = 50, 
                             bar = FALSE, value = "gcv") +
  ggtitle("Plot of Variable Importance with Sentiments(Sum): GOOG - stockReturn")
plot(marsGoogSRvip_SentiSum)

marsGoogSRdummyvip_SentiSum = vip(marsOutGoogSRdummy_SentiSum, num_features = 50, 
                                  bar = FALSE, value = "gcv") + ggtitle("Plot of Variable Importance with Sentiments(Sum): GOOG - stockReturn(dummy)")
plot(marsGoogSRdummyvip_SentiSum)


```

####Classification Tree

```{r classificationTreeSum}
set.seed(2022)
cl = parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
####TSLA
#trControl = caret::trainControl(method = "repeatedcv", repeats = 5, 
#                                number = 10, classProbs = TRUE)
#Y1
tuneGridTree_TslaHL = expand.grid(cp = c(0.0001,0.001,0.01,0.1,0.15,0.5,1))
rpartOutSentiSum_TslaHL     = train(x = XtrainMatSentiSum_tslaHL, y = Ytrain_tslaHL,
                            method = "rpart",
                            tuneGrid = tuneGridTree_TslaHL,
                            trControl = trControl)
plot(rpartOutSentiSum_TslaHL$finalModel, margin = rep(.1,4),
     main = "Classification Tree with Sentiments(Sum) - TSLA diffHighLow")
text(rpartOutSentiSum_TslaHL$finalModel, cex = 0.6, digits = 1)



#Y2
tuneGridTree_TslaSR = expand.grid(cp = c(0.0001,0.001,0.01,0.1,0.15,0.5,1))
rpartOutSentiSum_TslaSR     = train(x = XtrainMatSentiSum_tslaSR, y = Ytrain_tslaSR,
                            method = "rpart",
                            tuneGrid = tuneGridTree_TslaSR,
                            trControl = trControl,
                            control = rpart.control(minsplit = 1, minbucket = 1))
rpartOutSentiSum_TslaSR$finalModel #just a root
#plot(rpartOut_TslaSR$finalModel, margin = rep(.1,4))
#text(rpartOut_TslaSR$finalModel, cex = 0.6, digits = 1)


#Y3
tuneGridTree_TslaSRdummy = expand.grid(cp = c(0,0.0001,0.001,0.01,0.1,0.15,0.5,1))
rpartOutSentiSum_TslaSRdummy     = train(x = XtrainMatSentiSum_tslaSRdummy, 
                                 y = Ytrain_tslaSRdummy_,
                            method = "rpart",
                            #parms = list(prior = c(.65,.35),split = "gini"),
                            parms = list(split = "gini"),
                            tuneGrid = tuneGridTree_TslaSRdummy,
                            trControl = trControl)

plot(rpartOutSentiSum_TslaSRdummy$finalModel, margin = rep(.1,4),
    main = "Classification Tree with Sentiments(Sum) - TSLA stockReturn(dummy)")
text(rpartOutSentiSum_TslaSRdummy$finalModel, cex = 0.6, digits = 1)



####GOOG
set.seed(2022)
cl = parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
#trControl = caret::trainControl(method = "repeatedcv", repeats = 5, 
                               # number = 10, classProbs = TRUE)
#Y1
tuneGridTree_GoogHL = expand.grid(cp = c(0,0.0001,0.001,0.01,0.1,0.15,0.5,1))
rpartOutSentiSum_GoogHL     = train(x = XtrainMatSentiSum_googHL, y = Ytrain_googHL,
                            method = "rpart",
                            tuneGrid = tuneGridTree_GoogHL,
                            trControl = trControl,
                            control = rpart.control(minsplit = 1, 
                                                    minbucket = 1))
plot(rpartOutSentiSum_GoogHL$finalModel, margin = rep(.1,4),
     main = "Classification Tree with Sentiments(Sum) - GOOG diffHighLow")
text(rpartOut_GoogHL$finalModel, cex = 0.6, digits = 1)

#Y2
tuneGridTree_GoogSR = expand.grid(cp = c(0,0.0001,0.001,0.01,0.1,0.15,0.5,1))
rpartOutSentiSum_GoogSR = train(x = XtrainMatSentiSum_googSR, y = Ytrain_googSR,
                            method = "rpart",
                            tuneGrid = tuneGridTree_GoogSR,
                            trControl = trControl,
                            control = rpart.control(minsplit = 1, minbucket = 1))
rpartOutSentiSum_GoogSR$finalModel #just a root
#plot(rpartOut_GoogSR$finalModel, margin = rep(.1,4))
#text(rpartOut_TslaSR$finalModel, cex = 0.6, digits = 1)


#Y3

tuneGridTree_GoogSRdummy = expand.grid(cp = c(0,0.0001,0.001,0.01,0.05,0.1,0.15,1))
rpartOutSentiSum_GoogSRdummy     = train(x = XtrainMatSentiSum_googSRdummy, 
                                 y = Ytrain_googSRdummy_,
                            method = "rpart",
                            parms = list(split = "gini"),
                            tuneGrid = tuneGridTree_GoogSRdummy,
                            trControl = trControl,
                            control = rpart.control(minsplit = 1, minbucket = 1))

#rpartOutSentiSum_GoogSRdummy$finalModel
plot(rpartOutSentiSum_GoogSRdummy$finalModel, margin = rep(.1,4),
     main = "Classification Tree with Sentiments(Sum) - GOOG stockReturnDummy")
text(rpartOutSentiSum_GoogSRdummy$finalModel, cex = 0.6, digits = 1)


```

####Random Forest

```{r randomForestSum}
set.seed(2020)
cl = parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
####TSLA
#trControl = caret::trainControl(method = "repeatedcv", repeats = 5, 
#                                number = 10, classProbs = TRUE)
#Y1
tuneGridRangerSentiSum_TslaHL = data.frame(splitrule = "variance", min.node.size = 5,
                                   mtry = round(sqrt(ncol(XtrainSentiSum_tslaHL))))
rfOutSentiSum_tslaHL  = train(x = XtrainMatSentiSum_tslaHL, y = Ytrain_tslaHL, 
                      method = "ranger",
                      num.trees = 500,
                      tuneGrid = tuneGridRangerSentiSum_TslaHL, 
                      importance = "permutation",
                      trControl = trControl)
#rfOutSentiSum_tslaHL$finalModel

#print(rfOut_tslaHL)

#Y2
tuneGridRangerSentiSum_TslaSR = data.frame(splitrule = "variance", min.node.size = 5,
                                   mtry = round(sqrt(ncol(XtrainSentiSum_tslaSR))))
rfOutSentiSum_tslaSR  = train(x = XtrainMatSentiSum_tslaSR, y = Ytrain_tslaSR, 
                      method = "ranger",
                      num.trees = 500,
                      tuneGrid = tuneGridRangerSentiSum_TslaSR, 
                      importance = "permutation",
                      trControl = trControl)
#rfOutSentiSum_tslaSR$finalModel

#Y3
set.seed(2020)
cl = parallel::makeCluster(8)
doParallel::registerDoParallel(cl)

tuneGridRangerSentiSum_TslaSRdummy = data.frame(splitrule = "gini", min.node.size = 10,
                                   mtry = round(sqrt(ncol(XtrainSentiSum_tslaSRdummy))))
rfOutSentiSum_tslaSRdummy  = train(x = XtrainMatSentiSum_tslaSRdummy, 
                           y = as.matrix(Ytrain_tslaSRdummy_) , 
                      method = "ranger",
                      num.trees = 500,
                      tuneGrid = tuneGridRangerSentiSum_TslaSRdummy, 
                      importance = "permutation",
                      trControl = trControl,
                      classification = TRUE)
#rfOutSentiSum_tslaSRdummy$finalModel

####GOOG
#trControl = caret::trainControl(method = "repeatedcv", repeats = 5, 
#                                number = 10, classProbs = TRUE)
#Y1

tuneGridRangerSentiSum_GoogHL = data.frame(splitrule = "variance", min.node.size = 5,
                                   mtry = round(sqrt(ncol(XtrainSentiSum_googHL))))
rfOutSentiSum_googHL  = train(x = XtrainMatSentiSum_googHL, y = Ytrain_googHL, 
                      method = "ranger",
                      num.trees = 500,
                      tuneGrid = tuneGridRangerSentiSum_GoogHL, 
                      importance = "permutation",
                      trControl = trControl)
#rfOutSentiSum_googHL$finalModel

#Y2

tuneGridRangerSentiSum_GoogSR = data.frame(splitrule = "variance", min.node.size = 5,
                                   mtry = round(sqrt(ncol(XtrainSentiSum_googSR))))
rfOutSentiSum_googSR  = train(x = XtrainMatSentiSum_googSR, y = Ytrain_googSR, 
                      method = "ranger",
                      num.trees = 500,
                      tuneGrid = tuneGridRangerSentiSum_GoogSR, 
                      importance = "permutation",
                      trControl = trControl)
rfOutSentiSum_googSR$finalModel

#Y3
tuneGridRangerSentiSum_GoogSRdummy = data.frame(splitrule = "gini", min.node.size = 10,
                                   mtry = round(sqrt(ncol(XtrainSentiSum_googSRdummy))))
rfOutSentiSum_googSRdummy  = train(x = XtrainMatSentiSum_googSRdummy, 
                                   y =as.matrix(Ytrain_googSRdummy_), 
                      method = "ranger",
                      num.trees = 500,
                      tuneGrid = tuneGridRangerSentiSum_GoogSRdummy, 
                      importance = "permutation",
                      trControl = trControl)
rfOutSentiSum_googSRdummy$finalModel


#List of Tuning Parameters
tuneParaRFSentiSum = rbind(
  rfOutSentiSum_tslaHL$bestTune,
  rfOutSentiSum_tslaSR$bestTune,
  rfOutSentiSum_tslaSRdummy$bestTune,
  rfOutSentiSum_googHL$bestTune,
  rfOutSentiSum_googSR$bestTune,
  rfOutSentiSum_googSRdummy$bestTune
  )


row.names(tuneParaRFSentiSum) = c("TSLA - diffHighLow", "TSLA - stockReturn", 
                            "TSLA - stockReturn(Dummy)","GOOG - diffHighLow", 
                            "GOOG - stockReturn","GOOG - stockReturn(Dummy)")

knitr::kable(
 tuneParaRFSentiSum,
 col.names = c("mtry", "splitrule", "min.node.size"),
 caption   = "Table 4: Random Forest regression and Classification with Sentiments(Sum) - Tuning Parameters",
 align     = "lccrr"
)

```

####Boosting

```{r boostingSum}
set.seed(2020)
cl = parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
####TSLA
#Y1
tuneGridRandom_TslaHL = expand.grid('nrounds'= c(50,150,500,1000,2000,3000),
                                   'max_depth' = 6,
                                   'eta' = c(0.01,0.03,0.05),
                                   'gamma' = 0,
                                   'colsample_bytree' = 1,
                                   'min_child_weight' = 0,
                                   'subsample' = c(0.5, 0.8))

boostOutRandomSentiSum_TslaHL = train(x = XtrainSentiSum_tslaHL, y = Ytrain_tslaHL,
                              method = 'xgbTree', verbose = 0,
                              tuneGrid = tuneGridRandom_TslaHL,
                              trControl = trControl)
plot(boostOutRandomSentiSum_TslaHL)

#Y2

tuneGridRandom_TslaSR = expand.grid('nrounds'= c(50,150,500,1000,2000,3000),
                                   'max_depth' = 6,
                                   'eta' = c(0.01,0.03,0.05),
                                   'gamma' = 0,
                                   'colsample_bytree' = 1,
                                   'min_child_weight' = 0,
                                   'subsample' = c(0.5, 0.8))

boostOutRandomSentiSum_TslaSR = train(x = XtrainSentiSum_tslaSR, y = Ytrain_tslaSR,
                              method = 'xgbTree', verbose = 0,
                              tuneGrid = tuneGridRandom_TslaSR,
                              trControl = trControl)
plot(boostOutRandomSentiSum_TslaSR)


#Y3


tuneGridRandom_TslaSRdummy = expand.grid(
                                   'nrounds'= c(50,150,500,1000,2000,3000),
                                   'max_depth' = 6,
                                   'eta' = c(0.01,0.03,0.05),
                                   'gamma' = 0,
                                   'colsample_bytree' = 1,
                                   'min_child_weight' = 0,
                                   'subsample' = c(0.5, 0.8))

boostOutRandomSentiSum_TslaSRdummy = train(x = XtrainSentiSum_tslaSRdummy, 
                                   y = Ytrain_tslaSRdummy_,
                              method = 'xgbTree', verbose = 0,
                              tuneGrid = tuneGridRandom_TslaSRdummy,
                              trControl = trControl)
plot(boostOutRandomSentiSum_TslaSRdummy)






####GOOG
set.seed(2020)
cl = parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
#Y1
tuneGridRandom_GoogHL = expand.grid('nrounds'= c(50,150,500,1000,2000,3000),
                                   'max_depth' = 6,
                                   'eta' = c(0.01,0.03,0.05),
                                   'gamma' = 0,
                                   'colsample_bytree' = 1,
                                   'min_child_weight' = 0,
                                   'subsample' = c(0.5, 0.8))

boostOutRandomSentiSum_GoogHL = train(x = XtrainSentiSum_googHL, y = Ytrain_googHL,
                              method = 'xgbTree', verbose = 0,
                              tuneGrid = tuneGridRandom_GoogHL,
                              trControl = trControl)
#plot(boostOutRandomSentiSum_GoogHL)

#Y2
tuneGridRandom_GoogSR = expand.grid('nrounds'= c(50,150,500,1000,2000,3000),
                                   'max_depth' = 6,
                                   'eta' = c(0.01,0.03,0.05),
                                   'gamma' = 0,
                                   'colsample_bytree' = 1,
                                   'min_child_weight' = 0,
                                   'subsample' = c(0.5, 0.8))

boostOutRandomSentiSum_GoogSR = train(x = XtrainSentiSum_googSR, y = Ytrain_googSR,
                              method = 'xgbTree', verbose = 0,
                              tuneGrid = tuneGridRandom_GoogSR,
                              trControl = trControl)
#plot(boostOutRandomSentiSum_GoogSR)
#boostOutRandomSentiSum_GoogSR$bestTune$nrounds

#Y3
tuneGridRandom_GoogSRdummy = expand.grid(
                                   'nrounds'= c(50,150,500,1000,2000,3000),
                                   'max_depth' = 6,
                                   'eta' = c(0.01,0.03,0.05),
                                   'gamma' = 0,
                                   'colsample_bytree' = 1,
                                   'min_child_weight' = 0,
                                   'subsample' = c(0.5, 0.8))

boostOutRandomSentiSum_GoogSRdummy = train(x = XtrainSentiSum_googSRdummy, 
                                   y = Ytrain_googSRdummy_,
                              method = 'xgbTree', verbose = 0,
                              tuneGrid = tuneGridRandom_GoogSRdummy,
                              trControl = trControl)
#plot(boostOutRandomSentiSum_GoogSRdummy)

#boostOutRandomSentiSum_GoogSRdummy$bestTune

###Overview

plot(boostOutRandomSentiSum_TslaHL, 
     main = "Boosting with Sentiments(Sum): TSLA diffHighLow")
plot(boostOutRandomSentiSum_TslaSR, 
     main = "Boosting with Sentiments(Sum): TSLA stockReturn")
plot(boostOutRandomSentiSum_TslaSRdummy, 
     main = "Boosting with Sentiments(Sum): TSLA stockReturn(Dummy)")

plot(boostOutRandomSentiSum_GoogHL, 
     main = "Boosting with Sentiments(Sum): GOOG diffHighLow")
plot(boostOutRandomSentiSum_GoogSR, 
     main = "Boosting with Sentiments(Sum): GOOG stockReturn")
plot(boostOutRandomSentiSum_GoogSRdummy, 
     main = "Boosting with Sentiments(Sum): GOOG stockReturn(Dummy)")


#List of Tuning Parameters
tuneParaBoostSentiSum = rbind(
  boostOutRandomSentiSum_TslaHL$bestTune,
  boostOutRandomSentiSum_TslaSR$bestTune,
  boostOutRandomSentiSum_TslaSRdummy$bestTune,
  boostOutRandomSentiSum_GoogHL$bestTune,
  boostOutRandomSentiSum_GoogSR$bestTune,
  boostOutRandomSentiSum_GoogSRdummy$bestTune
  )


row.names(tuneParaBoostSentiSum) = c("TSLA - diffHighLow", "TSLA - stockReturn", 
                            "TSLA - stockReturn(Dummy)","GOOG - diffHighLow", 
                            "GOOG - stockReturn","GOOG - stockReturn(Dummy)")

knitr::kable(
 tuneParaBoostSentiSum,
 col.names = c("nrounds","max_depth","eta","gamma","colsample_bytree",
               "min_child_weight","subsample"),
 caption   = "Table 5: Boosting regression and Classification with Sentiments(Sum)- Tuning Parameters",
 align     = "lccrr"
)

```

####Performance Review

```{r importanceBoostingSum}
####TSLA
(boostImportanceSentiSum_TslaHL = xgboost::xgb.importance(model = boostOutRandomSentiSum_TslaHL$finalModel))

(boostImportanceSentiSum_TslaSR = xgboost::xgb.importance(model = boostOutRandomSentiSum_TslaSR$finalModel))

(boostImportanceSentiSum_TslaSRdummy = xgboost::xgb.importance(model = boostOutRandomSentiSum_TslaSRdummy$finalModel))

####GOOG
(boostImportanceSentiSum_GoogHL = xgboost::xgb.importance(model = boostOutRandomSentiSum_GoogHL$finalModel))

(boostImportanceSentiSum_GoogSR = xgboost::xgb.importance(model = boostOutRandomSentiSum_GoogSR$finalModel))

(boostImportanceSentiSum_GoogSRdummy = xgboost::xgb.importance(model = boostOutRandomSentiSum_GoogSRdummy$finalModel))
```

```{r judgePerformanceSum}
set.seed(2020)
################Regression
####TSLA
#Y1
resultsTestSentiSum_TslaHL  = data.frame(
  YhatGlmnet_SentiSum = c(predict(glmnetOutTslaHL_SentiSum, XtestMatSentiSum_tslaHL,
                         s = elasticOutTslaHL_SentiSum$bestTune$lambda)),
  YhatMARS_SentiSum   = c(predict(marsOutTslaHL_SentiSum, XtestMatSentiSum_tslaHL)),
  YhatTrees_SentiSum  = predict(rpartOutSentiSum_TslaHL, XtestMatSentiSum_tslaHL),
  YhatRF_SentiSum     = predict(rfOutSentiSum_tslaHL, XtestMatSentiSum_tslaHL),
  YhatBoost_SentiSum  = predict(boostOutRandomSentiSum_TslaHL, XtestMatSentiSum_tslaHL)
)



par(mar=c(10,5,4,2))
plot(1:length(resultsTestSentiSum_TslaHL), 
     sapply(resultsTestSentiSum_TslaHL, function(Yhat){mean((Yhat - Ytest_tslaHL)^2)}),
     xlab = '', xaxt = 'n', pch = 16, ylab = 'test error', 
     main = 'TSLA with Sentiments(Sum) - Supervisor = difference between highest and lowest prices')
axis(1, labels = names(resultsTestSentiSum_TslaHL), 
     at = 1:ncol(resultsTestSentiSum_TslaHL), las = 3)

#Y2
set.seed(2020)
resultsTestSentiSum_TslaSR  = data.frame(
  YhatGlmnet_SentiSum = c(predict(glmnetOutTslaSR_SentiSum, XtestMatSentiSum_tslaSR,
                         s = elasticOutTslaSR_SentiSum$bestTune$lambda)),
  YhatMARS_SentiSum   = c(predict(marsOutTslaSR_SentiSum, XtestMatSentiSum_tslaSR)),
  YhatTrees_SentiSum  = predict(rpartOutSentiSum_TslaSR, XtestMatSentiSum_tslaSR),
  YhatRF_SentiSum     = predict(rfOutSentiSum_tslaSR, XtestMatSentiSum_tslaSR),
  YhatBoost_SentiSum  = predict(boostOutRandomSentiSum_TslaSR, XtestMatSentiSum_tslaSR)
)

par(mar=c(10,5,4,2))
plot(1:length(resultsTestSentiSum_TslaSR), 
     sapply(resultsTestSentiSum_TslaSR, function(Yhat){mean((Yhat - Ytest_tslaSR)^2)}),
     xlab = '', xaxt = 'n', pch = 16, ylab = 'test error', 
     main = 'TSLA with Sentiments(Sum) - Supervisor = stock return')
axis(1, labels = names(resultsTestSentiSum_TslaSR), 
     at = 1:ncol(resultsTestSentiSum_TslaSR), las = 3)

####GOOG
#Y1
set.seed(2020)
resultsTestSentiSum_GoogHL  = data.frame(
  YhatGlmnet_SentiSum = c(predict(glmnetOutGoogHL_SentiSum, XtestMatSentiSum_googHL,
                         s = elasticOutGoogHL_SentiSum$bestTune$lambda)),
  YhatMARS_SentiSum   = c(predict(marsOutGoogHL_SentiSum, XtestMatSentiSum_googHL)),
  YhatTrees_SentiSum  = predict(rpartOutSentiSum_GoogHL, XtestMatSentiSum_googHL),
  YhatRF_SentiSum     = predict(rfOutSentiSum_googHL, XtestMatSentiSum_googHL),
  YhatBoost_SentiSum  = predict(boostOutRandomSentiSum_GoogHL, XtestMatSentiSum_googHL)
)

par(mar=c(10,5,4,2))
plot(1:length(resultsTestSentiSum_GoogHL), 
     sapply(resultsTestSentiSum_GoogHL, function(Yhat){mean((Yhat - Ytest_googHL)^2)}),
     xlab = '', xaxt = 'n', pch = 16, ylab = 'test error', 
     main = 'GOOG with Sentiments(Sum) - Supervisor = difference between highest and lowest prices')
axis(1, labels = names(resultsTestSentiSum_GoogHL), 
     at = 1:ncol(resultsTestSentiSum_GoogHL), las = 3)

#Y2
set.seed(2020)
resultsTestSentiSum_GoogSR  = data.frame(
  YhatGlmnet_SentiSum = c(predict(glmnetOutGoogSR_SentiSum, XtestMatSentiSum_googSR,
                         s = elasticOutGoogSR_SentiSum$bestTune$lambda)),
  YhatMARS_SentiSum   = c(predict(marsOutGoogSR_SentiSum, XtestMatSentiSum_googSR)),
  YhatTrees_SentiSum  = predict(rpartOutSentiSum_GoogSR, XtestMatSentiSum_googSR),
  YhatRF_SentiSum     = predict(rfOutSentiSum_googSR, XtestMatSentiSum_googSR),
  YhatBoost_SentiSum  = predict(boostOutRandomSentiSum_GoogSR, XtestMatSentiSum_googSR)
)

par(mar=c(10,5,4,2))
plot(1:length(resultsTestSentiSum_GoogSR), 
     sapply(resultsTestSentiSum_GoogSR, function(Yhat){mean((Yhat - Ytest_googSR)^2)}),
     xlab = '', xaxt = 'n', pch = 16, ylab = 'test error', 
     main = 'GOOG with Sentiments(Sum)- Supervisor = stock return')
axis(1, labels = names(resultsTestSentiSum_GoogSR), at = 1:ncol(resultsTestSentiSum_GoogSR), las = 3)










###################Classification
####TSLA
#TSLA MARS(FDA)- Y3
YhatTestFDASentiSum_TslaSRdummyProb = predict(marsOutTslaSRdummy_SentiSum,
                                              XtestSentiSum_tslaSRdummy,
                                              type = 'prob')
YhatTestFDASentiSum_TslaSRdummy     = ifelse(YhatTestFDASentiSum_TslaSRdummyProb[,2] > 0.5, '1','0')

table(YhatTestFDASentiSum_TslaSRdummy, Ytest_tslaSRdummy)
(TslaSRdummySentiSum_accuracyFDA = sum(diag(table(YhatTestFDASentiSum_TslaSRdummy, Ytest_tslaSRdummy)))/length(Ytest_tslaSRdummy))

#TSLA Classification Tree - Y3
YhatTestTreeSentiSum_TslaSRdummyProb = predict(rpartOutSentiSum_TslaSRdummy,
                                               XtestSentiSum_tslaSRdummy,
                                               type = 'prob')
YhatTestTreeSentiSum_TslaSRdummy     = ifelse(YhatTestTreeSentiSum_TslaSRdummyProb[,2] > 0.5, '1','0')
table(YhatTestTreeSentiSum_TslaSRdummy, Ytest_tslaSRdummy)
(TslaSRdummySentiSum_accuracyTree = sum(diag(table(YhatTestTreeSentiSum_TslaSRdummy, Ytest_tslaSRdummy)))/length(Ytest_tslaSRdummy))

#TSLA Random Forest - Y3

YhatTestRFSentiSum_TslaSRdummyRaw = predict(rfOutSentiSum_tslaSRdummy,
                                            XtestMatSentiSum_tslaSRdummy,
                                            type = 'raw')
YhatTestRFSentiSum_TslaSRdummy     = ifelse(YhatTestRFSentiSum_TslaSRdummyRaw == "Yes", '1','0')

table(YhatTestRFSentiSum_TslaSRdummy, Ytest_tslaSRdummy)
(TslaSRdummySentiSum_accuracyRF = sum(diag(table(YhatTestRFSentiSum_TslaSRdummy, Ytest_tslaSRdummy)))/length(Ytest_tslaSRdummy))

#TSLA Boosting - Y3
YhatTestBoostSentiSum_TslaSRdummyProb = predict(boostOutRandomSentiSum_TslaSRdummy,
                                        XtestMatSentiSum_tslaSRdummy,type = 'prob')
YhatTestBoostSentiSum_TslaSRdummy     = ifelse(YhatTestBoostSentiSum_TslaSRdummyProb[,2] > 0.5, '1','0')

table(YhatTestBoostSentiSum_TslaSRdummy, Ytest_tslaSRdummy)
(TslaSRdummySentiSum_accuracyBoost = sum(diag(table(YhatTestBoostSentiSum_TslaSRdummy, Ytest_tslaSRdummy)))/length(Ytest_tslaSRdummy))

#Summary - TSLA - Classification
resultsTestClassSentiSum_Tsla = data.frame(
  accuracyFDA_SentiSum  = TslaSRdummySentiSum_accuracyFDA,
  accuracyTree_SentiSum = TslaSRdummySentiSum_accuracyTree,
  accuracyRF_SentiSum = TslaSRdummySentiSum_accuracyRF,
  accuracyBoost_SentiSum = TslaSRdummySentiSum_accuracyBoost
)
par(mar=c(11,5,4,2))
plot(1:length(resultsTestClassSentiSum_Tsla), 
     resultsTestClassSentiSum_Tsla,
     xlab = '', xaxt = 'n', pch = 16, ylab = 'accuracy', 
     main = 'TSLA with Sentiments(Sum) - Supervisor = stock return (dummy)')
axis(1, labels = names(resultsTestClassSentiSum_Tsla), 
     at = 1:ncol(resultsTestClassSentiSum_Tsla), las = 3)


####GOOG
#GOOG MARS(FDA) - Y3
YhatTestFDASentiSum_GoogSRdummyProb = predict(marsOutGoogSRdummy_SentiSum,
                                              XtestSentiSum_googSRdummy,
                                              type = 'prob')

YhatTestFDASentiSum_GoogSRdummy     = ifelse(YhatTestFDASentiSum_GoogSRdummyProb[,2] > 0.5, '1','0')

table(YhatTestFDASentiSum_GoogSRdummy, Ytest_googSRdummy)
(GoogSRdummySentiSum_accuracyFDA = sum(diag(table(YhatTestFDASentiSum_GoogSRdummy, Ytest_googSRdummy)))/length(Ytest_googSRdummy))

#GOOG Classification Tree - Y3
YhatTestTreeSentiSum_GoogSRdummyProb = predict(rpartOutSentiSum_GoogSRdummy, Xtest_googSRdummy,
                                  type = 'prob')
YhatTestTreeSentiSum_GoogSRdummy     = ifelse(YhatTestTreeSentiSum_GoogSRdummyProb[,2] > 0.5, '1','0')
table(YhatTestTreeSentiSum_GoogSRdummy, Ytest_googSRdummy)
(GoogSRdummySentiSum_accuracyTree = sum(diag(table(YhatTestTreeSentiSum_GoogSRdummy, Ytest_googSRdummy)))/length(Ytest_googSRdummy))

#GOOG Random Forest - Y3
YhatTestRFSentiSum_GoogSRdummyRaw = predict(rfOutSentiSum_googSRdummy,
                                            XtestSentiSum_googSRdummy,
                                            type = 'raw')

YhatTestRFSentiSum_GoogSRdummy     = ifelse(YhatTestRFSentiSum_GoogSRdummyRaw == "Yes", '1','0')

table(YhatTestRFSentiSum_GoogSRdummy, Ytest_googSRdummy)
(GoogSRdummySentiSum_accuracyRF = sum(diag(table(YhatTestRFSentiSum_GoogSRdummy, Ytest_googSRdummy)))/length(Ytest_googSRdummy))


#GOOG Boosting - Y3
YhatTestBoostSentiSum_GoogSRdummyProb = predict(boostOutRandomSentiSum_GoogSRdummy,
                                        XtestMatSentiSum_googSRdummy,type = 'prob')
YhatTestBoostSentiSum_GoogSRdummy     = ifelse(YhatTestBoostSentiSum_GoogSRdummyProb[,2] > 0.5, '1','0')

table(YhatTestBoostSentiSum_GoogSRdummy, Ytest_googSRdummy)
(GoogSRdummySentiSum_accuracyBoost = sum(diag(table(YhatTestBoostSentiSum_GoogSRdummy, Ytest_googSRdummy)))/length(Ytest_googSRdummy))


#Summary - GOOG - Classification
resultsTestClassSentiSum_Goog = data.frame(
  accuracyFDA_SentiSum   = GoogSRdummySentiSum_accuracyFDA,
  accuracyTree_SentiSum  = GoogSRdummySentiSum_accuracyTree,
  accuracyRF_SentiSum    = GoogSRdummySentiSum_accuracyRF,
  accuracyBoost_SentiSum = GoogSRdummySentiSum_accuracyBoost
)

par(mar=c(10,5,4,2))
plot(1:length(resultsTestClassSentiSum_Goog), 
     resultsTestClassSentiSum_Goog,
     xlab = '', xaxt = 'n', pch = 16,  ylab = 'accuracy', 
     main = 'GOOG with Sentiments(Sum) - Supervisor = stock return (dummy)')
axis(1, labels = names(resultsTestClassSentiSum_Goog), 
     at = 1:ncol(resultsTestClassSentiSum_Goog), las = 3)
```

```{r FinalPerformanceReview}



colVec = rainbow(3)
par(mar = c(7,5,4,2))
plot(1:ncol(resultsTestClassSentiSum_Goog), resultsTestClassSentiSum_Goog, col = colVec[1], 
     pch = 15, ylim = c(0,1), ylab = "GOOG - Supervisor = stock return (dummy)", xlab = " " )
points(1:ncol(resultsTestClass_Goog),  resultsTestClass_Goog,  col = colVec[2], pch = 16)

axis(1, labels = names(resultsTestClass_Goog), at = 1:ncol(resultsTestClass_Goog), 
     las = 3)
legend('topright', col = colVec, pch = c(15:21), 
       legend = c('with Sentiments(Sum)','without Sentiments'))

```

























###### 9 - Final Task with sentiments Mean


```{r dataSplitFinalTaskMean}
#Line 990
#Superviors:
  #Y1: YtslaWithSentiments$diffHighLowTomorrow
  #Y2: YtslaWithSentiments$stockReturnTomorrow
  #Y3: YtslaWithSentiments$stockReturnTomorrowDummy

#Features wtiht Sentiments:
XtslaWithSentimentsMean = XtslaWithSentiments %>%
  select(-tslaSentimentsSum)
XgoogWithSentimentsMean = XgoogWithSentiments %>%
  select(-googSentimentsSum)


#Data Split
##TSLA

#set.seed(2020)
#inTrain_tslaHL = caret::createDataPartition(YtslaWithSentiments$diffHighLowTomorrow, p = 4/5, list = FALSE) #Y1
#inTrain_tslaSR = caret::createDataPartition(YtslaWithSentiments$stockReturnTomorrow, p = 4/5, list = FALSE) #Y2
#inTrain_tslaSRdummy = caret::createDataPartition(YtslaWithSentiments$stockReturnTomorrowDummy, p = 4/5, list = FALSE) #Y3


Ytrain_tslaHL = YtslaWithSentiments$diffHighLowTomorrow[inTrain_tslaHL]
Ytest_tslaHL  = YtslaWithSentiments$diffHighLowTomorrow[-inTrain_tslaHL]
Ytrain_tslaSR = YtslaWithSentiments$stockReturnTomorrow[inTrain_tslaSR]
Ytest_tslaSR  = YtslaWithSentiments$stockReturnTomorrow[-inTrain_tslaSR]
Ytrain_tslaSRdummy = YtslaWithSentiments$stockReturnTomorrowDummy[inTrain_tslaSRdummy]
Ytest_tslaSRdummy  = YtslaWithSentiments$stockReturnTomorrowDummy[-inTrain_tslaSRdummy]


XtrainSentiMean_tslaHL = XtslaWithSentimentsMean[inTrain_tslaHL,] 
XtestSentiMean_tslaHL  = XtslaWithSentimentsMean[-inTrain_tslaHL,]
XtrainSentiMean_tslaSR = XtslaWithSentimentsMean[inTrain_tslaSR,] 
XtestSentiMean_tslaSR  = XtslaWithSentimentsMean[-inTrain_tslaSR,]
XtrainSentiMean_tslaSRdummy = XtslaWithSentimentsMean[inTrain_tslaSRdummy,]
XtestSentiMean_tslaSRdummy  = XtslaWithSentimentsMean[-inTrain_tslaSRdummy,]

###GOOG

#set.seed(2020)
#inTrain_googHL = caret::createDataPartition(YgoogWithSentiments$diffHighLowTomorrow, p = 4/5, list = FALSE) #Y1
#inTrain_googSR = caret::createDataPartition(YgoogWithSentiments$stockReturnTomorrow, p = 4/5, list = FALSE) #Y2
#inTrain_googSRdummy = caret::createDataPartition(YgoogWithSentiments$stockReturnTomorrowDummy, p = 4/5, list = FALSE) #Y3


Ytrain_googHL = YgoogWithSentiments$diffHighLowTomorrow[inTrain_googHL]
Ytest_googHL  = YgoogWithSentiments$diffHighLowTomorrow[-inTrain_googHL]
Ytrain_googSR = YgoogWithSentiments$stockReturnTomorrow[inTrain_googSR]
Ytest_googSR  = YgoogWithSentiments$stockReturnTomorrow[-inTrain_googSR]
Ytrain_googSRdummy = YgoogWithSentiments$stockReturnTomorrowDummy[inTrain_googSRdummy]
Ytest_googSRdummy  = YgoogWithSentiments$stockReturnTomorrowDummy[-inTrain_googSRdummy]


XtrainSentiMean_googHL = XgoogWithSentimentsMean[inTrain_googHL,]
XtestSentiMean_googHL  = XgoogWithSentimentsMean[-inTrain_googHL,]
XtrainSentiMean_googSR = XgoogWithSentimentsMean[inTrain_googSR,]
XtestSentiMean_googSR  = XgoogWithSentimentsMean[-inTrain_googSR,]
XtrainSentiMean_googSRdummy = XgoogWithSentimentsMean[inTrain_googSRdummy,]
XtestSentiMean_googSRdummy  =XgoogWithSentimentsMean[-inTrain_googSRdummy,]

```


```{r setupFinalTaskMean}

#Repeated cross validation
trControl = caret::trainControl(method = "repeatedcv", repeats = 5, number = 10)

XtrainMatSentiMean_tslaHL      = as.matrix(XtrainSentiMean_tslaHL)
XtestMatSentiMean_tslaHL       = as.matrix(XtestSentiMean_tslaHL)
XtrainMatSentiMean_tslaSR      = as.matrix(XtrainSentiMean_tslaSR)
XtestMatSentiMean_tslaSR       = as.matrix(XtestSentiMean_tslaSR)
XtrainMatSentiMean_tslaSRdummy = as.matrix(XtrainSentiMean_tslaSRdummy)
XtestMatSentiMean_tslaSRdummy  = as.matrix(XtestSentiMean_tslaSRdummy)

####GOOG
#Feature transformations
XtrainMatSentiMean_googHL      = as.matrix(XtrainSentiMean_googHL)
XtestMatSentiMean_googHL       = as.matrix(XtestSentiMean_googHL)
XtrainMatSentiMean_googSR      = as.matrix(XtrainSentiMean_googSR)
XtestMatSentiMean_googSR       = as.matrix(XtestSentiMean_googSR)
XtrainMatSentiMean_googSRdummy = as.matrix(XtrainSentiMean_googSRdummy)
XtestMatSentiMean_googSRdummy  = as.matrix(XtestSentiMean_googSRdummy)

#Parallelism
#cl = parallel::makeCluster(8)
#doParallel::registerDoParallel(cl)
```


```{r elasticNetTuningParameters}
set.seed(2020)
cl = parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
####Supervisor Y1 = YtslaWithSentiments$diffHighLowTomorrow
####TSLA
trControl = caret::trainControl(method = "repeatedcv", repeats = 5, number = 10)

lassoGridTslaHL_SentiMean = expand.grid(lambda = c(0.0001,0.001, 0.01, 0.05, 0.1, 0.2),
                            alpha = c(0.05,0.5,1))


elasticOutTslaHL_SentiMean = train(x = XtrainMatSentiMean_tslaHL, y = Ytrain_tslaHL, 
                       method = 'glmnet',
                       tuneGrid = lassoGridTslaHL_SentiMean, 
                       trControl = trControl)
plot(elasticOutTslaHL_SentiMean, main = "Elastic Net - TSLA diffHighLow with Sentiments(Mean)")

####GOOG
#trControl = caret::trainControl(method = "repeatedcv", repeats = 2, number = 10)

lassoGridGoogHL_SentiMean = expand.grid(lambda = c(0.0001,0.001, 0.01, 0.05, 0.1, 0.2),
                            alpha = c(0.05,0.5,1))


elasticOutGoogHL_SentiMean = train(x = XtrainMatSentiMean_googHL, y = Ytrain_googHL, 
                       method = 'glmnet',
                       tuneGrid = lassoGridGoogHL_SentiMean, 
                       trControl = trControl)
plot(elasticOutGoogHL_SentiMean, main = "Elastic Net - GOOG diffHighLow with Sentiments(Mean)")



####Supervisor Y2 = YtslaWithSentiments$stockReturnTomorrow
####TSLA
#trControl = caret::trainControl(method = "repeatedcv", repeats = 2, number = 10)

lassoGridTslaSR_SentiMean = expand.grid(lambda = c(0.0001,0.001, 0.01, 0.05, 0.1, 0.2),
                            alpha = c(0.05,0.5,1))


elasticOutTslaSR_SentiMean = train(x = XtrainMatSentiMean_tslaSR, y = Ytrain_tslaSR, 
                       method = 'glmnet',
                       tuneGrid = lassoGridTslaSR_SentiMean, 
                       trControl = trControl)
plot(elasticOutTslaSR_SentiMean, main = "Elastic Net - TSLA stockReturn with Sentiments(Mean)")

####GOOG
#trControl = caret::trainControl(method = "repeatedcv", repeats = 2, number = 10)

lassoGridGoogSR_SentiMean = expand.grid(lambda = c(0.0001,0.001, 0.01, 0.05, 0.1, 0.2),
                            alpha = c(0.05,0.5,1))


elasticOutGoogSR_SentiMean = train(x = XtrainMatSentiMean_googSR, y = Ytrain_googSR, 
                       method = 'glmnet',
                       tuneGrid = lassoGridGoogSR_SentiMean, 
                       trControl = trControl)
plot(elasticOutGoogSR_SentiMean, main = "Elastic Net - GOOG stockReturn with Sentiments(Mean)")


#List of turning parameters
tunePara = rbind(
  elasticOutTslaHL_SentiMean$bestTune,
  elasticOutTslaSR_SentiMean$bestTune,
  elasticOutGoogHL_SentiMean$bestTune,
  elasticOutGoogSR_SentiMean$bestTune
  )

row.names(tunePara) = c("TSLA - diffHighLow", "TSLA - stockReturn",
                "GOOG - diffHighLow", "GOOG - stockReturn")

knitr::kable(
 tunePara,
 col.names = c("alpha","lambda"),
 caption   = "Table 1: Optimal tuning parameters for Elastic Penalized  regression with Sentiments Mean",
 align     = "lccrr"
)

```


```{r elasticNet}
####Supervisor Y1 = YtslaStandardizedWithDummy$diffHighLowTomorrow
####TSLA
glmnetOutTslaHL_SentiMean       = glmnet(x = XtrainMatSentiMean_tslaHL, y = Ytrain_tslaHL, 
                               alpha = elasticOutTslaHL_SentiMean$bestTune$alpha)
betaHatGlmnetTslaHL_SentiMean   = coef(glmnetOutTslaHL_SentiMean, 
                             s = elasticOutTslaHL_SentiMean$bestTune$lambda)
YhatTrainGlmnetTslaHL_SentiMean = predict(glmnetOutTslaHL_SentiMean, XtrainMatSentiMean_tslaHL, 
                                s = elasticOutTslaHL_SentiMean$bestTune$lambda)

residualsTslaHL_SentiMean = Ytrain_tslaHL - YhatTrainGlmnetTslaHL_SentiMean
plot(YhatTrainGlmnetTslaHL_SentiMean, residualsTslaHL_SentiMean, 
     xlab = "Traning predictions - TSLA diffHighLow",
     ylab = "Residuals", main = "Residual Plot - TSLA diffHighLow with Sentiments(Mean)")

####GOOG

glmnetOutGoogHL_SentiMean       = glmnet(x = XtrainMatSentiMean_googHL, y = Ytrain_googHL, 
                               alpha = elasticOutGoogHL_SentiMean$bestTune$alpha)
betaHatGlmnetGoogHL_SentiMean   = coef(glmnetOutGoogHL_SentiMean, 
                             s = elasticOutGoogHL_SentiMean$bestTune$lambda)
YhatTrainGlmnetGoogHL_SentiMean = predict(glmnetOutGoogHL_SentiMean, XtrainMatSentiMean_googHL, 
                                s = elasticOutGoogHL_SentiMean$bestTune$lambda )

residualsGoogHL_SentiMean = Ytrain_googHL - YhatTrainGlmnetGoogHL_SentiMean
plot(YhatTrainGlmnetGoogHL_SentiMean, residualsGoogHL_SentiMean, 
     xlab = "Traning predictions - GOOG diffHighLow",
     ylab = "Residuals", main = "Residual Plot - GOOG diffHighLow with Sentiments(Mean)")

####Supervisor Y2 = YtslaStandardizedWithDummy$stockReturnTomorrow
####TSLA
glmnetOutTslaSR_SentiMean       = glmnet(x = XtrainMatSentiMean_tslaSR, y = Ytrain_tslaSR, 
                               alpha = elasticOutTslaSR_SentiMean$bestTune$alpha)
betaHatGlmnetTslaSR_SentiMean   = coef(glmnetOutTslaSR_SentiMean, 
                             s = elasticOutTslaSR_SentiMean$bestTune$lambda)
YhatTrainGlmnetTslaSR_SentiMean = predict(glmnetOutTslaSR_SentiMean, XtrainMatSentiMean_tslaSR, 
                                s = elasticOutTslaSR_SentiMean$bestTune$lambda)

residualsTslaSR_SentiMean = Ytrain_tslaSR - YhatTrainGlmnetTslaSR_SentiMean
plot(YhatTrainGlmnetTslaSR_SentiMean, residualsTslaSR_SentiMean, 
     xlab = "Traning predictions - TSLA Stock Return",
     ylab = "Residuals", main = "Residual Plot - TSLA stockReturn with Sentiments(Mean)")

####GOOG
glmnetOutGoogSR_SentiMean       = glmnet(x = XtrainMatSentiMean_googSR, y = Ytrain_googSR,
                               alpha = elasticOutGoogSR_SentiMean$bestTune$alpha)
betaHatGlmnetGoogSR_SentiMean   = coef(glmnetOutGoogSR_SentiMean, 
                             s = elasticOutGoogSR_SentiMean$bestTune$lambda)
YhatTrainGlmnetGoogSR_SentiMean = predict(glmnetOutGoogSR_SentiMean, XtrainMatSentiMean_googSR, 
                                s = elasticOutGoogSR_SentiMean$bestTune$lambda)

residualsGoogSR_SentiMean = Ytrain_googSR - YhatTrainGlmnetGoogSR
plot(YhatTrainGlmnetGoogSR, residualsGoogSR_SentiMean, 
     xlab = "Traning predictions - GOOG Stock Return",
     ylab = "Residuals", main = "Residual Plot - GOOG stockReturn with Sentiments(Mean)")

```

####Logistic Classification
```{r logisticClassificationMean}
set.seed(2020)
trControl = caret::trainControl(method = "repeatedcv", repeats = 5, number = 10)
tuneGridTslaSRdummy = expand.grid('alpha' = c(0,.25,.5,.75,1),
                                  'lambda' = seq(0.000001, .001, length.out = 30))
elasticOutTslaSRdummy_SentiMean = train(x = XtrainSentiMean_tslaSRdummy, 
                              y = as.factor(Ytrain_tslaSRdummy_),
                              method = 'glmnet',
                              trControl = trControl, 
                              tuneGrid = tuneGridTslaSRdummy)

glmnetOutTslaSRdummy_SentiMean = glmnet(x = XtrainMatSentiMean_tslaSRdummy, 
                              y = as.factor(Ytrain_tslaSRdummy_),
                              alpha = 0.25,
                              family = 'binomial')
probHatTestSentiMean_TslaSRdummy = predict(glmnetOutTslaSRdummy_SentiMean,
                                  XtestMatSentiMean_tslaSRdummy,
                                  s = elasticOutTslaSRdummy_SentiMean$bestTune$lambda,
                                  type = 'response')

YhatTestGlmnetSentiMean_TslaSRdummy = ifelse(probHatTestSentiMean_TslaSRdummy > 0.5, '1', '0')
YhatTestSentiMean_TslaSRdummy       = predict(elasticOutTslaSRdummy_SentiMean,
                                             XtestMatSentiMean_tslaSRdummy,
                                     s = elasticOutTslaSRdummy_SentiMean$lambda, 
                                     type = 'raw')

#Cross-check they're the same. #Lecture 23 notes.
table(YhatTestSentiMean_TslaSRdummy,YhatTestSentiMean_TslaSRdummy)


betaHatGlmnetTslaSRdummy_SentiMean = coef(glmnetOutTslaSRdummy_SentiMean, 
                                s = elasticOutTslaSRdummy_SentiMean$bestTune$lambda)
#Accuracy
accuracyLinearSentiMean_TslaSRdummy = mean(YhatTestSentiMean_TslaSRdummy==Ytest_tslaSRdummy)

probHatTestSentiMean_TslaSRdummy_ = predict(elasticOutTslaSRdummy_SentiMean,
                                           XtestMatSentiMean_tslaSRdummy,
                                   s = elasticOutTslaSRdummy_SentiMean$bestTune$lambda,
                                   type = 'prob')
rocOutSentiMean_TslaSRdummy = pROC::roc(response = Ytest_tslaSRdummy,                   
                               probHatTestSentiMean_TslaSRdummy_[,2])

plot(rocOutSentiMean_TslaSRdummy, main = "ROC Plot - TSLA Stock Return (Dummy) with Sentiments(Mean)")






####GOOG
set.seed(2020)

tuneGridGoogSRdummy = expand.grid('alpha' = c(0,.25,.5,.75,1),
                                  'lambda' = seq(0.000001, .001, length.out = 30))
elasticOutGoogSRdummy_SentiMean = train(x = XtrainSentiMean_googSRdummy, 
                              y = as.factor(Ytrain_googSRdummy),
                              method = 'glmnet',
                              trControl = trControl, 
                              tuneGrid = tuneGridGoogSRdummy)


glmnetOutGoogSRdummy_SentiMean = glmnet(x = XtrainMatSentiMean_googSRdummy, 
                              y = as.factor(Ytrain_googSRdummy),
                              alpha = 0.25,
                              family = 'binomial')
probHatTestSentiMean_GoogSRdummy = predict(glmnetOutGoogSRdummy_SentiMean,
                                           XtestMatSentiMean_googSRdummy,
                                  s = elasticOutGoogSRdummy_SentiMean$bestTune$lambda,
                                  type = 'response')

YhatTestGlmnetSentiMean_GoogSRdummy = ifelse(probHatTestSentiMean_GoogSRdummy > 0.5,
                                             '1', '0')
YhatTestSentiMean_GoogSRdummy       = predict(elasticOutGoogSRdummy_SentiMean,
                                             XtestMatSentiMean_googSRdummy,
                                     s = elasticOutGoogSRdummy_SentiMean$lambda, 
                                     type = 'raw')

#Cross-check they're the same. #Lecture 23 notes.
table(YhatTestSentiMean_GoogSRdummy,YhatTestSentiMean_GoogSRdummy)

betaHatGlmnetGoogSRdummy_SentiMean = coef(glmnetOutGoogSRdummy_SentiMean, 
                                s = elasticOutGoogSRdummy_SentiMean$bestTune$lambda)
#Accuracy
accuracyLinearSentiMean_GoogSRdummy = mean(YhatTestSentiMean_GoogSRdummy==Ytest_googSRdummy)
probHatTestSentiMean_GoogSRdummy_ = predict(elasticOutGoogSRdummy_SentiMean,
                                           XtestMatSentiMean_googSRdummy,
                                   s = elasticOutGoogSRdummy_SentiMean$bestTune$lambda,
                                   type = 'prob')
rocOutSentiMean_GoogSRdummy = pROC::roc(response = Ytest_googSRdummy,                   
                                       probHatTestSentiMean_GoogSRdummy_[,2])

plot(rocOutSentiMean_GoogSRdummy, 
     main = "ROC Plot - GOOG Stock Return (Dummy) with Sentiments(Mean)")



#List of Accuracy
accuracyLinearSentiMean = rbind(
  accuracyLinearSentiMean_TslaSRdummy,
  accuracyLinearSentiMean_GoogSRdummy
  )

row.names(accuracyLinearSentiMean) = c("TSLA - Stock Return(dummy)", 
                "GOOG - Stock Return(dummy)")

knitr::kable(
 accuracyLinearSentiMean,
 col.names = c("Accuracy based on Testing data"),
 caption   = "Table 2: Accuracy - Logistic Elastic Net with Sentiments(Mean)",
 align     = "lccrr"
)

```

####Nonlinear Methods

####MARS
```{r MARS_Mean}
set.seed(2020)
cl = parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
trControl = caret::trainControl(method = "repeatedcv", repeats = 5, number = 10)

###TSLA
#Y1
tuneGridTslaHL      = expand.grid(degree = 1:3,
                                  nprune = 10:35)
marsOutTslaHL_SentiMean = train(x = XtrainMatSentiMean_tslaHL, y = Ytrain_tslaHL,
                      method = 'earth', metric = 'RMSE',
                      tuneGrid = tuneGridTslaHL,
                      trControl = trControl)

#plot(marsOutTslaHL_SentiMean, 
#     main = "MARS Regression - TSLA diffHighLow with Sentiments(Mean)")
#ggplot(marsOutTslaHL_SentiMean)+labs( title= "MARS Regression - TSLA diffHighLow")


#Y2
tuneGridTslaSR      = expand.grid(degree = 1:3,
                                  nprune = 10:35)
marsOutTslaSR_SentiMean = train(x = XtrainMatSentiMean_tslaSR, y = Ytrain_tslaSR,
                      method = 'earth', metric = 'RMSE',
                      tuneGrid = tuneGridTslaSR,
                      trControl = trControl)

#plot(marsOutTslaSR_SentiMean, 
#     main = "MARS Regression - TSLA stockReturn with Sentiments(Mean)")


#Y3
tuneGridTslaSRdummy = expand.grid(degree = 1:3,
                                  nprune = c(10,20,50,100))

trControl_tslaSRdummy = caret::trainControl(method = "repeatedcv", repeats = 2, 
                                 number = 10, classProbs = TRUE)

Ytrain_tslaSRdummy_ = as.factor(Ytrain_tslaSRdummy[Ytrain_tslaSRdummy == '1'|
                                                   Ytrain_tslaSRdummy == '0'])
Ytrain_tslaSRdummy_ = relevel(Ytrain_tslaSRdummy_, ref = '0')
levels(Ytrain_tslaSRdummy_) = c("No", "Yes")


library(mda)
set.seed(888)
marsOutTslaSRdummy_SentiMean = train(x = XtrainMatSentiMean_tslaSRdummy, 
                           y = Ytrain_tslaSRdummy_,
                      method = 'fda',
                      metric = 'Accuracy',
                      tuneGrid = tuneGridTslaSRdummy,
                      trControl = trainControl(method = "CV",  
                                               number = 2, classProbs = TRUE))

#plot(marsOutTslaSRdummy,
#     main = "MARS Regression - TSLA stockReturnDummy with Sentiments(Mean)")



###GOOG
#Y1
tuneGridGoogHL      = expand.grid(degree = 1:3,
                                  nprune = 10:35)
marsOutGoogHL_SentiMean = train(x = XtrainMatSentiMean_googHL, y = Ytrain_googHL,
                      method = 'earth', metric = 'RMSE',
                      tuneGrid = tuneGridGoogHL,
                      trControl = trControl)

#ggplot(marsOutGoogHL_SentiMean)+labs(title= "MARS Regression - GOOG diffHighLow with Sentiments(Mean)")

#Meanmary(marsOutGoogHL) %>% .$coefficients %>% head(10)


#Y2
tuneGridGoogSR      = expand.grid(degree = 1:3,
                                  nprune = 10:35)
marsOutGoogSR_SentiMean = train(x = XtrainMatSentiMean_googSR, y = Ytrain_googSR,
                      method = 'earth', metric = 'RMSE',
                      tuneGrid = tuneGridGoogSR,
                      trControl = trControl)

#plot(marsOutGoogSR_SentiMean, 
#     main = "MARS Regression - GOOG stockReturn with Sentiments(Mean)")
#Y3
tuneGridGoogSRdummy = expand.grid(degree = 1:3,
                                  nprune = c(10,20,50,100))
trControl_googSRdummy = caret::trainControl(method = "repeatedcv", repeats = 2, 
                                number = 10, classProbs = TRUE)
Ytrain_googSRdummy_ = as.factor(Ytrain_googSRdummy[Ytrain_googSRdummy == '1'|
                                                   Ytrain_googSRdummy == '0'])
Ytrain_googSRdummy_ = relevel(Ytrain_googSRdummy_, ref = '0')


levels(Ytrain_googSRdummy_) = c("No", "Yes")
library(mda)
set.seed(888)
marsOutGoogSRdummy_SentiMean = train(x = XtrainMatSentiMean_googSRdummy, 
                           y = Ytrain_googSRdummy_,
                      method = 'fda',
                      metric = 'Accuracy',
                      tuneGrid = tuneGridGoogSRdummy,
                      trControl = trControl_googSRdummy)



###Meanmary
ggplot(marsOutTslaHL_SentiMean)+labs( title= "MARS Regression - TSLA diffHighLow with Sentiments(Mean)")
ggplot(marsOutTslaSR_SentiMean)+labs( title= "MARS Regression - TSLA stockReturn with Sentiments(Mean)")
ggplot(marsOutTslaSRdummy_SentiMean)+labs(title= "MARS Classification - TSLA stockReturn(dummy) with Sentiments(Mean)")
ggplot(marsOutGoogHL_SentiMean)+labs( title= "MARS Regression - GOOG diffHighLow with Sentiments(Mean)")
ggplot(marsOutGoogSR_SentiMean)+labs( title= "MARS Regression - GOOG stockReturn with Sentiments(Mean)")
ggplot(marsOutGoogSRdummy_SentiMean)+labs(title= "MARS Classification - GOOG stockReturn(dummy) with Sentiments(Mean)")

#List of Tuning Parameters
tuneParaMars_SentiMean = rbind(
  marsOutTslaHL_SentiMean$bestTune,
  marsOutTslaSR_SentiMean$bestTune,
  marsOutTslaSRdummy_SentiMean$bestTune,
  marsOutGoogHL_SentiMean$bestTune,
  marsOutGoogSR_SentiMean$bestTune,
  marsOutGoogSRdummy_SentiMean$bestTune
  )


row.names(tuneParaMars_SentiMean) = c("TSLA - diffHighLow", "TSLA - stockReturn", 
                            "TSLA - stockReturn(Dummy)","GOOG - diffHighLow", 
                            "GOOG - stockReturn","GOOG - stockReturn(Dummy)")

knitr::kable(
 tuneParaMars_SentiMean,
 col.names = c("nprune", "degree"),
 caption   = "Table 3: MARS regression and Classification - Tuning Parameters ( with Sentiments(Mean))",
 align     = "lccrr"
)

#Importance

marsTslaHLvip_SentiMean = vip(marsOutTslaHL_SentiMean, num_features = 50, 
                             bar = FALSE, value = "gcv") +
  ggtitle("Plot of Variable Importance with Sentiments(Mean): TSLA - diffHighLow")
plot(marsTslaHLvip_SentiMean)

marsTslaSRvip_SentiMean = vip(marsOutTslaSR_SentiMean, num_features = 50, 
                             bar = FALSE, value = "gcv") +
  ggtitle("Plot of Variable Importance with Sentiments(Mean): TSLA - stockReturn")
plot(marsTslaSRvip_SentiMean)

marsTslaSRdummyvip_SentiMean = vip(marsOutTslaSRdummy_SentiMean, num_features = 50, 
                                  bar = FALSE, value = "gcv") + ggtitle("Plot of Variable Importance with Sentiments(Mean): TSLA - stockReturn(dummy)")
plot(marsTslaSRdummyvip_SentiMean)


marsGoogHLvip_SentiMean = vip(marsOutGoogHL_SentiMean, num_features = 50, 
                             bar = FALSE, value = "gcv") +
  ggtitle("Plot of Variable Importance with Sentiments(Mean): GOOG - diffHighLow")
plot(marsGoogHLvip_SentiMean)

marsGoogSRvip_SentiMean = vip(marsOutGoogSR_SentiMean, num_features = 50, 
                             bar = FALSE, value = "gcv") +
  ggtitle("Plot of Variable Importance with Sentiments(Mean): GOOG - stockReturn")
plot(marsGoogSRvip_SentiMean)

marsGoogSRdummyvip_SentiMean = vip(marsOutGoogSRdummy_SentiMean, num_features = 50, 
                                  bar = FALSE, value = "gcv") + ggtitle("Plot of Variable Importance with Sentiments(Mean): GOOG - stockReturn(dummy)")
plot(marsGoogSRdummyvip_SentiMean)


```

####Classification Tree

```{r classificationTreeMean}
set.seed(2022)
cl = parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
####TSLA
#trControl = caret::trainControl(method = "repeatedcv", repeats = 5, 
#                                number = 10, classProbs = TRUE)
#Y1
tuneGridTree_TslaHL = expand.grid(cp = c(0.0001,0.001,0.01,0.1,0.15,0.5,1))
rpartOutSentiMean_TslaHL     = train(x = XtrainMatSentiMean_tslaHL, y = Ytrain_tslaHL,
                            method = "rpart",
                            tuneGrid = tuneGridTree_TslaHL,
                            trControl = trControl)
plot(rpartOutSentiMean_TslaHL$finalModel, margin = rep(.1,4),
     main = "Classification Tree with Sentiments(Mean) - TSLA diffHighLow")
text(rpartOutSentiMean_TslaHL$finalModel, cex = 0.6, digits = 1)



#Y2
tuneGridTree_TslaSR = expand.grid(cp = c(0.0001,0.001,0.01,0.1,0.15,0.5,1))
rpartOutSentiMean_TslaSR     = train(x = XtrainMatSentiMean_tslaSR, y = Ytrain_tslaSR,
                            method = "rpart",
                            tuneGrid = tuneGridTree_TslaSR,
                            trControl = trControl,
                            control = rpart.control(minsplit = 1, minbucket = 1))
rpartOutSentiMean_TslaSR$finalModel #just a root
#plot(rpartOut_TslaSR$finalModel, margin = rep(.1,4))
#text(rpartOut_TslaSR$finalModel, cex = 0.6, digits = 1)


#Y3
tuneGridTree_TslaSRdummy = expand.grid(cp = c(0,0.0001,0.001,0.01,0.1,0.15,0.5,1))
rpartOutSentiMean_TslaSRdummy     = train(x = XtrainMatSentiMean_tslaSRdummy, 
                                 y = Ytrain_tslaSRdummy_,
                            method = "rpart",
                            #parms = list(prior = c(.65,.35),split = "gini"),
                            parms = list(split = "gini"),
                            tuneGrid = tuneGridTree_TslaSRdummy,
                            trControl = trControl)

#plot(rpartOutSentiMean_TslaSRdummy$finalModel, margin = rep(.1,4),
#    main = "Classification Tree with Sentiments(Mean) - TSLA stockReturn(dummy)")
#text(rpartOutSentiMean_TslaSRdummy$finalModel, cex = 0.6, digits = 1)



####GOOG
set.seed(2022)
cl = parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
#trControl = caret::trainControl(method = "repeatedcv", repeats = 5, 
                               # number = 10, classProbs = TRUE)
#Y1
tuneGridTree_GoogHL = expand.grid(cp = c(0,0.0001,0.001,0.01,0.1,0.15,0.5,1))
rpartOutSentiMean_GoogHL     = train(x = XtrainMatSentiMean_googHL, y = Ytrain_googHL,
                            method = "rpart",
                            tuneGrid = tuneGridTree_GoogHL,
                            trControl = trControl,
                            control = rpart.control(minsplit = 1, 
                                                    minbucket = 1))
plot(rpartOutSentiMean_GoogHL$finalModel, margin = rep(.1,4),
     main = "Classification Tree with Sentiments(Mean) - GOOG diffHighLow")
text(rpartOut_GoogHL$finalModel, cex = 0.6, digits = 1)

#Y2
tuneGridTree_GoogSR = expand.grid(cp = c(0,0.0001,0.001,0.01,0.1,0.15,0.5,1))
rpartOutSentiMean_GoogSR = train(x = XtrainMatSentiMean_googSR, y = Ytrain_googSR,
                            method = "rpart",
                            tuneGrid = tuneGridTree_GoogSR,
                            trControl = trControl,
                            control = rpart.control(minsplit = 1, minbucket = 1))
rpartOutSentiMean_GoogSR$finalModel #just a root
#plot(rpartOut_GoogSR$finalModel, margin = rep(.1,4))
#text(rpartOut_TslaSR$finalModel, cex = 0.6, digits = 1)


#Y3

tuneGridTree_GoogSRdummy = expand.grid(cp = c(0,0.0001,0.001,0.01,0.05,0.1,0.15,1))
rpartOutSentiMean_GoogSRdummy     = train(x = XtrainMatSentiMean_googSRdummy, 
                                 y = Ytrain_googSRdummy_,
                            method = "rpart",
                            parms = list(split = "gini"),
                            tuneGrid = tuneGridTree_GoogSRdummy,
                            trControl = trControl,
                            control = rpart.control(minsplit = 1, minbucket = 1))

#rpartOutSentiMean_GoogSRdummy$finalModel
#plot(rpartOutSentiMean_GoogSRdummy$finalModel, margin = rep(.1,4),
#     main = "Classification Tree with Sentiments(Mean) - GOOG stockReturnDummy")
#text(rpartOutSentiMean_GoogSRdummy$finalModel, cex = 0.6, digits = 1)


```

####Random Forest

```{r randomForestMean}
set.seed(2020)
cl = parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
####TSLA
#trControl = caret::trainControl(method = "repeatedcv", repeats = 5, 
#                                number = 10, classProbs = TRUE)
#Y1
tuneGridRangerSentiMean_TslaHL = data.frame(splitrule = "variance", min.node.size = 5,
                                   mtry = round(sqrt(ncol(XtrainSentiMean_tslaHL))))
rfOutSentiMean_tslaHL  = train(x = XtrainMatSentiMean_tslaHL, y = Ytrain_tslaHL, 
                      method = "ranger",
                      num.trees = 500,
                      tuneGrid = tuneGridRangerSentiMean_TslaHL, 
                      importance = "permutation",
                      trControl = trControl)
#rfOutSentiMean_tslaHL$finalModel

#print(rfOut_tslaHL)

#Y2
tuneGridRangerSentiMean_TslaSR = data.frame(splitrule = "variance", min.node.size = 5,
                                   mtry = round(sqrt(ncol(XtrainSentiMean_tslaSR))))
rfOutSentiMean_tslaSR  = train(x = XtrainMatSentiMean_tslaSR, y = Ytrain_tslaSR, 
                      method = "ranger",
                      num.trees = 500,
                      tuneGrid = tuneGridRangerSentiMean_TslaSR, 
                      importance = "permutation",
                      trControl = trControl)
#rfOutSentiMean_tslaSR$finalModel

#Y3
set.seed(2020)
cl = parallel::makeCluster(8)
doParallel::registerDoParallel(cl)

tuneGridRangerSentiMean_TslaSRdummy = data.frame(splitrule = "gini", min.node.size = 10,
                                   mtry = round(sqrt(ncol(XtrainSentiMean_tslaSRdummy))))
rfOutSentiMean_tslaSRdummy  = train(x = XtrainMatSentiMean_tslaSRdummy, 
                           y = as.matrix(Ytrain_tslaSRdummy_) , 
                      method = "ranger",
                      num.trees = 500,
                      tuneGrid = tuneGridRangerSentiMean_TslaSRdummy, 
                      importance = "permutation",
                      trControl = trControl,
                      classification = TRUE)
#rfOutSentiMean_tslaSRdummy$finalModel

####GOOG
#trControl = caret::trainControl(method = "repeatedcv", repeats = 5, 
#                                number = 10, classProbs = TRUE)
#Y1

tuneGridRangerSentiMean_GoogHL = data.frame(splitrule = "variance", min.node.size = 5,
                                   mtry = round(sqrt(ncol(XtrainSentiMean_googHL))))
rfOutSentiMean_googHL  = train(x = XtrainMatSentiMean_googHL, y = Ytrain_googHL, 
                      method = "ranger",
                      num.trees = 500,
                      tuneGrid = tuneGridRangerSentiMean_GoogHL, 
                      importance = "permutation",
                      trControl = trControl)
#rfOutSentiMean_googHL$finalModel

#Y2

tuneGridRangerSentiMean_GoogSR = data.frame(splitrule = "variance", min.node.size = 5,
                                   mtry = round(sqrt(ncol(XtrainSentiMean_googSR))))
rfOutSentiMean_googSR  = train(x = XtrainMatSentiMean_googSR, y = Ytrain_googSR, 
                      method = "ranger",
                      num.trees = 500,
                      tuneGrid = tuneGridRangerSentiMean_GoogSR, 
                      importance = "permutation",
                      trControl = trControl)
rfOutSentiMean_googSR$finalModel

#Y3
tuneGridRangerSentiMean_GoogSRdummy = data.frame(splitrule = "gini", min.node.size = 10,
                                   mtry = round(sqrt(ncol(XtrainSentiMean_googSRdummy))))
rfOutSentiMean_googSRdummy  = train(x = XtrainMatSentiMean_googSRdummy, 
                                   y =as.matrix(Ytrain_googSRdummy_), 
                      method = "ranger",
                      num.trees = 500,
                      tuneGrid = tuneGridRangerSentiMean_GoogSRdummy, 
                      importance = "permutation",
                      trControl = trControl)
rfOutSentiMean_googSRdummy$finalModel


#List of Tuning Parameters
tuneParaRFSentiMean = rbind(
  rfOutSentiMean_tslaHL$bestTune,
  rfOutSentiMean_tslaSR$bestTune,
  rfOutSentiMean_tslaSRdummy$bestTune,
  rfOutSentiMean_googHL$bestTune,
  rfOutSentiMean_googSR$bestTune,
  rfOutSentiMean_googSRdummy$bestTune
  )


row.names(tuneParaRFSentiMean) = c("TSLA - diffHighLow", "TSLA - stockReturn", 
                            "TSLA - stockReturn(Dummy)","GOOG - diffHighLow", 
                            "GOOG - stockReturn","GOOG - stockReturn(Dummy)")

knitr::kable(
 tuneParaRFSentiMean,
 col.names = c("mtry", "splitrule", "min.node.size"),
 caption   = "Table 4: Random Forest regression and Classification with Sentiments(Mean) - Tuning Parameters",
 align     = "lccrr"
)

```

####Boosting

```{r boostingMean}
set.seed(2020)
cl = parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
####TSLA
#Y1
tuneGridRandom_TslaHL = expand.grid('nrounds'= c(50,150,500,1000,2000,3000),
                                   'max_depth' = 6,
                                   'eta' = c(0.01,0.03,0.05),
                                   'gamma' = 0,
                                   'colsample_bytree' = 1,
                                   'min_child_weight' = 0,
                                   'subsample' = c(0.5, 0.8))

boostOutRandomSentiMean_TslaHL = train(x = XtrainSentiMean_tslaHL, y = Ytrain_tslaHL,
                              method = 'xgbTree', verbose = 0,
                              tuneGrid = tuneGridRandom_TslaHL,
                              trControl = trControl)
#plot(boostOutRandomSentiMean_TslaHL)

#Y2
set.seed(2020)
cl = parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
tuneGridRandom_TslaSR = expand.grid('nrounds'= c(50,150,500,1000,2000,3000),
                                   'max_depth' = 6,
                                   'eta' = c(0.01,0.03,0.05),
                                   'gamma' = 0,
                                   'colsample_bytree' = 1,
                                   'min_child_weight' = 0,
                                   'subsample' = c(0.5, 0.8))

boostOutRandomSentiMean_TslaSR = train(x = XtrainSentiMean_tslaSR, y = Ytrain_tslaSR,
                              method = 'xgbTree', verbose = 0,
                              tuneGrid = tuneGridRandom_TslaSR,
                              trControl = trControl)
#plot(boostOutRandomSentiMean_TslaSR)


#Y3


tuneGridRandom_TslaSRdummy = expand.grid(
                                   'nrounds'= c(50,150,500,1000,2000,3000),
                                   'max_depth' = 6,
                                   'eta' = c(0.01,0.03,0.05),
                                   'gamma' = 0,
                                   'colsample_bytree' = 1,
                                   'min_child_weight' = 0,
                                   'subsample' = c(0.5, 0.8))

boostOutRandomSentiMean_TslaSRdummy = train(x = XtrainSentiMean_tslaSRdummy, 
                                   y = Ytrain_tslaSRdummy_,
                              method = 'xgbTree', verbose = 0,
                              tuneGrid = tuneGridRandom_TslaSRdummy,
                              trControl = trControl)
#plot(boostOutRandomSentiMean_TslaSRdummy)






####GOOG
set.seed(2020)
cl = parallel::makeCluster(8)
doParallel::registerDoParallel(cl)
#Y1
tuneGridRandom_GoogHL = expand.grid('nrounds'= c(50,150,500,1000,2000,3000),
                                   'max_depth' = 6,
                                   'eta' = c(0.01,0.03,0.05),
                                   'gamma' = 0,
                                   'colsample_bytree' = 1,
                                   'min_child_weight' = 0,
                                   'subsample' = c(0.5, 0.8))

boostOutRandomSentiMean_GoogHL = train(x = XtrainSentiMean_googHL, y = Ytrain_googHL,
                              method = 'xgbTree', verbose = 0,
                              tuneGrid = tuneGridRandom_GoogHL,
                              trControl = trControl)
#plot(boostOutRandomSentiMean_GoogHL)

#Y2
tuneGridRandom_GoogSR = expand.grid('nrounds'= c(50,150,500,1000,2000,3000),
                                   'max_depth' = 6,
                                   'eta' = c(0.01,0.03,0.05),
                                   'gamma' = 0,
                                   'colsample_bytree' = 1,
                                   'min_child_weight' = 0,
                                   'subsample' = c(0.5, 0.8))

boostOutRandomSentiMean_GoogSR = train(x = XtrainSentiMean_googSR, y = Ytrain_googSR,
                              method = 'xgbTree', verbose = 0,
                              tuneGrid = tuneGridRandom_GoogSR,
                              trControl = trControl)
#plot(boostOutRandomSentiMean_GoogSR)
#boostOutRandomSentiMean_GoogSR$bestTune$nrounds

#Y3
tuneGridRandom_GoogSRdummy = expand.grid(
                                   'nrounds'= c(50,150,500,1000,2000,3000),
                                   'max_depth' = 6,
                                   'eta' = c(0.01,0.03,0.05),
                                   'gamma' = 0,
                                   'colsample_bytree' = 1,
                                   'min_child_weight' = 0,
                                   'subsample' = c(0.5, 0.8))

boostOutRandomSentiMean_GoogSRdummy = train(x = XtrainSentiMean_googSRdummy, 
                                   y = Ytrain_googSRdummy_,
                              method = 'xgbTree', verbose = 0,
                              tuneGrid = tuneGridRandom_GoogSRdummy,
                              trControl = trControl)
#plot(boostOutRandomSentiMean_GoogSRdummy)

#boostOutRandomSentiMean_GoogSRdummy$bestTune

###Overview

plot(boostOutRandomSentiMean_TslaHL, 
     main = "Boosting with Sentiments(Mean): TSLA diffHighLow")
plot(boostOutRandomSentiMean_TslaSR, 
     main = "Boosting with Sentiments(Mean): TSLA stockReturn")
plot(boostOutRandomSentiMean_TslaSRdummy, 
     main = "Boosting with Sentiments(Mean): TSLA stockReturn(Dummy)")

plot(boostOutRandomSentiMean_GoogHL, 
     main = "Boosting with Sentiments(Mean): GOOG diffHighLow")
plot(boostOutRandomSentiMean_GoogSR, 
     main = "Boosting with Sentiments(Mean): GOOG stockReturn")
plot(boostOutRandomSentiMean_GoogSRdummy, 
     main = "Boosting with Sentiments(Mean): GOOG stockReturn(Dummy)")


#List of Tuning Parameters
tuneParaBoostSentiMean = rbind(
  boostOutRandomSentiMean_TslaHL$bestTune,
  boostOutRandomSentiMean_TslaSR$bestTune,
  boostOutRandomSentiMean_TslaSRdummy$bestTune,
  boostOutRandomSentiMean_GoogHL$bestTune,
  boostOutRandomSentiMean_GoogSR$bestTune,
  boostOutRandomSentiMean_GoogSRdummy$bestTune
  )


row.names(tuneParaBoostSentiMean) = c("TSLA - diffHighLow", "TSLA - stockReturn", 
                            "TSLA - stockReturn(Dummy)","GOOG - diffHighLow", 
                            "GOOG - stockReturn","GOOG - stockReturn(Dummy)")

knitr::kable(
 tuneParaBoostSentiMean,
 col.names = c("nrounds","max_depth","eta","gamma","colsample_bytree",
               "min_child_weight","subsample"),
 caption   = "Table 5: Boosting regression and Classification with Sentiments(Mean)- Tuning Parameters",
 align     = "lccrr"
)

```

####Performance Review

```{r importanceBoostingMean}
####TSLA
(boostImportanceSentiMean_TslaHL = xgboost::xgb.importance(model = boostOutRandomSentiMean_TslaHL$finalModel))

(boostImportanceSentiMean_TslaSR = xgboost::xgb.importance(model = boostOutRandomSentiMean_TslaSR$finalModel))

(boostImportanceSentiMean_TslaSRdummy = xgboost::xgb.importance(model = boostOutRandomSentiMean_TslaSRdummy$finalModel))

####GOOG
(boostImportanceSentiMean_GoogHL = xgboost::xgb.importance(model = boostOutRandomSentiMean_GoogHL$finalModel))

(boostImportanceSentiMean_GoogSR = xgboost::xgb.importance(model = boostOutRandomSentiMean_GoogSR$finalModel))

(boostImportanceSentiMean_GoogSRdummy = xgboost::xgb.importance(model = boostOutRandomSentiMean_GoogSRdummy$finalModel))
```

```{r judgePerformanceMean}
set.seed(2020)
################Regression
####TSLA
#Y1
resultsTestSentiMean_TslaHL  = data.frame(
  YhatGlmnet_SentiMean = c(predict(glmnetOutTslaHL_SentiMean, XtestMatSentiMean_tslaHL,
                         s = elasticOutTslaHL_SentiMean$bestTune$lambda)),
  YhatMARS_SentiMean   = c(predict(marsOutTslaHL_SentiMean, XtestMatSentiMean_tslaHL)),
  YhatTrees_SentiMean  = predict(rpartOutSentiMean_TslaHL, XtestMatSentiMean_tslaHL),
  YhatRF_SentiMean     = predict(rfOutSentiMean_tslaHL, XtestMatSentiMean_tslaHL),
  YhatBoost_SentiMean  = predict(boostOutRandomSentiMean_TslaHL, XtestMatSentiMean_tslaHL)
)



par(mar=c(10,5,4,2))
plot(1:length(resultsTestSentiMean_TslaHL), 
     sapply(resultsTestSentiMean_TslaHL, function(Yhat){mean((Yhat - Ytest_tslaHL)^2)}),
     xlab = '', xaxt = 'n', pch = 16, ylab = 'test error', 
     main = 'TSLA with Sentiments(Mean) - Supervisor = difference between highest and lowest prices')
axis(1, labels = names(resultsTestSentiMean_TslaHL), 
     at = 1:ncol(resultsTestSentiMean_TslaHL), las = 3)

#Y2
set.seed(2020)
resultsTestSentiMean_TslaSR  = data.frame(
  YhatGlmnet_SentiMean = c(predict(glmnetOutTslaSR_SentiMean, XtestMatSentiMean_tslaSR,
                         s = elasticOutTslaSR_SentiMean$bestTune$lambda)),
  YhatMARS_SentiMean   = c(predict(marsOutTslaSR_SentiMean, XtestMatSentiMean_tslaSR)),
  YhatTrees_SentiMean  = predict(rpartOutSentiMean_TslaSR, XtestMatSentiMean_tslaSR),
  YhatRF_SentiMean     = predict(rfOutSentiMean_tslaSR, XtestMatSentiMean_tslaSR),
  YhatBoost_SentiMean  = predict(boostOutRandomSentiMean_TslaSR, XtestMatSentiMean_tslaSR)
)

par(mar=c(10,5,4,2))
plot(1:length(resultsTestSentiMean_TslaSR), 
     sapply(resultsTestSentiMean_TslaSR, function(Yhat){mean((Yhat - Ytest_tslaSR)^2)}),
     xlab = '', xaxt = 'n', pch = 16, ylab = 'test error', 
     main = 'TSLA with Sentiments(Mean) - Supervisor = stock return')
axis(1, labels = names(resultsTestSentiMean_TslaSR), 
     at = 1:ncol(resultsTestSentiMean_TslaSR), las = 3)

####GOOG
#Y1
set.seed(2020)
resultsTestSentiMean_GoogHL  = data.frame(
  YhatGlmnet_SentiMean = c(predict(glmnetOutGoogHL_SentiMean, XtestMatSentiMean_googHL,
                         s = elasticOutGoogHL_SentiMean$bestTune$lambda)),
  YhatMARS_SentiMean   = c(predict(marsOutGoogHL_SentiMean, XtestMatSentiMean_googHL)),
  YhatTrees_SentiMean  = predict(rpartOutSentiMean_GoogHL, XtestMatSentiMean_googHL),
  YhatRF_SentiMean     = predict(rfOutSentiMean_googHL, XtestMatSentiMean_googHL),
  YhatBoost_SentiMean  = predict(boostOutRandomSentiMean_GoogHL, XtestMatSentiMean_googHL)
)

par(mar=c(10,5,4,2))
plot(1:length(resultsTestSentiMean_GoogHL), 
     sapply(resultsTestSentiMean_GoogHL, function(Yhat){mean((Yhat - Ytest_googHL)^2)}),
     xlab = '', xaxt = 'n', pch = 16, ylab = 'test error', 
     main = 'GOOG with Sentiments(Mean) - Supervisor = difference between highest and lowest prices')
axis(1, labels = names(resultsTestSentiMean_GoogHL), 
     at = 1:ncol(resultsTestSentiMean_GoogHL), las = 3)

#Y2
set.seed(2020)
resultsTestSentiMean_GoogSR  = data.frame(
  YhatGlmnet_SentiMean = c(predict(glmnetOutGoogSR_SentiMean, XtestMatSentiMean_googSR,
                         s = elasticOutGoogSR_SentiMean$bestTune$lambda)),
  YhatMARS_SentiMean   = c(predict(marsOutGoogSR_SentiMean, XtestMatSentiMean_googSR)),
  YhatTrees_SentiMean  = predict(rpartOutSentiMean_GoogSR, XtestMatSentiMean_googSR),
  YhatRF_SentiMean     = predict(rfOutSentiMean_googSR, XtestMatSentiMean_googSR),
  YhatBoost_SentiMean  = predict(boostOutRandomSentiMean_GoogSR, XtestMatSentiMean_googSR)
)

par(mar=c(10,5,4,2))
plot(1:length(resultsTestSentiMean_GoogSR), 
     sapply(resultsTestSentiMean_GoogSR, function(Yhat){mean((Yhat - Ytest_googSR)^2)}),
     xlab = '', xaxt = 'n', pch = 16, ylab = 'test error', 
     main = 'GOOG with Sentiments(Mean)- Supervisor = stock return')
axis(1, labels = names(resultsTestSentiMean_GoogSR), at = 1:ncol(resultsTestSentiMean_GoogSR), las = 3)










###################Classification
####TSLA
#TSLA MARS(FDA)- Y3
YhatTestFDASentiMean_TslaSRdummyProb = predict(marsOutTslaSRdummy_SentiMean,
                                              XtestSentiMean_tslaSRdummy,
                                              type = 'prob')
YhatTestFDASentiMean_TslaSRdummy     = ifelse(YhatTestFDASentiMean_TslaSRdummyProb[,2] > 0.5, '1','0')

table(YhatTestFDASentiMean_TslaSRdummy, Ytest_tslaSRdummy)
(TslaSRdummySentiMean_accuracyFDA = Mean(diag(table(YhatTestFDASentiMean_TslaSRdummy, Ytest_tslaSRdummy)))/length(Ytest_tslaSRdummy))

#TSLA Classification Tree - Y3
YhatTestTreeSentiMean_TslaSRdummyProb = predict(rpartOutSentiMean_TslaSRdummy,
                                               XtestSentiMean_tslaSRdummy,
                                               type = 'prob')
YhatTestTreeSentiMean_TslaSRdummy     = ifelse(YhatTestTreeSentiMean_TslaSRdummyProb[,2] > 0.5, '1','0')
table(YhatTestTreeSentiMean_TslaSRdummy, Ytest_tslaSRdummy)
(TslaSRdummySentiMean_accuracyTree = Mean(diag(table(YhatTestTreeSentiMean_TslaSRdummy, Ytest_tslaSRdummy)))/length(Ytest_tslaSRdummy))

#TSLA Random Forest - Y3

YhatTestRFSentiMean_TslaSRdummyRaw = predict(rfOutSentiMean_tslaSRdummy,
                                            XtestMatSentiMean_tslaSRdummy,
                                            type = 'raw')
YhatTestRFSentiMean_TslaSRdummy     = ifelse(YhatTestRFSentiMean_TslaSRdummyRaw == "Yes", '1','0')

table(YhatTestRFSentiMean_TslaSRdummy, Ytest_tslaSRdummy)
(TslaSRdummySentiMean_accuracyRF = Mean(diag(table(YhatTestRFSentiMean_TslaSRdummy, Ytest_tslaSRdummy)))/length(Ytest_tslaSRdummy))

#TSLA Boosting - Y3
YhatTestBoostSentiMean_TslaSRdummyProb = predict(boostOutRandomSentiMean_TslaSRdummy,
                                        XtestMatSentiMean_tslaSRdummy,type = 'prob')
YhatTestBoostSentiMean_TslaSRdummy     = ifelse(YhatTestBoostSentiMean_TslaSRdummyProb[,2] > 0.5, '1','0')

table(YhatTestBoostSentiMean_TslaSRdummy, Ytest_tslaSRdummy)
(TslaSRdummySentiMean_accuracyBoost = Mean(diag(table(YhatTestBoostSentiMean_TslaSRdummy, Ytest_tslaSRdummy)))/length(Ytest_tslaSRdummy))

#Meanmary - TSLA - Classification
resultsTestClassSentiMean_Tsla = data.frame(
  accuracyFDA_SentiMean  = TslaSRdummySentiMean_accuracyFDA,
  accuracyTree_SentiMean = TslaSRdummySentiMean_accuracyTree,
  accuracyRF_SentiMean = TslaSRdummySentiMean_accuracyRF,
  accuracyBoost_SentiMean = TslaSRdummySentiMean_accuracyBoost
)
par(mar=c(11,5,4,2))
plot(1:length(resultsTestClassSentiMean_Tsla), 
     resultsTestClassSentiMean_Tsla,
     xlab = '', xaxt = 'n', pch = 16, ylab = 'accuracy', 
     main = 'TSLA with Sentiments(Mean) - Supervisor = stock return (dummy)')
axis(1, labels = names(resultsTestClassSentiMean_Tsla), 
     at = 1:ncol(resultsTestClassSentiMean_Tsla), las = 3)


####GOOG
#GOOG MARS(FDA) - Y3
YhatTestFDASentiMean_GoogSRdummyProb = predict(marsOutGoogSRdummy_SentiMean,
                                              XtestSentiMean_googSRdummy,
                                              type = 'prob')

YhatTestFDASentiMean_GoogSRdummy     = ifelse(YhatTestFDASentiMean_GoogSRdummyProb[,2] > 0.5, '1','0')

table(YhatTestFDASentiMean_GoogSRdummy, Ytest_googSRdummy)
(GoogSRdummySentiMean_accuracyFDA = Mean(diag(table(YhatTestFDASentiMean_GoogSRdummy, Ytest_googSRdummy)))/length(Ytest_googSRdummy))

#GOOG Classification Tree - Y3
YhatTestTreeSentiMean_GoogSRdummyProb = predict(rpartOutSentiMean_GoogSRdummy, Xtest_googSRdummy,
                                  type = 'prob')
YhatTestTreeSentiMean_GoogSRdummy     = ifelse(YhatTestTreeSentiMean_GoogSRdummyProb[,2] > 0.5, '1','0')
table(YhatTestTreeSentiMean_GoogSRdummy, Ytest_googSRdummy)
(GoogSRdummySentiMean_accuracyTree = Mean(diag(table(YhatTestTreeSentiMean_GoogSRdummy, Ytest_googSRdummy)))/length(Ytest_googSRdummy))

#GOOG Random Forest - Y3
YhatTestRFSentiMean_GoogSRdummyRaw = predict(rfOutSentiMean_googSRdummy,
                                            XtestSentiMean_googSRdummy,
                                            type = 'raw')

YhatTestRFSentiMean_GoogSRdummy     = ifelse(YhatTestRFSentiMean_GoogSRdummyRaw == "Yes", '1','0')

table(YhatTestRFSentiMean_GoogSRdummy, Ytest_googSRdummy)
(GoogSRdummySentiMean_accuracyRF = Mean(diag(table(YhatTestRFSentiMean_GoogSRdummy, Ytest_googSRdummy)))/length(Ytest_googSRdummy))


#GOOG Boosting - Y3
YhatTestBoostSentiMean_GoogSRdummyProb = predict(boostOutRandomSentiMean_GoogSRdummy,
                                        XtestMatSentiMean_googSRdummy,type = 'prob')
YhatTestBoostSentiMean_GoogSRdummy     = ifelse(YhatTestBoostSentiMean_GoogSRdummyProb[,2] > 0.5, '1','0')

table(YhatTestBoostSentiMean_GoogSRdummy, Ytest_googSRdummy)
(GoogSRdummySentiMean_accuracyBoost = Mean(diag(table(YhatTestBoostSentiMean_GoogSRdummy, Ytest_googSRdummy)))/length(Ytest_googSRdummy))


#Meanmary - GOOG - Classification
resultsTestClassSentiMean_Goog = data.frame(
  accuracyFDA_SentiMean   = GoogSRdummySentiMean_accuracyFDA,
  accuracyTree_SentiMean  = GoogSRdummySentiMean_accuracyTree,
  accuracyRF_SentiMean    = GoogSRdummySentiMean_accuracyRF,
  accuracyBoost_SentiMean = GoogSRdummySentiMean_accuracyBoost
)

par(mar=c(10,5,4,2))
plot(1:length(resultsTestClassSentiMean_Goog), 
     resultsTestClassSentiMean_Goog,
     xlab = '', xaxt = 'n', pch = 16,  ylab = 'accuracy', 
     main = 'GOOG with Sentiments(Mean) - Supervisor = stock return (dummy)')
axis(1, labels = names(resultsTestClassSentiMean_Goog), 
     at = 1:ncol(resultsTestClassSentiMean_Goog), las = 3)
```





