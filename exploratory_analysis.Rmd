---
title: "Exploratory Analysis"
author: "Kyle Dixon, Mia Li, Caitlin Hennessey"
date: "9/2/2020"
output: html_document
---
### 1 - General review of raw data 
#### 1.1 Load and clean data
```{r initialize, include = F}
## Clear the environment
#rm(list = ls())

## Load libraries
library(bit64)
library(data.table)
library(dplyr)
library(ggplot2)
knitr::opts_chunk$set(echo = T)
```

```{r clean_data}
## Load raw data into the global environment
tsla <- base::data.frame(data.table::fread("1 - Data/Tesla/tsla.csv", na.strings = c("#N/A N/A", "#N/A Invalid Field", "#N/A Requesting Data...")), stringsAsFactors = F)
goog <- base::data.frame(data.table::fread("1 - Data/Google/goog.csv", na.strings = c("#N/A N/A", "#N/A Invalid Field", "#N/A Requesting Data...")), stringsAsFactors = F)

## Clean raw data
tsla <- tsla %>% dplyr::select_if(~sum(!is.na(.)) > 0) %>% # Drop columns that contain only NAs
  dplyr::filter(!is.na(PX_LAST)) # Drop rows where PX_LAST is NA
goog <- goog %>% dplyr::select_if(~sum(!is.na(.)) > 0) %>% # Drop columns that contain only NAs
  dplyr::filter(!is.na(PX_LAST)) # Drop rows where PX_LAST is NA

## Format date columns
tsla$Date <- as.Date(tsla$Date, "%m/%d/%Y")
goog$Date <- as.Date(goog$Date, "%m/%d/%Y")
```

#### 1.2 Visualize data
```{r plot_data}
## Plot prices versus time
tsla_plot <- ggplot2::ggplot() + 
  ggplot2::geom_line(data = tsla, ggplot2::aes(x = Date, y = PX_LAST)) + ggplot2::ggtitle("TSLA")
goog_plot <- ggplot2::ggplot() + 
  ggplot2::geom_line(data = goog, ggplot2::aes(x = Date, y = PX_LAST)) + ggplot2::ggtitle("GOOG") + 
  ggplot2::scale_x_date(limits = c(base::min(tsla$Date), base::max(tsla$Date))) # Align the x-axis with TSLA
gridExtra::grid.arrange(tsla_plot, goog_plot)
```

### 2 - Data Preprocessing
#### 2.1 Count the number of Missing Values in each feature

```{r numNA, warning=FALSE}
require(dplyr)
totalRowTsla = base::nrow(tsla)
totalColTsla = base::ncol(tsla)

naTsla       = tsla %>%
               base::sapply(.,function(y) base::sum(base::length(base::which(base::is.na(y))))) %>%
               base::as.data.frame() %>%
               tibble::rownames_to_column(., "Features")
              

totalRowGoog = base::nrow(goog)
totalColGoog = base::ncol(goog)

naGoog       = goog %>%
               base::sapply(.,function(y) base::sum(base::length(base::which(base::is.na(y))))) %>%
               base::as.data.frame() %>%
               tibble::rownames_to_column(., "Features")
```

>__Tesla__

Total number of rows: `r totalRowTsla`

Total number of columns: `r totalColTsla`


```{r naTslaKnit, echo=FALSE}

knitr::kable(
 naTsla,
 col.names = c("Features","Number of Missing Values"),
 caption   = "Table 2-1: The number of Missing Values - Tesla",
 align     = "lccrr"
)
```

>__Google__

Total number of rows: `r totalRowGoog`

Total number of columns: `r totalColGoog`


```{r naGoogKnit, echo=FALSE}
knitr::kable(
 naGoog,
 col.names = c("Features","Number of Missing Values"),
 caption   = "Table 2-2: The number of Missing Values - Google",
 align     = "lccrr"
)
```


#### 2.2 Data Transformation 

##### 2.2.1 Data Filtering - Tesla
Features with less than 100 missing values will be included by deleting corresponding rows with missing values instead.
```{r filterTsla, warning=FALSE}
#Select a subset of original data for data transformation and PCA
tslaSelected = tsla %>%
  .[,(base::which(naTsla[,2] < 100))] %>%
  .[!(base::apply(.,1, function(y){any(is.na(y))})),] %>%
  .[,-1] #remove dates in the first column

#Apply Log-transformation on tslaSelected$TURNOVER to avoid producing NaN in skewness computation
tslaSelected$TURNOVER = base::log(tslaSelected$TURNOVER)
base::names(tslaSelected) [6]= "log(TURNOVER)"
```

##### 2.2.2 Calculate Skewness - Tesla
```{r skewnessTsla, warning=FALSE}
require(e1071)
skewValuesTsla = base::apply(tslaSelected,2,e1071::skewness)
```

```{r skewnessTslaTable, warning=FALSE, echo=FALSE}
skewValuesTsla = skewValuesTsla%>%
               base::as.data.frame() %>%
               tibble::rownames_to_column(., "features")

knitr::kable(
 skewValuesTsla,
 col.names = c("Features","Skewness"),
 caption   = "Table 2-3: Skewness of Selected Features - Tesla",
 align     = "lccrr"
)
```

##### 2.2.3 Data Transformation - Tesla
```{r dataTransTsla, warning=FALSE}
#Transform the selected data
(tslaTrans = caret::preProcess(tslaSelected, method = c("BoxCox","center","scale","pca")))

#Apply the transformations("BoxCox","center","scale","pca")
tslaPCA = stats::predict(tslaTrans,tslaSelected) #Outputs are PCA components
utils::head(tslaPCA)

#Summary of PCA results
(tslaTrans_     = caret::preProcess(tslaSelected, method = c("BoxCox","center","scale")))
propVarTslaPCA = tslaSelected %>%
                 stats::predict(tslaTrans_,.) %>%
                 stats::prcomp() %>%
                 base::summary()
propVarTslaPCA #proportion of variance explained by each PCs

```

##### 2.2.4 Data Filtering - Google
Features with less than 100 missing values will be included by deleting corresponding rows with missing values instead.
```{r filterGoog, warning=FALSE}
#Select a subset of original data for data transformation and PCA
googSelected = goog %>%
  .[,(base::which(naGoog[,2] < 100))] %>%
  .[!(base::apply(.,1, function(y){any(is.na(y))})),] %>%
  .[,-1] #remove dates in the first column

#Apply Log-transformation on googSelected$TURNOVER
googSelected$TURNOVER = base::log(googSelected$TURNOVER)
base::names(googSelected) [6]= "log(TURNOVER)"
```


##### 2.2.5 Calculate Skewness - Google
```{r skewnessGoog, warning=FALSE}
#require(e1071)
skewValuesGoog = base::apply(googSelected,2,e1071::skewness)
```

```{r skewnessGoogTable, warning=FALSE, echo=FALSE}
skewValuesGoog = skewValuesGoog%>%
               base::as.data.frame() %>%
               tibble::rownames_to_column(., "features")

knitr::kable(
 skewValuesTsla,
 col.names = c("Features","Skewness"),
 caption   = "Table 2-4: Skewness of Selected Features - Google",
 align     = "lccrr"
)
```


##### 2.2.6 Data Transformation - Google
```{r dataTransGoog, warning=FALSE}
#Transform the selected data
(googTrans = caret::preProcess(googSelected, method = c("BoxCox","center","scale","pca")))

#Apply the transformations("BoxCox","center","scale","pca")
googPCA = stats::predict(googTrans,googSelected) #Outputs are PCA components
utils::head(googPCA)

#Summary of PCA results
(googTrans_    = caret::preProcess(googSelected, method = c("BoxCox","center","scale")))
propVarGoogPCA = googSelected %>%
                 stats::predict(googTrans_,.) %>%
                 stats::prcomp() %>%
                 base::summary()
propVarGoogPCA #proportion of variance explained by each PCs
```


### 2.3 Correlation Analysis 
>__Tesla__
```{r findCorrelationTsla, warning=FALSE}
library(corrplot)
corrTsla     = stats::cor(tslaSelected)
corrplot::corrplot(corrTsla, order="hclust")
```

#### Fig. 2.1 Correlations between features - Tesla


>__Google__
```{r findCorrelationGoog, warning=FALSE}
#library(corrplot)
corrGoog     = stats::cor(googSelected)
corrplot::corrplot(corrGoog, order="hclust")
```

#### Fig. 2.2 Correlations between features - Google
